{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b461584d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b4696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from replay.data import FeatureType, FeatureHint, FeatureInfo, FeatureSchema, Dataset\n",
    "from replay.splitters import TimeSplitter # LastNSplitter\n",
    "from replay.data.nn import (\n",
    "    SequenceTokenizer,\n",
    "    SequentialDataset,\n",
    "    TensorFeatureSource,\n",
    "    TensorSchema,\n",
    "    TensorFeatureInfo\n",
    ")\n",
    "from replay.data import FeatureHint, FeatureSource, FeatureType\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential import Bert4Rec\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from replay.models.nn.sequential.callbacks import ValidationMetricsCallback\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.models.nn.sequential.bert4rec import (\n",
    "    Bert4RecTrainingDataset,\n",
    "    Bert4RecValidationDataset\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import gc\n",
    "import weakref\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.9) # Memory usage limit for MacOS\n",
    "    torch.mps.empty_cache() \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(911)\n",
    "random.seed(911)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ebaea",
   "metadata": {},
   "source": [
    "**For cleaning memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb7a4dda-0964-49d1-8812-6c0bb98246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931cb14-3e62-4c69-b4cc-b034940382c2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78abc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path().resolve() # Path(__file__).resolve()\n",
    "project_dir = file_path.parent\n",
    "raw_data_path = project_dir / 'data' / 'raw'\n",
    "products_data_dir = project_dir / 'data' / 'processed' / 'products_data'\n",
    "interim_data_dir = project_dir / 'data' / 'interim'\n",
    "models_outputs_dir = project_dir / 'data' / 'processed' / 'models_outputs'\n",
    "models_dir = project_dir / 'models'\n",
    "processed_images_dir = products_data_dir / 'processed_images_224x224'\n",
    "\n",
    "raw_data_path.mkdir(parents=True, exist_ok=True)\n",
    "products_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "interim_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_images_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc263f5a",
   "metadata": {},
   "source": [
    "## Fast Data load (only if data was processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b330cef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>product_created_at_day</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "      <th>embedding_e5_large_v2</th>\n",
       "      <th>embedding_bge_large_en_v15</th>\n",
       "      <th>embedding_nomic_embed_text_v15</th>\n",
       "      <th>articul_encrypred_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228217</th>\n",
       "      <td>xspvtuqv</td>\n",
       "      <td>18529</td>\n",
       "      <td>9417.00</td>\n",
       "      <td>[0.1068585216999054, -0.06343062222003937, -0....</td>\n",
       "      <td>[0.017839273437857628, -0.010774536058306694, ...</td>\n",
       "      <td>[-0.24715401232242584, 0.41301143169403076, -0...</td>\n",
       "      <td>[0.3190707266330719, 0.028264325112104416, 0.0...</td>\n",
       "      <td>[0.5622039437294006, -0.4325735867023468, 0.44...</td>\n",
       "      <td>[0.8816746473312378, 0.691596269607544, 0.1884...</td>\n",
       "      <td>[0.2884502708911896, 0.38565462827682495, -0.0...</td>\n",
       "      <td>[0.03428741917014122, -0.06396043300628662, 0....</td>\n",
       "      <td>[0.007279624696820974, 0.006243441719561815, 0...</td>\n",
       "      <td>[-0.036529459059238434, 0.03486456722021103, -...</td>\n",
       "      <td>218574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228218</th>\n",
       "      <td>xtqwuuuy</td>\n",
       "      <td>18530</td>\n",
       "      <td>19380.79</td>\n",
       "      <td>[0.09790005534887314, -0.03745045466348529, 0....</td>\n",
       "      <td>[0.012738960678689182, -0.002624053042382002, ...</td>\n",
       "      <td>[-0.03077596426010132, 0.19863871857523918, -0...</td>\n",
       "      <td>[0.03357352642342448, 0.0015215009916573763, 0...</td>\n",
       "      <td>[0.5787270814180374, -0.054604075849056244, 0....</td>\n",
       "      <td>[0.7522355616092682, 0.7038511633872986, 0.364...</td>\n",
       "      <td>[-0.0036218371242284775, 0.18161564506590366, ...</td>\n",
       "      <td>[0.03048939537256956, -0.06178726628422737, 0....</td>\n",
       "      <td>[-0.0015129486564546824, 0.01574902841821313, ...</td>\n",
       "      <td>[0.005874196067452431, 0.08644555881619453, -0...</td>\n",
       "      <td>207628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred  product_created_at_day  sales_total  \\\n",
       "228217          xspvtuqv                   18529      9417.00   \n",
       "228218          xtqwuuuy                   18530     19380.79   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "228217  [0.1068585216999054, -0.06343062222003937, -0....   \n",
       "228218  [0.09790005534887314, -0.03745045466348529, 0....   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "228217  [0.017839273437857628, -0.010774536058306694, ...   \n",
       "228218  [0.012738960678689182, -0.002624053042382002, ...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "228217  [-0.24715401232242584, 0.41301143169403076, -0...   \n",
       "228218  [-0.03077596426010132, 0.19863871857523918, -0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "228217  [0.3190707266330719, 0.028264325112104416, 0.0...   \n",
       "228218  [0.03357352642342448, 0.0015215009916573763, 0...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "228217  [0.5622039437294006, -0.4325735867023468, 0.44...   \n",
       "228218  [0.5787270814180374, -0.054604075849056244, 0....   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "228217  [0.8816746473312378, 0.691596269607544, 0.1884...   \n",
       "228218  [0.7522355616092682, 0.7038511633872986, 0.364...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \\\n",
       "228217  [0.2884502708911896, 0.38565462827682495, -0.0...   \n",
       "228218  [-0.0036218371242284775, 0.18161564506590366, ...   \n",
       "\n",
       "                                    embedding_e5_large_v2  \\\n",
       "228217  [0.03428741917014122, -0.06396043300628662, 0....   \n",
       "228218  [0.03048939537256956, -0.06178726628422737, 0....   \n",
       "\n",
       "                               embedding_bge_large_en_v15  \\\n",
       "228217  [0.007279624696820974, 0.006243441719561815, 0...   \n",
       "228218  [-0.0015129486564546824, 0.01574902841821313, ...   \n",
       "\n",
       "                           embedding_nomic_embed_text_v15  \\\n",
       "228217  [-0.036529459059238434, 0.03486456722021103, -...   \n",
       "228218  [0.005874196067452431, 0.08644555881619453, -0...   \n",
       "\n",
       "        articul_encrypred_id  \n",
       "228217                218574  \n",
       "228218                207628  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store_encoded</th>\n",
       "      <th>articul_encrypred_id</th>\n",
       "      <th>sales_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3354708</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wyuutrv</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>3</td>\n",
       "      <td>69858</td>\n",
       "      <td>453198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354709</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wywqryu</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>3</td>\n",
       "      <td>129264</td>\n",
       "      <td>155835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred  order_date  store_encoded  \\\n",
       "3354708  wyyyyqqsyyvxvvtr           wyuutrv  2020-08-17              3   \n",
       "3354709  wyyyyqqsyyvxvvtr           wywqryu  2020-07-15              3   \n",
       "\n",
       "         articul_encrypred_id  sales_total  \n",
       "3354708                 69858       453198  \n",
       "3354709                129264       155835  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_products_articul = pd.read_parquet(products_data_dir / 'df_products_articul.parquet')\n",
    "df_sales_articul = pd.read_parquet(products_data_dir / 'df_sales_articul.parquet')\n",
    "\n",
    "display(df_products_articul.tail(2), df_sales_articul.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb74048",
   "metadata": {},
   "source": [
    "## Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc17ce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>image_path</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding_e5_large_v2</th>\n",
       "      <th>embedding_bge_large_en_v15</th>\n",
       "      <th>embedding_nomic_embed_text_v15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306670</th>\n",
       "      <td>wqsvuwy</td>\n",
       "      <td>Разноцветный</td>\n",
       "      <td>Lancel</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Аксессуары</td>\n",
       "      <td>Платки</td>\n",
       "      <td>Платок шелковый</td>\n",
       "      <td>Шелковый платок</td>\n",
       "      <td>13567982</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>6027468-shelkovyi-platok-lancel-raznotcvetnyi-...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/f5/9...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[0.14456921815872192, -0.06249238923192024, -0...</td>\n",
       "      <td>[0.013126503676176071, -0.0019127298146486282,...</td>\n",
       "      <td>[0.22613008320331573, 0.1457078456878662, -0.1...</td>\n",
       "      <td>[0.030423777177929878, 0.0, 0.0, 0.08489743620...</td>\n",
       "      <td>[0.15574012696743011, -0.3459433317184448, 0.6...</td>\n",
       "      <td>[0.6875616312026978, 0.6793960332870483, 0.354...</td>\n",
       "      <td>[0.42158013582229614, 0.2945811450481415, 0.35...</td>\n",
       "      <td>This Lancel silk scarf features shades of blue...</td>\n",
       "      <td>[0.02612929418683052, -0.05050811171531677, 0....</td>\n",
       "      <td>[-0.020242616534233093, -0.01976708509027958, ...</td>\n",
       "      <td>[0.01306484080851078, 0.022184912115335464, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306671</th>\n",
       "      <td>ttquswt</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Giorgio Armani</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Бижутерия</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>11201309</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>5504265-brosh-giorgio-armani-chernyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/76/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.12436471879482269, -0.030923746526241302, ...</td>\n",
       "      <td>[-0.01337357982993126, -0.0029991380870342255,...</td>\n",
       "      <td>[-0.09756504744291306, -0.15952929854393005, 0...</td>\n",
       "      <td>[0.03119073063135147, 0.0002419875527266413, 0...</td>\n",
       "      <td>[0.5343070030212402, 0.26047518849372864, 0.37...</td>\n",
       "      <td>[0.7018769979476929, 0.5926704406738281, 0.369...</td>\n",
       "      <td>[0.2984030842781067, 0.4144335687160492, -0.12...</td>\n",
       "      <td>This item is a black brooch from Giorgio Arman...</td>\n",
       "      <td>[0.013706686906516552, -0.061785973608493805, ...</td>\n",
       "      <td>[-0.029468011111021042, 0.002113671973347664, ...</td>\n",
       "      <td>[0.03772303834557533, 0.08191631734371185, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred    color_base           brand               ktt1  \\\n",
       "306670           wqsvuwy  Разноцветный          Lancel  Товары для женщин   \n",
       "306671           ttquswt        Чёрный  Giorgio Armani  Товары для женщин   \n",
       "\n",
       "              ktt2    ktt3             ktt4            title  product_id  \\\n",
       "306670  Аксессуары  Платки  Платок шелковый  Шелковый платок    13567982   \n",
       "306671   Бижутерия   Брошь            Брошь            Брошь    11201309   \n",
       "\n",
       "       product_created_at                                               slug  \\\n",
       "306670         2020-06-25  6027468-shelkovyi-platok-lancel-raznotcvetnyi-...   \n",
       "306671         2016-07-26               5504265-brosh-giorgio-armani-chernyi   \n",
       "\n",
       "                                          photo_analytics  sales_total  \\\n",
       "306670  https://st-cdn.tsum.com/int/height/1526/i/f5/9...         0.01   \n",
       "306671  https://st-cdn.tsum.com/int/height/1526//i/76/...         0.01   \n",
       "\n",
       "                                               image_path  \\\n",
       "306670  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "306671  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.14456921815872192, -0.06249238923192024, -0...   \n",
       "306671  [-0.12436471879482269, -0.030923746526241302, ...   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.013126503676176071, -0.0019127298146486282,...   \n",
       "306671  [-0.01337357982993126, -0.0029991380870342255,...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.22613008320331573, 0.1457078456878662, -0.1...   \n",
       "306671  [-0.09756504744291306, -0.15952929854393005, 0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "306670  [0.030423777177929878, 0.0, 0.0, 0.08489743620...   \n",
       "306671  [0.03119073063135147, 0.0002419875527266413, 0...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.15574012696743011, -0.3459433317184448, 0.6...   \n",
       "306671  [0.5343070030212402, 0.26047518849372864, 0.37...   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.6875616312026978, 0.6793960332870483, 0.354...   \n",
       "306671  [0.7018769979476929, 0.5926704406738281, 0.369...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.42158013582229614, 0.2945811450481415, 0.35...   \n",
       "306671  [0.2984030842781067, 0.4144335687160492, -0.12...   \n",
       "\n",
       "                                              description  \\\n",
       "306670  This Lancel silk scarf features shades of blue...   \n",
       "306671  This item is a black brooch from Giorgio Arman...   \n",
       "\n",
       "                                    embedding_e5_large_v2  \\\n",
       "306670  [0.02612929418683052, -0.05050811171531677, 0....   \n",
       "306671  [0.013706686906516552, -0.061785973608493805, ...   \n",
       "\n",
       "                               embedding_bge_large_en_v15  \\\n",
       "306670  [-0.020242616534233093, -0.01976708509027958, ...   \n",
       "306671  [-0.029468011111021042, 0.002113671973347664, ...   \n",
       "\n",
       "                           embedding_nomic_embed_text_v15  \n",
       "306670  [0.01306484080851078, 0.022184912115335464, -0...  \n",
       "306671  [0.03772303834557533, 0.08191631734371185, -0....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products = pd.read_parquet(products_data_dir / 'products_data.parquet')\n",
    "df_products.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c93e89",
   "metadata": {},
   "source": [
    "There are some broken URLs — we remove these items from our dataset.\n",
    "\n",
    "![alt text](../junk/broken_urls.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c40ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows initially: 306672\n",
      "Number of rows with at least one missing value: 8\n",
      "Number of rows after cleaning: 306664\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of rows initially: {df_products.shape[0]}')\n",
    "print(f'Number of rows with at least one missing value: {df_products[df_products.isna().any(axis=1)].shape[0]}')\n",
    "\n",
    "df_products.dropna(inplace=True)\n",
    "print(f'Number of rows after cleaning: {df_products.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde12f24",
   "metadata": {},
   "source": [
    "**Переход с ключа `product_id` на ключ `articul_encrypred`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d71d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>product_created_at_day</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "      <th>embedding_e5_large_v2</th>\n",
       "      <th>embedding_bge_large_en_v15</th>\n",
       "      <th>embedding_nomic_embed_text_v15</th>\n",
       "      <th>articul_encrypred_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228214</th>\n",
       "      <td>wyyyxuw</td>\n",
       "      <td>18430</td>\n",
       "      <td>372493.07</td>\n",
       "      <td>[0.054675329476594925, -0.031218096613883972, ...</td>\n",
       "      <td>[-0.015285112895071507, -0.002974292729049921,...</td>\n",
       "      <td>[-0.10003115236759186, -0.007143696304410696, ...</td>\n",
       "      <td>[0.022604845464229584, 0.008857643231749535, 0...</td>\n",
       "      <td>[-0.005107337608933449, 0.055002182722091675, ...</td>\n",
       "      <td>[0.6566806435585022, 0.8994556665420532, 0.425...</td>\n",
       "      <td>[0.40712353587150574, 0.6740058064460754, -0.0...</td>\n",
       "      <td>[0.026547163724899292, -0.05078291893005371, 0...</td>\n",
       "      <td>[0.010242261923849583, -0.008357411250472069, ...</td>\n",
       "      <td>[-0.01627330109477043, 0.03971276432275772, -0...</td>\n",
       "      <td>80702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228215</th>\n",
       "      <td>wyyyxux</td>\n",
       "      <td>18405</td>\n",
       "      <td>55930.00</td>\n",
       "      <td>[0.12628699839115143, -0.1826455146074295, -0....</td>\n",
       "      <td>[0.013777711428701878, -0.02734513208270073, -...</td>\n",
       "      <td>[-0.25407537817955017, -0.1469070166349411, -0...</td>\n",
       "      <td>[0.1269151270389557, 0.0, 6.139278411865234e-0...</td>\n",
       "      <td>[0.1935054361820221, 0.6354405879974365, 0.621...</td>\n",
       "      <td>[0.6567713618278503, 0.706050455570221, 0.4033...</td>\n",
       "      <td>[0.5280981063842773, 0.5120133757591248, 0.190...</td>\n",
       "      <td>[0.03120279870927334, -0.04832116514444351, 0....</td>\n",
       "      <td>[-0.02726542204618454, -0.004029609262943268, ...</td>\n",
       "      <td>[-0.024061240255832672, 0.05157441273331642, -...</td>\n",
       "      <td>176363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228216</th>\n",
       "      <td>wyyyxuy</td>\n",
       "      <td>18412</td>\n",
       "      <td>293330.55</td>\n",
       "      <td>[-0.03089914657175541, 0.0044742790050804615, ...</td>\n",
       "      <td>[0.010508312843739986, 0.01059587299823761, -0...</td>\n",
       "      <td>[-0.01950656808912754, -0.05603202059864998, -...</td>\n",
       "      <td>[0.004777229391038418, 0.0, 0.1000245586037635...</td>\n",
       "      <td>[0.4373447895050049, 0.04957278072834015, 0.67...</td>\n",
       "      <td>[0.8001006245613098, 0.9261599779129028, 0.368...</td>\n",
       "      <td>[0.34528201818466187, 0.702330470085144, 0.210...</td>\n",
       "      <td>[0.01696249097585678, -0.058472465723752975, 0...</td>\n",
       "      <td>[-0.0057455929927527905, -0.000962883175816386...</td>\n",
       "      <td>[0.03578423336148262, 0.022266210988163948, -0...</td>\n",
       "      <td>94224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228217</th>\n",
       "      <td>xspvtuqv</td>\n",
       "      <td>18529</td>\n",
       "      <td>9417.00</td>\n",
       "      <td>[0.1068585216999054, -0.06343062222003937, -0....</td>\n",
       "      <td>[0.017839273437857628, -0.010774536058306694, ...</td>\n",
       "      <td>[-0.24715401232242584, 0.41301143169403076, -0...</td>\n",
       "      <td>[0.3190707266330719, 0.028264325112104416, 0.0...</td>\n",
       "      <td>[0.5622039437294006, -0.4325735867023468, 0.44...</td>\n",
       "      <td>[0.8816746473312378, 0.691596269607544, 0.1884...</td>\n",
       "      <td>[0.2884502708911896, 0.38565462827682495, -0.0...</td>\n",
       "      <td>[0.03428741917014122, -0.06396043300628662, 0....</td>\n",
       "      <td>[0.007279624696820974, 0.006243441719561815, 0...</td>\n",
       "      <td>[-0.036529459059238434, 0.03486456722021103, -...</td>\n",
       "      <td>218574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228218</th>\n",
       "      <td>xtqwuuuy</td>\n",
       "      <td>18530</td>\n",
       "      <td>19380.79</td>\n",
       "      <td>[0.09790005534887314, -0.03745045466348529, 0....</td>\n",
       "      <td>[0.012738960678689182, -0.002624053042382002, ...</td>\n",
       "      <td>[-0.03077596426010132, 0.19863871857523918, -0...</td>\n",
       "      <td>[0.03357352642342448, 0.0015215009916573763, 0...</td>\n",
       "      <td>[0.5787270814180374, -0.054604075849056244, 0....</td>\n",
       "      <td>[0.7522355616092682, 0.7038511633872986, 0.364...</td>\n",
       "      <td>[-0.0036218371242284775, 0.18161564506590366, ...</td>\n",
       "      <td>[0.03048939537256956, -0.06178726628422737, 0....</td>\n",
       "      <td>[-0.0015129486564546824, 0.01574902841821313, ...</td>\n",
       "      <td>[0.005874196067452431, 0.08644555881619453, -0...</td>\n",
       "      <td>207628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred  product_created_at_day  sales_total  \\\n",
       "228214           wyyyxuw                   18430    372493.07   \n",
       "228215           wyyyxux                   18405     55930.00   \n",
       "228216           wyyyxuy                   18412    293330.55   \n",
       "228217          xspvtuqv                   18529      9417.00   \n",
       "228218          xtqwuuuy                   18530     19380.79   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "228214  [0.054675329476594925, -0.031218096613883972, ...   \n",
       "228215  [0.12628699839115143, -0.1826455146074295, -0....   \n",
       "228216  [-0.03089914657175541, 0.0044742790050804615, ...   \n",
       "228217  [0.1068585216999054, -0.06343062222003937, -0....   \n",
       "228218  [0.09790005534887314, -0.03745045466348529, 0....   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "228214  [-0.015285112895071507, -0.002974292729049921,...   \n",
       "228215  [0.013777711428701878, -0.02734513208270073, -...   \n",
       "228216  [0.010508312843739986, 0.01059587299823761, -0...   \n",
       "228217  [0.017839273437857628, -0.010774536058306694, ...   \n",
       "228218  [0.012738960678689182, -0.002624053042382002, ...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "228214  [-0.10003115236759186, -0.007143696304410696, ...   \n",
       "228215  [-0.25407537817955017, -0.1469070166349411, -0...   \n",
       "228216  [-0.01950656808912754, -0.05603202059864998, -...   \n",
       "228217  [-0.24715401232242584, 0.41301143169403076, -0...   \n",
       "228218  [-0.03077596426010132, 0.19863871857523918, -0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "228214  [0.022604845464229584, 0.008857643231749535, 0...   \n",
       "228215  [0.1269151270389557, 0.0, 6.139278411865234e-0...   \n",
       "228216  [0.004777229391038418, 0.0, 0.1000245586037635...   \n",
       "228217  [0.3190707266330719, 0.028264325112104416, 0.0...   \n",
       "228218  [0.03357352642342448, 0.0015215009916573763, 0...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "228214  [-0.005107337608933449, 0.055002182722091675, ...   \n",
       "228215  [0.1935054361820221, 0.6354405879974365, 0.621...   \n",
       "228216  [0.4373447895050049, 0.04957278072834015, 0.67...   \n",
       "228217  [0.5622039437294006, -0.4325735867023468, 0.44...   \n",
       "228218  [0.5787270814180374, -0.054604075849056244, 0....   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "228214  [0.6566806435585022, 0.8994556665420532, 0.425...   \n",
       "228215  [0.6567713618278503, 0.706050455570221, 0.4033...   \n",
       "228216  [0.8001006245613098, 0.9261599779129028, 0.368...   \n",
       "228217  [0.8816746473312378, 0.691596269607544, 0.1884...   \n",
       "228218  [0.7522355616092682, 0.7038511633872986, 0.364...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \\\n",
       "228214  [0.40712353587150574, 0.6740058064460754, -0.0...   \n",
       "228215  [0.5280981063842773, 0.5120133757591248, 0.190...   \n",
       "228216  [0.34528201818466187, 0.702330470085144, 0.210...   \n",
       "228217  [0.2884502708911896, 0.38565462827682495, -0.0...   \n",
       "228218  [-0.0036218371242284775, 0.18161564506590366, ...   \n",
       "\n",
       "                                    embedding_e5_large_v2  \\\n",
       "228214  [0.026547163724899292, -0.05078291893005371, 0...   \n",
       "228215  [0.03120279870927334, -0.04832116514444351, 0....   \n",
       "228216  [0.01696249097585678, -0.058472465723752975, 0...   \n",
       "228217  [0.03428741917014122, -0.06396043300628662, 0....   \n",
       "228218  [0.03048939537256956, -0.06178726628422737, 0....   \n",
       "\n",
       "                               embedding_bge_large_en_v15  \\\n",
       "228214  [0.010242261923849583, -0.008357411250472069, ...   \n",
       "228215  [-0.02726542204618454, -0.004029609262943268, ...   \n",
       "228216  [-0.0057455929927527905, -0.000962883175816386...   \n",
       "228217  [0.007279624696820974, 0.006243441719561815, 0...   \n",
       "228218  [-0.0015129486564546824, 0.01574902841821313, ...   \n",
       "\n",
       "                           embedding_nomic_embed_text_v15  \\\n",
       "228214  [-0.01627330109477043, 0.03971276432275772, -0...   \n",
       "228215  [-0.024061240255832672, 0.05157441273331642, -...   \n",
       "228216  [0.03578423336148262, 0.022266210988163948, -0...   \n",
       "228217  [-0.036529459059238434, 0.03486456722021103, -...   \n",
       "228218  [0.005874196067452431, 0.08644555881619453, -0...   \n",
       "\n",
       "        articul_encrypred_id  \n",
       "228214                 80702  \n",
       "228215                176363  \n",
       "228216                 94224  \n",
       "228217                218574  \n",
       "228218                207628  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_products.copy()\n",
    "del df_products\n",
    "\n",
    "df['product_created_at_day'] = pd.to_datetime(df['product_created_at']).dt.floor('D')\n",
    "df['product_created_at_day'] = (df['product_created_at_day'] - pd.Timestamp('1970-01-01')) // pd.Timedelta(days=1)\n",
    "\n",
    "# Embedding columns\n",
    "embedding_cols = [col for col in df.columns if any(prefix in col for prefix in ['CLS_', 'mean_patch_', 'pooled_', 'embedding_'])]\n",
    "agg_dict = {'product_created_at_day': 'min', \n",
    "            'sales_total': 'sum'}\n",
    "# Mean by dimenshion for embeddings\n",
    "for col in embedding_cols:\n",
    "    agg_dict[col] = 'mean'\n",
    "df_products_articul = df.groupby('articul_encrypred').agg(agg_dict).reset_index()\n",
    "\n",
    "del df\n",
    "\n",
    "# Create ranked ID by descending sales volume\n",
    "articul_rank = df_products_articul[['articul_encrypred', 'sales_total']].drop_duplicates().sort_values('sales_total', ascending=False).reset_index(drop=True).assign(articul_encrypred_id=lambda x: x.index + 1)\n",
    "df_products_articul = df_products_articul.merge(articul_rank[['articul_encrypred', 'articul_encrypred_id']], on='articul_encrypred', how='left')\n",
    "\n",
    "df_products_articul.to_parquet(products_data_dir / 'df_products_articul.parquet', index=False)\n",
    "df_products_articul.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b125a",
   "metadata": {},
   "source": [
    "## Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5214c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store_encoded</th>\n",
       "      <th>articul_encrypred_id</th>\n",
       "      <th>sales_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3369678</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wyuutrv</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>3</td>\n",
       "      <td>69858</td>\n",
       "      <td>453198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369679</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wywqryu</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>3</td>\n",
       "      <td>129264</td>\n",
       "      <td>155835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred  order_date  store_encoded  \\\n",
       "3369678  wyyyyqqsyyvxvvtr           wyuutrv  2020-08-17              3   \n",
       "3369679  wyyyyqqsyyvxvvtr           wywqryu  2020-07-15              3   \n",
       "\n",
       "         articul_encrypred_id  sales_total  \n",
       "3369678                 69858       453198  \n",
       "3369679                129264       155835  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales = pd.read_csv(raw_data_path / 'full_orders_v6.csv', sep=None, engine='python')[['anon_id_encrypred', 'articul_encrypred', 'order_date', 'store']]\n",
    "\n",
    "df_grouped = df_sales.groupby(['anon_id_encrypred', 'articul_encrypred', 'order_date']).agg(lambda x: x.mode().iloc[0]).reset_index() \n",
    "\n",
    "# Encode purchase channel\n",
    "store_encoding = {'E': 1, 'O': 2, 'T': 3, 'D': 4, 'B': 5} \n",
    "df_grouped['store_encoded'] = df_grouped['store'].map(store_encoding) \n",
    "\n",
    "# Add total sales by articul (sales total calculated in photo_embeddings.py)\n",
    "df_sales_articul = df_grouped.merge(df_products_articul[['articul_encrypred', 'articul_encrypred_id', 'sales_total']], on='articul_encrypred', how='left')\n",
    "df_sales_articul.drop(columns='store', inplace=True)\n",
    "\n",
    "# Drop articul_encrypred which are not represented in df_products_articul\n",
    "df_sales_articul.dropna(inplace=True)\n",
    "df_sales_articul['articul_encrypred_id'] = df_sales_articul['articul_encrypred_id'].astype(int)\n",
    "df_sales_articul['sales_total'] = df_sales_articul['sales_total'].astype(int)\n",
    "\n",
    "del df_grouped, df_sales\n",
    "\n",
    "df_sales_articul.to_parquet(products_data_dir / 'df_sales_articul.parquet', index=False)\n",
    "df_sales_articul.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64930a5f",
   "metadata": {},
   "source": [
    "Keep only the products that are present in the df_products dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 'articul_encrypred' values — df_sales: 234460, df_products: 228219\n",
      "Unique 'product_id' values — df_sales: 314113, df_products: 306664\n",
      "\n",
      "Unique 'articul_encrypred' values (after filtering) — df_sales: 228219, df_products: 228219\n",
      "Unique 'product_id' values (after filtering) — df_sales: 306664, df_products: 306664\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Unique 'articul_encrypred' values — articul_encrypred: {len(articul_encrypred['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "# print(f\"Unique 'articul_encrypred' values — df_sales: {len(df_sales['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "\n",
    "# df_sales = df_sales.merge(\n",
    "#     df_products[['articul_encrypred']],\n",
    "#     on=['articul_encrypred'],\n",
    "#     how='inner'\n",
    "# )\n",
    "# print()\n",
    "# print(f\"Unique 'articul_encrypred' values (after filtering) — df_sales: {len(df_sales['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "# print(f\"Unique 'articul_encrypred' values (after filtering) — df_sales: {len(df_sales['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "\n",
    "# df_sales.to_parquet(interim_data_dir / 'df_sales.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3df99b-df71-4157-8c56-0825361a43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_purchase_days_per_user = 100  # Maximum number of purchase days allowed per user (a purchase = unique user-day pair)\n",
    "# min_purchases_per_user = 2       # Minimum number of purchases required per user (a purchase = user-item interaction)\n",
    "\n",
    "# # Exclude \"resellers\" — users with too many unique purchase days (e.g., buying 5 items on 1 day = 1 purchase)\n",
    "# purchase_days = df_sales.groupby('anon_id_encrypred')['order_date'].nunique().reset_index()\n",
    "# purchase_days.columns = ['anon_id_encrypred', 'unique_purchase_days']\n",
    "# resellers = purchase_days[purchase_days['unique_purchase_days'] > max_purchase_days_per_user]['anon_id_encrypred']\n",
    "\n",
    "# # Exclude users with too few purchases (e.g., buying 5 items on 1 day = 5 purchases)\n",
    "# user_purchase_counts = df_sales['anon_id_encrypred'].value_counts()\n",
    "\n",
    "# df_sales = (df_sales[~df_sales['anon_id_encrypred'].isin(resellers)]\n",
    "#                [df_sales['anon_id_encrypred'].isin(user_purchase_counts[user_purchase_counts >= min_purchases_per_user].index)]\n",
    "#            ).reset_index(drop=True)\n",
    "\n",
    "# df_sales.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c3fb1-d990-47f8-a8e3-aa0ff9260640",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76daa2ba-dbc4-43d1-b2f2-7217b2d6007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Precision@K for batched recommendation results using GPU.\n",
    "    '''\n",
    "    precision_sum, total_users = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Precision@K'):\n",
    "            recs = batch['recs'][:, :k]     # [B, k]\n",
    "            true_pad = batch['true']        # [B, L]\n",
    "            true_len = batch['true_len']    # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True if the recommended item appears in the ground truth\n",
    "            # torch.isin performs elementwise comparison: [B, k, L], .any(-1) collapses last dim — \"was there at least one match\"\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1),       # [B, k, 1] – add dummy dimension\n",
    "            #     true_pad.unsqueeze(1)     # [B, 1, L_max] – reshape ground truth\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin with .any is not reliable on MPS (works fine on CUDA and even Mac CPU)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)\n",
    "\n",
    "            hits_cnt = hits_mask.sum(1).float()  # [B] – number of correct recommendations per user\n",
    "            denom = torch.minimum(true_len.clamp(min=1).float(), torch.tensor(k, device=device))  # min(k, true_len) – avoid penalizing users with few ground truth items\n",
    "            precision = hits_cnt / denom\n",
    "\n",
    "            precision_sum += precision.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return precision_sum / total_users\n",
    "    \n",
    "\n",
    "def recall_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Recall@K for batched recommendation results using GPU.\n",
    "    '''\n",
    "    recall_sum, total_users = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Recall@K'):\n",
    "            recs      = batch['recs'][:, :k]      # [B, k]  top-k recommendations\n",
    "            true_pad  = batch['true']             # [B, L]  true items, padded with -1\n",
    "            true_len  = batch['true_len']         # [B]     lengths of true lists\n",
    "\n",
    "            # hits_mask: [B, k] – True if a recommendation matches any true item\n",
    "            # torch.isin compares [B, k, 1] with [B, 1, L], resulting in [B, k, L]; .any(-1) collapses over L to detect any match\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1),       # [B, k, 1] – expand recs\n",
    "            #     true_pad.unsqueeze(1)     # [B, 1, L] – expand ground truth\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin with .any does not work correctly on MPS (works on CUDA and Mac CPU)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            hits_cnt = hits_mask.sum(1).float()    # [B]  number of relevant recommendations\n",
    "\n",
    "            # recall = hits / |true|; skip users with no true items\n",
    "            valid_mask = true_len > 0              # [B]  boolean mask\n",
    "            recall = torch.zeros_like(hits_cnt)\n",
    "            recall[valid_mask] = hits_cnt[valid_mask] / true_len[valid_mask].float()\n",
    "\n",
    "            recall_sum  += recall.sum().item()\n",
    "            total_users += valid_mask.sum().item()\n",
    "\n",
    "    return recall_sum / total_users\n",
    "    \n",
    "\n",
    "def map_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Mean Average Precision (MAP@K) for batched recommendation results using GPU.\n",
    "    '''\n",
    "    map_sum, total_users = 0.0, 0\n",
    "    positions = (torch.arange(k, device=device).float() + 1)  # [1 … k]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='MAP@K'):\n",
    "            recs      = batch['recs'][:, :k]      # [B, k]\n",
    "            true_pad  = batch['true']             # [B, L]\n",
    "            true_len  = batch['true_len']         # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True if a recommended item is in the ground truth\n",
    "            # torch.isin performs pairwise comparison and returns [B, k, L]; .any(-1) collapses last dim to check if any match exists\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1),       # [B, k, 1] – expand recs\n",
    "            #     true_pad.unsqueeze(1)     # [B, 1, L_max] – expand ground truth\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin with .any does not work correctly on MPS (works fine on CUDA and Mac CPU)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            # cum_hits: number of hits encountered up to position j\n",
    "            cum_hits  = torch.cumsum(hits_mask.float(), dim=1)   # [B, k]\n",
    "\n",
    "            # precisions@j are computed only at hit positions\n",
    "            precisions = (cum_hits * hits_mask.float()) / positions  # [B, k]\n",
    "\n",
    "            # AP = sum of precisions / min(|true|, k)\n",
    "            denom = torch.minimum(true_len.clamp(min=1).float(), torch.tensor(k, device=device)) # [B]\n",
    "            ap = precisions.sum(1) / denom # [B]\n",
    "\n",
    "            map_sum += ap.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return map_sum / total_users\n",
    "\n",
    "\n",
    "def ndcg_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Normalized Discounted Cumulative Gain (NDCG@K) for batched recommendation results using GPU.\n",
    "    '''\n",
    "    ndcg_sum, total_users = 0.0, 0\n",
    "    discount = 1.0 / torch.log2(torch.arange(k, device=device).float() + 2)  # [1/log2(i+2)]\n",
    "    ideal_cum = torch.cumsum(discount, dim=0)                                # prefix sum for IDCG\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='NDCG@K'):\n",
    "            recs = batch['recs'][:, :k]        # [B, k]\n",
    "            true_pad = batch['true']           # [B, L]\n",
    "            true_len = batch['true_len']       # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True if the recommended item appears in the ground truth\n",
    "            # torch.isin performs elementwise comparison [B, k, L]; .any(-1) checks if at least one match exists per position\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1),       # [B, k, 1]\n",
    "            #     true_pad.unsqueeze(1)     # [B, 1, L_max]\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin with .any does not work properly on MPS (works fine on CUDA and Mac CPU)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            # DCG: sum of discounted gains at hit positions\n",
    "            dcg = (hits_mask.float() * discount).sum(1)   # [B]\n",
    "\n",
    "            # IDCG: maximum possible DCG under ideal ranking\n",
    "            idcg_len = torch.minimum(true_len, torch.tensor(k, device=device))  # [B]\n",
    "            idcg = torch.zeros_like(dcg)\n",
    "            idcg[idcg_len > 0] = ideal_cum[idcg_len[idcg_len > 0] - 1]\n",
    "\n",
    "            # NDCG = DCG / IDCG (0 if IDCG == 0)\n",
    "            ndcg = torch.where(idcg > 0, dcg / idcg, torch.zeros_like(dcg))\n",
    "\n",
    "            ndcg_sum += ndcg.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return ndcg_sum / total_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a47c837-d7ec-4526-ae3b-f39c8a630f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_results(model_name, precision_k, recall_k, map_k, ndcg_k, k, hyperparameters=None, round_level=4):\n",
    "    '''\n",
    "    Appends model evaluation results to the dataframe.\n",
    "    \n",
    "    model_name: str – name of the model\n",
    "    precision_k, recall_k, map_k, ndcg_k: torch.Tensor or float – evaluation metrics\n",
    "    k: int – value of K used in metrics\n",
    "    hyperparameters: dict – model hyperparameters (optional)\n",
    "    round_level: int – number of decimal places to round to (default is 4)\n",
    "    '''\n",
    "    global df_metrics\n",
    "    \n",
    "    # Convert tensors to floats and round them (if they are tensors)\n",
    "    precision_k = round(precision_k.item() if isinstance(precision_k, torch.Tensor) else precision_k, round_level)\n",
    "    recall_k = round(recall_k.item() if isinstance(recall_k, torch.Tensor) else recall_k, round_level)\n",
    "    map_k = round(map_k.item() if isinstance(map_k, torch.Tensor) else map_k, round_level)\n",
    "    ndcg_k = round(ndcg_k.item() if isinstance(ndcg_k, torch.Tensor) else ndcg_k, round_level)\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'k': k,\n",
    "        'Precision@k': precision_k,\n",
    "        'Recall@k': recall_k,\n",
    "        'MAP@k': map_k,\n",
    "        'NDCG@k': ndcg_k,\n",
    "        'Other_hyperparameters': hyperparameters\n",
    "    }])\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics, new_row], ignore_index=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(columns=['Model', 'k', 'Precision@k', 'Recall@k', 'MAP@k', 'NDCG@k', 'Other_hyperparameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d3648-7b10-4194-86be-59363065dc73",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1259b4-022b-416e-8cb2-f955bfc6e142",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929c50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, user_recommendations, user_to_true_items, k):\n",
    "        self.recommendations = [torch.LongTensor(recs[:k]) for recs in user_recommendations.values()]\n",
    "        self.true_items = [torch.LongTensor(list(user_to_true_items.get(u, []))) for u in user_recommendations.keys()]\n",
    "        self.true_len = [len(t) for t in self.true_items] \n",
    "        self.k = k\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.true_items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'recs': self.recommendations[idx], \n",
    "            'true': self.true_items[idx],\n",
    "            'true_len': self.true_len[idx]\n",
    "        }\n",
    "    \n",
    "\n",
    "def collate_fn(batch, device='mps'):\n",
    "    \"\"\"\n",
    "    Assembles the batch into full tensors so that all metrics\n",
    "    can be computed without Python loops (vectorized GPU).\n",
    "    Returns:\n",
    "        recs      – LongTensor [B, k]\n",
    "        true      – LongTensor [B, L_max] (padding = -100)\n",
    "        true_len  – LongTensor [B]        (length of the true list)\n",
    "    \"\"\"\n",
    "    recs = torch.stack([item['recs'] for item in batch])  # [B, k]\n",
    "    true_len = torch.tensor([item['true_len'] for item in batch], dtype=torch.long)\n",
    "    L_max = int(true_len.max()) if true_len.numel() else 0\n",
    "    true_pad = torch.full((len(batch), L_max), -100, dtype=torch.long)  # -100: sentinel\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        if true_len[i]:\n",
    "            true_pad[i, :true_len[i]] = item['true']\n",
    "\n",
    "    return {\n",
    "        'recs': recs.to(device),\n",
    "        'true': true_pad.to(device),\n",
    "        'true_len': true_len.to(device)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa8898",
   "metadata": {},
   "source": [
    "**User-based temporal split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2512df89-a9ef-4132-b136-08aa155ee5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сортируем данные по времени и бьём на трейн и тест\n",
    "# df_sales_articul['order_date'] = pd.to_datetime(df_sales_articul['order_date'])\n",
    "# df_sales_articul = df_sales_articul.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "\n",
    "# for user, user_df in df_sales_articul.groupby('anon_id_encrypred'):\n",
    "#     split_idx = int(len(user_df) * 0.8)\n",
    "#     train_data.append(user_df.iloc[:split_idx])\n",
    "#     test_data.append(user_df.iloc[split_idx:])\n",
    "\n",
    "# train_df = pd.concat(train_data)\n",
    "# test_df = pd.concat(test_data)\n",
    "\n",
    "# df_sales_articul.to_csv(interim_data_dir / 'df_sales_articul.csv', index=False)\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_users.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_users.csv', index=False)\n",
    "\n",
    "# df_sales_articul = pd.read_csv(interim_data_dir / 'df_sales_articul.csv')\n",
    "# train_df = pd.read_csv(interim_data_dir / 'train_data_by_users.csv')\n",
    "# test_df = pd.read_csv(interim_data_dir / 'test_data_by_users.csv')\n",
    "\n",
    "# print(f\"Train shape: {train_df.shape}\")\n",
    "# print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# test_user_to_true_items = test_df.groupby('anon_id_encrypred')['articul_encrypred'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5337b",
   "metadata": {},
   "source": [
    "**Global temporal split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "816c5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2019-01-01 00:00:00\n",
      "Max date: 2021-02-18 00:00:00\n",
      "Threshold date (85.0%): 2020-10-24 00:00:00\n",
      "Train shape: (2790879, 7)\n",
      "Test shape: (563831, 7)\n",
      "\n",
      "Total number of users: 453280\n",
      "Number of users in the training set: 390237\n",
      "Number of users in the test set: 163131\n",
      "\n",
      "Total number of 'articul_encrypred_idx': 228219\n",
      "Number of 'articul_encrypred_idx' in the training set: 208758\n",
      "Number of 'articul_encrypred_idx' in the test set: 106325\n"
     ]
    }
   ],
   "source": [
    "# df_sales_articul['order_date'] = pd.to_datetime(df_sales_articul['order_date'])\n",
    "# df_sales_articul = df_sales_articul.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# # # Leave only users with 5+ purchases (for decreasing the noise)\n",
    "# # user_counts = df_sales_articul['anon_id_encrypred'].value_counts()\n",
    "# # active_users = user_counts[user_counts >= 5].index\n",
    "# # df_sales_articul = df_sales_articul[df_sales_articul['anon_id_encrypred'].isin(active_users)]\n",
    "\n",
    "# # Index mapping\n",
    "# unique_articul_encrypred_id = df_sales_articul['articul_encrypred_id'].unique()\n",
    "# articul_encrypred_id_to_idx = {pid: idx + 1 for idx, pid in enumerate(unique_articul_encrypred_id)} # + 1 for PAD zero token (0)\n",
    "# df_sales_articul['articul_encrypred_idx'] = df_sales_articul['articul_encrypred_id'].map(articul_encrypred_id_to_idx)\n",
    "\n",
    "# # Train/Test time split\n",
    "# threshold_level = 0.85\n",
    "# min_date = df_sales_articul['order_date'].min()\n",
    "# max_date = df_sales_articul['order_date'].max()\n",
    "\n",
    "# print(f\"Min date: {min_date}\")\n",
    "# print(f\"Max date: {max_date}\")\n",
    "\n",
    "# total_days = (max_date - min_date).days\n",
    "# threshold_days = int(total_days * threshold_level)\n",
    "# threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "# print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "# train_df = df_sales_articul[df_sales_articul['order_date'] < threshold_date]\n",
    "# test_df = df_sales_articul[df_sales_articul['order_date'] >= threshold_date]\n",
    "\n",
    "# df_sales_articul.to_csv(interim_data_dir / 'df_sales_articul.csv', index=False)\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_threshold_date.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_threshold_date.csv', index=False)\n",
    "\n",
    "df_sales_articul = pd.read_csv(interim_data_dir / 'df_sales_articul.csv')\n",
    "train_df = pd.read_csv(interim_data_dir / 'train_data_by_threshold_date.csv')\n",
    "test_df = pd.read_csv(interim_data_dir / 'test_data_by_threshold_date.csv')\n",
    "# Reconstructing the articul_encrypred_id_to_idx dictionary from the dataframe\n",
    "articul_encrypred_id_to_idx = dict(df_sales_articul[['articul_encrypred_id', 'articul_encrypred_idx']].drop_duplicates().values)\n",
    "num_items = len(articul_encrypred_id_to_idx)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print()\n",
    "print(f\"Total number of users: {len(df_sales_articul['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the training set: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the test set: {len(test_df['anon_id_encrypred'].unique())}\")\n",
    "print()\n",
    "print(f\"Total number of 'articul_encrypred_idx': {len(df_sales_articul['articul_encrypred_idx'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred_idx' in the training set: {len(train_df['articul_encrypred_idx'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred_idx' in the test set: {len(test_df['articul_encrypred_idx'].unique())}\")\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['articul_encrypred_idx'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83dfa9",
   "metadata": {},
   "source": [
    "**Config for simple models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cda962",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "k = 10\n",
    "round_level = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edc970-1bd8-411a-a29f-10c11418a180",
   "metadata": {},
   "source": [
    "### 1. Top-K Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c19127f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'top_sales' / 'user_recommendations_top_k.pkl', \"rb\") as f:\n",
    "    user_recommendations_top_k = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12aa9a3e-3dd8-4ecd-ab58-a28a3e1d5031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1e056272ad4450b269b2e42b6de05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "popular_items = train_df['articul_encrypred_id'].value_counts().index.tolist()\n",
    "\n",
    "def recommend_top_k(top_k_items=k):\n",
    "    return popular_items[:top_k_items]\n",
    "\n",
    "user_recommendations_top_k = {user: recommend_top_k(top_k_items=k) for user in tqdm(test_df['anon_id_encrypred'].unique())}\n",
    "\n",
    "with open(models_outputs_dir / 'top_sales' / 'user_recommendations_top_k.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_top_k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "32918cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_top_k = RecommendationDataset(user_recommendations=user_recommendations_top_k, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_top_k, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3cf2548-9d9b-482d-936d-b017c7766712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d811d41168e74d39b3117613292da83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ab4aacf4ae468aa21c4763d3df6111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04706bff2f04ee3b29ed0e6521a6c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce75ad5e3934b669bc0b320d22842ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "\n",
    "log_model_results(model_name='Top-K', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None, round_level=round_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996d325-c77b-434d-ba15-eb17e2608809",
   "metadata": {},
   "source": [
    "### 2. Random Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9afb51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'random' / 'user_recommendations_random.pkl', \"rb\") as f:\n",
    "    user_recommendations_random = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb35dc09-640d-46ed-ae31-0f4b3cc6e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ba944650e34db1b1dadb3211cf598e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning recommendations:   0%|          | 0/163131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "def recommend_random(df, top_k_items=k):\n",
    "    return np.random.choice(df.unique(), size=min(top_k_items, len(df.unique())), replace=False)\n",
    "\n",
    "random_recommendations = recommend_random(df=train_df['articul_encrypred_id'], top_k_items=k)\n",
    "user_recommendations_random = {user: random_recommendations for user in tqdm(test_df['anon_id_encrypred'].unique(), desc='Assigning recommendations')}\n",
    "\n",
    "with open(models_outputs_dir / 'random' / 'user_recommendations_random.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_random, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3389614",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_random = RecommendationDataset(user_recommendations=user_recommendations_random, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_random, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cfdb09d3-1cff-4823-b614-a75af109b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea078a51355342edb9b0e2dd20b82985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bd6279a08b49dc92d805d4bab096dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a5aaf5337548d5ac90abe1b5fe5e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70de6ec82284100b85970e024fa015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "\n",
    "log_model_results(model_name='Random', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None, round_level=round_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861ad65-6435-47bf-ad54-085126a7ba8a",
   "metadata": {},
   "source": [
    "### 3. User-Based Collaborative Filtering (UBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb4fae8f-9af4-4e6b-a35a-03ad6457aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20  # top_n_similar_users\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_users = 1\n",
    "# Important!!! If you're using a GPU desktop — comment out the line below\n",
    "device = torch.device(\"cpu\")  # Sparse ops on MPS (MacBook) are not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd9c7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function to create a user-item matrix\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Returns a sparse matrix (csr_matrix) and index mappings \n",
    "    for users and products (user_labels, product_labels) in the exact order of factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'articul_encrypred_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Factorize users and products\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['articul_encrypred_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Create a sparse matrix (rows = users, columns = products)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "\n",
    "# 2. Function to compute user similarity matrix on GPU\n",
    "def compute_user_similarity(df):\n",
    "    \"\"\"\n",
    "    Creates a user-item matrix, applies log-smoothing to counts,\n",
    "    converts it to a PyTorch sparse tensor, and computes cosine similarity.\n",
    "    Returns user_similarity (result of sparse.mm) and user_labels.\n",
    "    \"\"\"\n",
    "    # Create user-item matrix\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Apply log(1 + count) to reduce the influence of frequent purchases\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # Convert sparse matrix to PyTorch sparse_coo_tensor\n",
    "    # indices:  shape = (2, number of non-zero elements)\n",
    "    # values:   shape = (number of non-zero elements,)\n",
    "    # size:     (number of users, number of products)\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # Normalize users row-wise for cosine similarity\n",
    "    # row_norms.shape = (num_users,)\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(user_item_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Divide each value by the norm of its corresponding row\n",
    "    # user_item_tensor.indices()[0] = row indices (users)\n",
    "    normalized_values = user_item_tensor.values() / row_norms[user_item_tensor.indices()[0]]\n",
    "    user_item_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        user_item_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=user_item_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # Compute cosine similarity matrix as M * M^T\n",
    "    user_similarity = torch.sparse.mm(user_item_tensor_normalized, user_item_tensor_normalized.t())\n",
    "    \n",
    "    return user_similarity, user_labels  # product_labels not needed for UBCF\n",
    "\n",
    "\n",
    "# 3. Recommendation function (User-Based CF) on GPU with row-wise processing\n",
    "def recommend_user_based_batch(\n",
    "    user_ids,\n",
    "    user_similarity,\n",
    "    user_labels,\n",
    "    df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_users=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For a list of user_ids, returns recommendations based on top-N similar users.\n",
    "    \"\"\"\n",
    "    # For fast user index lookup by user_id\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    \n",
    "    # Dictionary of all user purchases\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['articul_encrypred_id'].apply(set).to_dict()\n",
    "\n",
    "    # Precompute popular items (store more than top_k_items for filtering)\n",
    "    most_popular_items = df['articul_encrypred_id'].value_counts().index.tolist()\n",
    "    \n",
    "    # Dictionary: user_id -> list of recommended items\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Split user_ids into batches (to avoid allocating the full dense matrix)\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "    \n",
    "        # For each user in the batch, extract their similarity row (sparse)\n",
    "        for user_id in batch_user_ids:\n",
    "            # Get user index in the user_similarity matrix\n",
    "            try:\n",
    "                u_idx = user_labels_index.get_loc(user_id)\n",
    "            except KeyError:\n",
    "                # If user_id is not found in user_labels\n",
    "                recommendations[user_id] = np.array(most_popular_items[:top_k_items])\n",
    "                continue\n",
    "    \n",
    "            # Extract row u_idx from user_similarity — shape (1, num_users) (sparse)\n",
    "            row_sparse = user_similarity[u_idx]  # submatrix (1, U)\n",
    "            # Convert it to a dense vector [U] for this user only\n",
    "            row_dense = row_sparse.to_dense().flatten()  # shape = [num_users]\n",
    "    \n",
    "            # Start with base `top_n_similar_users`\n",
    "            num_similar_users = top_n_similar_users\n",
    "            recommended_products = []\n",
    "            expansion_step = 0  # Number of expansion iterations\n",
    "    \n",
    "            # Check if dynamic expansion of top_n_similar_users is needed\n",
    "            while (len(recommended_products) < top_k_items \n",
    "                    and n_iter_x5_top_n_similar_users is not None \n",
    "                    and n_iter_x5_top_n_similar_users > 0 \n",
    "                    and expansion_step <= n_iter_x5_top_n_similar_users):\n",
    "    \n",
    "                # Find top-N similar users (dynamically increasing N)\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, num_similar_users + 1, dim=0)\n",
    "    \n",
    "                # Exclude the user themselves (similarity with self = 1)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask]\n",
    "    \n",
    "                # Convert similar user indices to user_ids\n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "                # user_bought = user_purchases.get(user_id)\n",
    "                # if not user_bought:\n",
    "                #     print(f\"[DEBUG] User {user_id} has no purchases in train\")\n",
    "                #     user_bought = set()\n",
    "    \n",
    "                # Collect unique items from similar users\n",
    "                product_counter = Counter()  # Count item frequencies among similar users\n",
    "    \n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    # Filter only if filter_already_purchased=True\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Update item counts\n",
    "    \n",
    "                # Take top-K most frequent items\n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "                if len(recommended_products) >= top_k_items:\n",
    "                    break  # Stop if enough items collected\n",
    "    \n",
    "                # Increase number of similar users by 5×\n",
    "                num_similar_users *= 5\n",
    "                expansion_step += 1\n",
    "    \n",
    "            # If n_iter_x5_top_n_similar_users=None → do not expand\n",
    "            if n_iter_x5_top_n_similar_users is None or n_iter_x5_top_n_similar_users <= 0:\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, top_n_similar_users + 1, dim=0)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask][:top_n_similar_users]\n",
    "    \n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "    \n",
    "                product_counter = Counter()\n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Update item counts\n",
    "    \n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "            # If not enough items → fill with popular items\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                # Use generator expression + islice for efficient cutoff\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items if p not in recommended_products and \n",
    "                     (p not in user_bought if filter_already_purchased else True)),  \n",
    "                    needed_items\n",
    "                ))\n",
    "                if len(additional_items) == 0:\n",
    "                    print(f\"[WARN] No fallback items available for user {user_id} after filtering\")\n",
    "                recommended_products.extend(additional_items)\n",
    "            # Safety check — final fallback\n",
    "            if not recommended_products:\n",
    "                print(f\"[Warning] Fallback failed for user {user_id}. Filling with top-{top_k_items} popular items.\")\n",
    "                recommended_products = most_popular_items[:top_k_items]\n",
    "            # Store result as np.array\n",
    "            recommendations[user_id] = np.array(list(recommended_products)[:top_k_items])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "612f2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'user_based' / 'user_recommendations_ubcf.pkl', \"rb\") as f:\n",
    "    user_recommendations_ubcf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf2811c5-4abb-46c5-8469-359c3bc21d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68484ede3634d01bc5fa50c99da0683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "# 1) Compute user similarity matrix on GPU\n",
    "user_similarity, user_labels = compute_user_similarity(train_df)\n",
    "\n",
    "# 2) Generate recommendations for all users\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ubcf = recommend_user_based_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 10],\n",
    "    user_similarity=user_similarity,\n",
    "    user_labels=user_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_users=n_iter_x5_top_n_similar_users\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'user_based' / 'user_recommendations_ubcf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_ubcf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f5fad0c-74ca-403f-8e7a-1a512c642b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ubcf = RecommendationDataset(user_recommendations=user_recommendations_ubcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ubcf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30715fd4-48dc-4dfb-b9dd-0adc7155fe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba34a3657ac45078d37e465cded0566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b45ed91de6b468b9420bf74739e3916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db6c1538f634aa4a30b205cd3bee29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff50e6b87ecc4061887108d49be11c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "\n",
    "log_model_results(model_name='UBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_users': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_users': n_iter_x5_top_n_similar_users})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab1e79-dc3b-4da9-bf3c-deeeacd47e72",
   "metadata": {},
   "source": [
    "### 4. Item-Based Collaborative Filtering (IBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0a7c584-a282-44da-88ce-b0da9e4455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20  # top_n_similar_items\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_items = 1\n",
    "# Important!!! If you're using a GPU desktop — comment out the line below\n",
    "device = torch.device(\"cpu\")  # Sparse ops on MPS (MacBook) are not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f436e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Returns a sparse matrix (csr_matrix) and index mappings \n",
    "    for users and products (user_labels, product_labels) in the exact order of factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'articul_encrypred_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Factorize users and products\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['articul_encrypred_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Create a sparse matrix (rows = users, columns = products)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "\n",
    "def compute_item_similarity(df):\n",
    "    \"\"\"\n",
    "    Creates a user-item matrix, applies log-smoothing to counts,\n",
    "    transposes it to (items x users), and computes cosine similarity between items.\n",
    "    Returns item_similarity (result of sparse.mm) and product_labels.\n",
    "    \"\"\"\n",
    "    # 1) Create the user-item matrix\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Apply log(1 + count) to reduce the influence of frequent purchases\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # 2) Convert to PyTorch sparse_coo_tensor\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    # user_item_matrix.shape = (num_users, num_items)\n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # 3) Transpose to get the item-user matrix (shape = num_items × num_users)\n",
    "    # In PyTorch, use sparse.transpose(dim0=0, dim1=1)\n",
    "    item_user_tensor = user_item_tensor.transpose(0, 1).coalesce()\n",
    "    \n",
    "    # 4) Normalize each row (i.e., item) for cosine similarity\n",
    "    # Compute L2 norm of each row\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(item_user_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Divide values by the norm of the corresponding row (item)\n",
    "    normalized_values = item_user_tensor.values() / row_norms[item_user_tensor.indices()[0]]\n",
    "    item_user_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        item_user_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=item_user_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # 5) Compute item-item similarity matrix: M * M^T\n",
    "    item_similarity = torch.sparse.mm(item_user_tensor_normalized, item_user_tensor_normalized.t())\n",
    "    \n",
    "    # Return item similarity matrix and product_labels\n",
    "    # (user_labels are not needed for item-based CF)\n",
    "    return item_similarity, product_labels\n",
    "\n",
    "\n",
    "def recommend_item_based_batch(\n",
    "    user_ids,\n",
    "    item_similarity,\n",
    "    item_labels,\n",
    "    df,\n",
    "    top_k_items=k,                  # Number of items to recommend\n",
    "    top_n_similar_items=n,          # Number of similar items to consider for each purchased item\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_items=None  # Same idea as n_iter_x5_top_n_similar_users\n",
    "):\n",
    "    \"\"\"\n",
    "    For a list of user_ids, returns item-based recommendations.\n",
    "    Similar to user-based, but instead of finding top-N similar users,\n",
    "    we find top-N similar items for each item purchased by the user.\n",
    "    \"\"\"\n",
    "    # For fast lookup of item index by articul_encrypred_id\n",
    "    item_labels_index = pd.Index(item_labels)\n",
    "    \n",
    "    # Dictionary of user purchases: anon_id_encrypred -> set(articul_encrypred_id)\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['articul_encrypred_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Dictionary: user_id -> list of recommended items\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Precompute most popular items (used as fallback)\n",
    "    most_popular_items_all = df['articul_encrypred_id'].value_counts().index.tolist()\n",
    "    \n",
    "    # Process user_ids in batches\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating Item-Based recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            user_bought = user_purchases.get(user_id, set())\n",
    "            if len(user_bought) == 0:\n",
    "                # If the user has no purchases, recommend popular items\n",
    "                needed_items = top_k_items\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if (p not in user_bought if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommendations[user_id] = np.array(additional_items)\n",
    "                continue\n",
    "            \n",
    "            product_counter = Counter()\n",
    "\n",
    "            valid_purchased_items = [item for item in user_bought if item in item_labels_index]\n",
    "            if not valid_purchased_items:\n",
    "                recommendations[user_id] = np.array(most_popular_items_all[:top_k_items])\n",
    "                continue\n",
    "            \n",
    "            # For each item the user has purchased, find similar items\n",
    "            for purchased_item in valid_purchased_items:\n",
    "                # Look up index of purchased_item in item_labels_index\n",
    "                try:\n",
    "                    i_idx = item_labels_index.get_loc(purchased_item)\n",
    "                except KeyError:\n",
    "                    # Skip if the item is not found in item_labels\n",
    "                    continue\n",
    "                \n",
    "                row_sparse = item_similarity[i_idx]  # submatrix (1, num_items) (sparse)\n",
    "                row_dense = row_sparse.to_dense().flatten()\n",
    "                \n",
    "                # Start with base top_n_similar_items\n",
    "                num_similar_items = top_n_similar_items\n",
    "                similar_items_list = []\n",
    "                expansion_step = 0\n",
    "                \n",
    "                # Same logic as user-based: expand until we gather top_k_items\n",
    "                while (len(similar_items_list) < top_k_items\n",
    "                       and n_iter_x5_top_n_similar_items is not None\n",
    "                       and n_iter_x5_top_n_similar_items > 0\n",
    "                       and expansion_step <= n_iter_x5_top_n_similar_items):\n",
    "                    \n",
    "                    # Get top-(num_similar_items+1)\n",
    "                    # (+1 to exclude the item itself, if included)\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, num_similar_items + 1, dim=0)\n",
    "                    \n",
    "                    # Remove the item itself if it's in the list\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask]\n",
    "                    \n",
    "                    # Convert indices to articul_encrypred_id\n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    \n",
    "                    # If filter_already_purchased=True, exclude already purchased items\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in valid_purchased_items:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                    \n",
    "                    if len(similar_items_list) >= top_k_items:\n",
    "                        break\n",
    "                    \n",
    "                    # Increase number of similar items 5×\n",
    "                    num_similar_items *= 5\n",
    "                    expansion_step += 1\n",
    "                \n",
    "                # If dynamic expansion is disabled\n",
    "                if n_iter_x5_top_n_similar_items is None or n_iter_x5_top_n_similar_items <= 0:\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, top_n_similar_items + 1, dim=0)\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask][:top_n_similar_items]\n",
    "                    \n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in valid_purchased_items:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                \n",
    "                # Count how often each similar item appears\n",
    "                product_counter.update(similar_items_list)\n",
    "            \n",
    "            # Select top-K items by frequency\n",
    "            recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "            \n",
    "            # If not enough recommendations → fill with popular items\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if p not in recommended_products and (p not in valid_purchased_items if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommended_products.extend(additional_items)\n",
    "\n",
    "            if not recommended_products:\n",
    "                print(f\"[Warning] Empty recommendation for user {user_id}. Fallback to top-{top_k_items} popular items.\")\n",
    "                recommended_products = most_popular_items_all[:top_k_items]\n",
    "            \n",
    "            recommendations[user_id] = np.array(recommended_products[:top_k_items])\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d5fbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'item_based' / 'user_recommendations_ibcf.pkl', \"rb\") as f:\n",
    "    user_recommendations_ibcf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db8a5888-09d1-4269-ba4f-7329f10aeec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34136970f6e9403d8fe98028e50aca09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Item-Based recommendations:   0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "batch_size = 8\n",
    "\n",
    "# 1) Compute item similarity matrix on GPU\n",
    "item_similarity, item_labels = compute_item_similarity(train_df)\n",
    "\n",
    "# 2) Generate recommendations for all users\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ibcf = recommend_item_based_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 30], # [:len(user_ids) // 50]\n",
    "    item_similarity=item_similarity,\n",
    "    item_labels=item_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_items=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_items=n_iter_x5_top_n_similar_users\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'item_based' / 'user_recommendations_ibcf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_ibcf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2c098fa-14ac-4395-b28c-68add56459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibcf = RecommendationDataset(user_recommendations=user_recommendations_ibcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ibcf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d3b920e-e22e-4424-a525-ba83016b7a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b3e4573c2c45b183ab3d63f67cb1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5120124f0a2248039340a418ec0f5b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3175f09826940d583cb39b251dba6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a26eaf728bd48c69cb4317d13e068d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "\n",
    "log_model_results(model_name='IBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_items': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_items': n_iter_x5_top_n_similar_items})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02406f-cf6c-4a83-b0a7-ecbea66cb300",
   "metadata": {},
   "source": [
    "### 5. Matrix Factorization (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93bdf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.9) # Memory usage limit for MacOS\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee142b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fe85a64-294d-4e05-b095-c8222a9ab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Returns a sparse matrix (csr_matrix) and index mappings \n",
    "    for users and products (user_labels, product_labels) in the exact order of factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'articul_encrypred_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Factorize users and products\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['articul_encrypred_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Create a sparse matrix (rows = users, columns = products)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb724ebc-b55a-4daa-8fe6-1aad44b89231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, latent_dim)\n",
    "        \n",
    "        # Initialize embeddings (e.g., Xavier uniform)\n",
    "        nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        user_indices: LongTensor (batch_size,)\n",
    "        item_indices: LongTensor (batch_size,)\n",
    "        Returns the predicted rating (dot product of embeddings).\n",
    "        \"\"\"\n",
    "        user_embedding = self.user_factors(user_indices)   # (batch_size, latent_dim)\n",
    "        item_embedding = self.item_factors(item_indices)   # (batch_size, latent_dim)\n",
    "        rating_pred = (user_embedding * item_embedding).sum(dim=1)  # (batch_size,)\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d21e0d00-734d-4118-a1a7-f2337c88fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matrix_factorization(\n",
    "    df,\n",
    "    latent_dim=256,\n",
    "    epochs=3,\n",
    "    lr=0.01,\n",
    "    batch_size=1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains matrix factorization (SVD with gradient descent) on the user-item matrix.\n",
    "    Returns the model along with user_labels and product_labels for inference.\n",
    "    \"\"\"\n",
    "    # Create the user-item matrix\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Apply logarithmic scaling to smooth the impact of large counts\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "\n",
    "    model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "    coo = user_item_matrix.tocoo()\n",
    "    user_indices = torch.tensor(coo.row, dtype=torch.long, device=device)\n",
    "    item_indices = torch.tensor(coo.col, dtype=torch.long, device=device)\n",
    "    ratings = torch.tensor(coo.data, dtype=torch.float32, device=device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(user_indices, item_indices, ratings)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Track loss\n",
    "    batch_losses = []\n",
    "    batch_avg_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Training Matrix Factorization (epochs)'):\n",
    "        total_loss = 0.0\n",
    "        epoch_losses = []\n",
    "        verbose = len(dataloader) // 10\n",
    "        for batch_idx, (batch_user, batch_item, batch_rating) in enumerate(tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}\")):\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_user, batch_item)\n",
    "            loss = criterion(preds, batch_rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "            # Log average loss every 50 batches\n",
    "            if (batch_idx + 1) % verbose == 0:\n",
    "                avg_loss = sum(epoch_losses[-50:]) / 50\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "                batch_avg_losses.append(avg_loss)\n",
    "                print(f\"Step {batch_idx + 1}, last AVG loss: {avg_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {total_loss:.4f}\")\n",
    "        batch_losses.extend(epoch_losses)\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(len(batch_avg_losses)), batch_avg_losses, label='Avg Loss per 50 batches', linewidth=2, color='royalblue', marker='o', markersize=4)\n",
    "    plt.xlabel('Logging step (every 50 batches)', fontsize=12)\n",
    "    plt.ylabel('MSE Loss', fontsize=12)\n",
    "    plt.title('Matrix Factorization Training Loss', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='best', fontsize=11)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, user_labels, product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "001adee4-6610-4e0d-9076-b92e0334da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_mf_batch(\n",
    "    user_ids,\n",
    "    model,\n",
    "    user_labels,\n",
    "    product_labels,\n",
    "    df,\n",
    "    top_k_items=10,\n",
    "    batch_size=1024,\n",
    "    filter_already_purchased=True\n",
    "):\n",
    "    \"\"\"\n",
    "    For a list of user_ids, returns recommendations based on matrix factorization.\n",
    "    Logic is similar to User-Based/Item-Based:\n",
    "      1) Predict scores for all items\n",
    "      2) If filter_already_purchased=True, exclude items already purchased by the user\n",
    "      3) Select top-K\n",
    "      4) If not enough, fill in with popular items\n",
    "    \"\"\"\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    product_labels_index = pd.Index(product_labels)\n",
    "\n",
    "    # Collect user purchases\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['articul_encrypred_id'].apply(set).to_dict()\n",
    "\n",
    "    # Most popular items (used as fallback)\n",
    "    most_popular_items = df['articul_encrypred_id'].value_counts().index.tolist()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating MF recommendations'):\n",
    "            batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "\n",
    "            # Convert user_ids to user_indices\n",
    "            valid_indices = []\n",
    "            valid_user_ids = []\n",
    "            for uid in batch_user_ids:\n",
    "                try:\n",
    "                    uidx = user_labels_index.get_loc(uid)\n",
    "                    valid_indices.append(uidx)\n",
    "                    valid_user_ids.append(uid)\n",
    "                except KeyError: \n",
    "                    # If the user is not in train_df — cold start, fallback to top-k popular items\n",
    "                    recommendations[uid] = np.array(most_popular_items[:top_k_items])\n",
    "            \n",
    "            if len(valid_indices) == 0:\n",
    "                continue  # All users in this batch are invalid\n",
    "\n",
    "            user_tensor = torch.tensor(valid_indices, dtype=torch.long, device=device)\n",
    "            item_tensor = torch.arange(len(product_labels), dtype=torch.long, device=device)\n",
    "\n",
    "            # Predict ratings for (batch_users x all items)\n",
    "            # Expand user_tensor to generate all combinations\n",
    "            # user_tensor.shape -> (batch_size_valid,)\n",
    "            # item_tensor.shape -> (num_items,)\n",
    "\n",
    "            # predictions.shape -> (batch_size_valid, num_items)\n",
    "            predictions = model(\n",
    "                user_tensor.unsqueeze(1).expand(-1, len(item_tensor)).flatten(),\n",
    "                item_tensor.repeat(len(user_tensor))\n",
    "            )\n",
    "            predictions = predictions.view(len(user_tensor), len(item_tensor))\n",
    "\n",
    "            # For each user, select top-K\n",
    "            for i, uid in enumerate(valid_user_ids):\n",
    "                user_bought = user_purchases.get(uid, set())\n",
    "\n",
    "                # If filter_already_purchased=True, exclude already purchased items\n",
    "                if filter_already_purchased:\n",
    "                    mask = torch.tensor(\n",
    "                        [product_labels[j] not in user_bought for j in range(len(product_labels))],\n",
    "                        dtype=torch.bool,\n",
    "                        device=device\n",
    "                    )\n",
    "                    # Assign -inf to filtered items\n",
    "                    predictions[i][~mask] = float('-inf')\n",
    "\n",
    "                # Select top-K\n",
    "                top_k_indices = torch.topk(predictions[i], top_k_items).indices\n",
    "                top_k_products = [product_labels[idx.item()] for idx in top_k_indices]\n",
    "\n",
    "                # If fewer than K recommendations (theoretically possible if filtering is too strong),\n",
    "                # fill with popular items (unlikely with MF due to many items)\n",
    "                if len(top_k_products) < top_k_items:\n",
    "                    needed = top_k_items - len(top_k_products)\n",
    "                    fallback = list(itertools.islice(\n",
    "                        (p for p in most_popular_items if p not in top_k_products and\n",
    "                         (p not in user_bought if filter_already_purchased else True)),\n",
    "                        needed\n",
    "                    ))\n",
    "\n",
    "                    # If fallback is still short, fill with just top popular items\n",
    "                    if top_k_items - len(top_k_products) - len(fallback) != 0:\n",
    "                        needed = top_k_items - len(top_k_products) - len(fallback)\n",
    "                        fallback = most_popular_items[:needed]\n",
    "                    top_k_products.extend(fallback)\n",
    "\n",
    "                recommendations[uid] = np.array(top_k_products[:top_k_items])\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0138a94e-7069-4832-8ccc-f3e61e421825",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_already_purchased = True\n",
    "latent_dim = 256\n",
    "batch_size = 1024\n",
    "epochs= 3\n",
    "lr= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a25dbef-1823-41f5-9773-80ba4e627d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899fa913d7d640438133b0a2c1f95a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Matrix Factorization (epochs):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5798cc63b6014ed09a2248d3df2f7eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 262, Avg Loss: 0.5103\n",
      "Step 262, last AVG loss: 0.5103\n",
      "Epoch 1, Batch 524, Avg Loss: 0.5090\n",
      "Step 524, last AVG loss: 0.5090\n",
      "Epoch 1, Batch 786, Avg Loss: 0.4891\n",
      "Step 786, last AVG loss: 0.4891\n",
      "Epoch 1, Batch 1048, Avg Loss: 0.4118\n",
      "Step 1048, last AVG loss: 0.4118\n",
      "Epoch 1, Batch 1310, Avg Loss: 0.3081\n",
      "Step 1310, last AVG loss: 0.3081\n",
      "Epoch 1, Batch 1572, Avg Loss: 0.2287\n",
      "Step 1572, last AVG loss: 0.2287\n",
      "Epoch 1, Batch 1834, Avg Loss: 0.1779\n",
      "Step 1834, last AVG loss: 0.1779\n",
      "Epoch 1, Batch 2096, Avg Loss: 0.1427\n",
      "Step 2096, last AVG loss: 0.1427\n",
      "Epoch 1, Batch 2358, Avg Loss: 0.1204\n",
      "Step 2358, last AVG loss: 0.1204\n",
      "Epoch 1, Batch 2620, Avg Loss: 0.1013\n",
      "Step 2620, last AVG loss: 0.1013\n",
      "Epoch 1/3, Total Loss: 828.4268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314f76b33d654c1b87b03ea689ab1334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 262, Avg Loss: 0.0431\n",
      "Step 262, last AVG loss: 0.0431\n",
      "Epoch 2, Batch 524, Avg Loss: 0.0406\n",
      "Step 524, last AVG loss: 0.0406\n",
      "Epoch 2, Batch 786, Avg Loss: 0.0385\n",
      "Step 786, last AVG loss: 0.0385\n",
      "Epoch 2, Batch 1048, Avg Loss: 0.0376\n",
      "Step 1048, last AVG loss: 0.0376\n",
      "Epoch 2, Batch 1310, Avg Loss: 0.0361\n",
      "Step 1310, last AVG loss: 0.0361\n",
      "Epoch 2, Batch 1572, Avg Loss: 0.0353\n",
      "Step 1572, last AVG loss: 0.0353\n",
      "Epoch 2, Batch 1834, Avg Loss: 0.0351\n",
      "Step 1834, last AVG loss: 0.0351\n",
      "Epoch 2, Batch 2096, Avg Loss: 0.0343\n",
      "Step 2096, last AVG loss: 0.0343\n",
      "Epoch 2, Batch 2358, Avg Loss: 0.0336\n",
      "Step 2358, last AVG loss: 0.0336\n",
      "Epoch 2, Batch 2620, Avg Loss: 0.0331\n",
      "Step 2620, last AVG loss: 0.0331\n",
      "Epoch 2/3, Total Loss: 97.1134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4442b71521344afc969dedc35436b42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 262, Avg Loss: 0.0222\n",
      "Step 262, last AVG loss: 0.0222\n",
      "Epoch 3, Batch 524, Avg Loss: 0.0209\n",
      "Step 524, last AVG loss: 0.0209\n",
      "Epoch 3, Batch 786, Avg Loss: 0.0202\n",
      "Step 786, last AVG loss: 0.0202\n",
      "Epoch 3, Batch 1048, Avg Loss: 0.0199\n",
      "Step 1048, last AVG loss: 0.0199\n",
      "Epoch 3, Batch 1310, Avg Loss: 0.0201\n",
      "Step 1310, last AVG loss: 0.0201\n",
      "Epoch 3, Batch 1572, Avg Loss: 0.0199\n",
      "Step 1572, last AVG loss: 0.0199\n",
      "Epoch 3, Batch 1834, Avg Loss: 0.0197\n",
      "Step 1834, last AVG loss: 0.0197\n",
      "Epoch 3, Batch 2096, Avg Loss: 0.0200\n",
      "Step 2096, last AVG loss: 0.0200\n",
      "Epoch 3, Batch 2358, Avg Loss: 0.0199\n",
      "Step 2358, last AVG loss: 0.0199\n",
      "Epoch 3, Batch 2620, Avg Loss: 0.0202\n",
      "Step 2620, last AVG loss: 0.0202\n",
      "Epoch 3/3, Total Loss: 53.7261\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_model, user_labels, product_labels = train_matrix_factorization(\n",
    "    train_df,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e48cf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFactorization(\n",
       "  (user_factors): Embedding(390237, 256)\n",
       "  (item_factors): Embedding(208758, 256)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(mf_model.state_dict(), models_dir / f'mf_model_latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}.pth')\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'user_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(user_labels, f)\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'product_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(product_labels, f)\n",
    "\n",
    "mf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84e0c5-4feb-4629-9828-eb0722ec9209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFactorization(\n",
       "  (user_factors): Embedding(370091, 512)\n",
       "  (item_factors): Embedding(267600, 512)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(models_outputs_dir / 'mf' / 'user_labels.pkl', \"rb\") as f:\n",
    "    user_labels = pickle.load(f)\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'product_labels.pkl', \"rb\") as f:\n",
    "    product_labels = pickle.load(f)\n",
    "\n",
    "# Reconstruct the model architecture\n",
    "num_users = len(user_labels)\n",
    "num_items = len(product_labels)\n",
    "\n",
    "mf_model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "# Load model weights\n",
    "mf_model.load_state_dict(torch.load(models_dir / f'mf_model_latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}.pth'))\n",
    "\n",
    "# Switch model to evaluation (inference) mode\n",
    "mf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4d94b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'mf' / 'user_recommendations_mf.pkl', \"rb\") as f:\n",
    "    user_recommendations_mf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c44d349a-ecb1-4827-b7dd-5545f7ee8e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e6a1d3d1c546d4bf75d83bebb956a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating MF recommendations:   0%|          | 0/8157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "user_recommendations_mf = recommend_mf_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 10],\n",
    "    model=mf_model,\n",
    "    user_labels=user_labels,\n",
    "    product_labels=product_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    batch_size=2,\n",
    "    filter_already_purchased=filter_already_purchased\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'user_recommendations_mf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_mf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1022f56b-2eaa-4714-aff5-82579d3b718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mf = RecommendationDataset(user_recommendations=user_recommendations_mf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_mf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1cc94cdf-56f6-4ad1-8dfb-5e46cc0940ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e8b4932eba4f7b85e5279598b40fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819d900c43a946b6869f78a51ed8c05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7d5b88637f408198c67dd0ccb514f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90fb36e4bce40449f24ac5efe023df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "\n",
    "log_model_results(model_name='Matrix Factorization', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'top_k_items': k, 'latent_dim': latent_dim, \n",
    "                                   'filter_already_purchased': filter_already_purchased})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324128d7-db5a-439e-b84a-1a7c4e60f824",
   "metadata": {},
   "source": [
    "## Strong Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dfcf5-3ad3-42cf-a453-6852d5bb70e8",
   "metadata": {},
   "source": [
    "### BERT4Rec (self-made)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab2e29",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1904.06690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b518c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4f64f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self, sequences, max_len, mask_prob, num_items, pad_token=0, mask_token=None, is_train=True, external_targets=None):\n",
    "        self.max_len = max_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.num_items = num_items\n",
    "        self.pad_token = pad_token\n",
    "        self.mask_token = mask_token if mask_token is not None else num_items + 1\n",
    "        self.is_train = is_train \n",
    "        self.external_targets = external_targets  # user_id -> true items (list or set)\n",
    "\n",
    "        self.user_ids = []\n",
    "        self.processed_sequences = []\n",
    "        \n",
    "        for user_id, seq in sequences:\n",
    "            self.user_ids.append(user_id)\n",
    "            truncated = seq[-self.max_len:] if len(seq) > self.max_len else seq\n",
    "            padded = truncated + [self.pad_token] * (self.max_len - len(truncated))  # RIGHT SIDE PADDING\n",
    "            self.processed_sequences.append(padded)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.user_ids[idx]\n",
    "        seq = self.processed_sequences[idx].copy()\n",
    "\n",
    "        # === Validation Mode ===\n",
    "        if not self.is_train and self.external_targets is not None:\n",
    "            input_seq = seq\n",
    "            true_items = list(self.external_targets.get(user_id, []))[:self.max_len]\n",
    "\n",
    "            # RIGHT SIDE PADDING for labels\n",
    "            padded_labels = true_items + [-100] * (self.max_len - len(true_items))  # -100 — default ignore_index (also default in CrossEntropyLoss)\n",
    "            labels = torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "            attention_mask = [1 if x != self.pad_token else 0 for x in input_seq]\n",
    "            position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "            return {\n",
    "                \"user_id\": user_id,\n",
    "                \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "                \"labels\": labels,\n",
    "                \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "                \"position_ids\": position_ids\n",
    "            }\n",
    "\n",
    "\n",
    "        # === Train Mode (with guarantee min_masked = 1) ===\n",
    "        input_seq = seq.copy()\n",
    "        target_seq = [-100] * self.max_len\n",
    "\n",
    "        candidate_idxs = [i for i, token in enumerate(seq) if token != self.pad_token]\n",
    "        masked_idxs = [i for i in candidate_idxs if random.random() < self.mask_prob]\n",
    "\n",
    "        # === min_masked = 1 ===\n",
    "        if len(masked_idxs) == 0 and len(candidate_idxs) > 0:\n",
    "            masked_idxs = [random.choice(candidate_idxs)]\n",
    "\n",
    "        for i in masked_idxs: # 90, 9, 1\n",
    "            original_token = seq[i]\n",
    "            prob = random.random()\n",
    "            if prob < 0.9:\n",
    "                input_seq[i] = self.mask_token\n",
    "            elif prob < 0.99:\n",
    "                input_seq[i] = random.randint(1, self.num_items)\n",
    "            else:\n",
    "                input_seq[i] = original_token\n",
    "            target_seq[i] = original_token\n",
    "\n",
    "        attention_mask = [1 if x != self.pad_token else 0 for x in input_seq]\n",
    "        position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"user_id\": user_id,\n",
    "            \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(target_seq, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"position_ids\": position_ids\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "117f009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield {\n",
    "                k: v.to(self.device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in batch.items()\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c59bd4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2044926, 7)\n",
      "Test shape: (372108, 7)\n",
      "\n",
      "Total number of users: 74590\n",
      "Number of users in the training set: 73597\n",
      "Number of users in the test set: 52415\n",
      "\n",
      "Total number of 'articul_encrypred_idx': 216575\n",
      "Number of 'articul_encrypred_idx' in the training set: 197508\n",
      "Number of 'articul_encrypred_idx' in the test set: 93643\n"
     ]
    }
   ],
   "source": [
    "# df_sales_articul['order_date'] = pd.to_datetime(df_sales_articul['order_date'])\n",
    "# df_sales_articul = df_sales_articul.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# # # Leave only users with 10+ purchases (for decreasing the noise)\n",
    "# # user_counts = df_sales_articul['anon_id_encrypred'].value_counts()\n",
    "# # active_users = user_counts[user_counts >= 10].index\n",
    "# # df_sales_articul = df_sales_articul[df_sales_articul['anon_id_encrypred'].isin(active_users)]\n",
    "\n",
    "# # Index mapping\n",
    "# unique_articul_encrypred_id = df_sales_articul['articul_encrypred_id'].unique()\n",
    "# articul_encrypred_id_to_idx = {pid: idx + 1 for idx, pid in enumerate(unique_articul_encrypred_id)} # + 1 for PAD zero token (0)\n",
    "# df_sales_articul['articul_encrypred_idx'] = df_sales_articul['articul_encrypred_id'].map(articul_encrypred_id_to_idx)\n",
    "\n",
    "# # Train/Test time split\n",
    "# threshold_level = 0.85\n",
    "# min_date = df_sales_articul['order_date'].min()\n",
    "# max_date = df_sales_articul['order_date'].max()\n",
    "\n",
    "# print(f\"Min date: {min_date}\")\n",
    "# print(f\"Max date: {max_date}\")\n",
    "\n",
    "# total_days = (max_date - min_date).days\n",
    "# threshold_days = int(total_days * threshold_level)\n",
    "# threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "# print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "# train_df = df_sales_articul[df_sales_articul['order_date'] < threshold_date]\n",
    "# test_df = df_sales_articul[df_sales_articul['order_date'] >= threshold_date]\n",
    "\n",
    "# df_sales_articul.to_csv(interim_data_dir / 'df_sales_articul.csv', index=False)\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_threshold_date.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_threshold_date.csv', index=False)\n",
    "\n",
    "df_sales_articul = pd.read_csv(interim_data_dir / 'df_sales_articul.csv')\n",
    "train_df = pd.read_csv(interim_data_dir / 'train_data_by_threshold_date.csv')\n",
    "test_df = pd.read_csv(interim_data_dir / 'test_data_by_threshold_date.csv')\n",
    "# Reconstructing the articul_encrypred_id_to_idx dictionary from the dataframe\n",
    "articul_encrypred_id_to_idx = dict(df_sales_articul[['articul_encrypred_id', 'articul_encrypred_idx']].drop_duplicates().values)\n",
    "num_items = len(articul_encrypred_id_to_idx)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print()\n",
    "print(f\"Total number of users: {len(df_sales_articul['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the training set: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the test set: {len(test_df['anon_id_encrypred'].unique())}\")\n",
    "print()\n",
    "print(f\"Total number of 'articul_encrypred_idx': {len(df_sales_articul['articul_encrypred_idx'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred_idx' in the training set: {len(train_df['articul_encrypred_idx'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred_idx' in the test set: {len(test_df['articul_encrypred_idx'].unique())}\")\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['articul_encrypred_idx'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b8bd7fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sequence for user wyyypqqtpqppptqt: [1, 2, 3, 4, 5, 6, 7]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by users and compute the sequence length for each\n",
    "# user_sequence_lengths = df_sales_articul.groupby('anon_id_encrypred').size()\n",
    "# percentiles = user_sequence_lengths.quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "\n",
    "# print(\"Sequence length percentiles:\")\n",
    "# print(percentiles)\n",
    "# print(f\"Maximum sequence length: {user_sequence_lengths.max()}\\n\\n\\n\")\n",
    "\n",
    "# Create purchase sequences for each user\n",
    "train_sequences = train_df.groupby('anon_id_encrypred')['articul_encrypred_idx'].apply(list).to_dict()\n",
    "test_sequences = test_df.groupby('anon_id_encrypred')['articul_encrypred_idx'].apply(list).to_dict()\n",
    "\n",
    "print(f\"Example sequence for user {list(train_sequences.keys())[0]}: {train_sequences[list(train_sequences.keys())[0]]}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "88217c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One object from `train_loader`\n",
      "User ID: wyyysqqtqpttxuqt\n",
      "Input IDs: tensor([ 11312,  11330,   2244, 126209, 141964,  13237,  45124, 216576,  38941,\n",
      "        165877,  63206,  32832, 216576,   6779,  24519,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n",
      "Labels: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100, 26350,  -100,  -100,\n",
      "         -100,  -100, 27552,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Position IDs: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24])\n",
      "\n",
      "One object from `test_dataset`\n",
      "User ID: wyyypqqtpqppptqt\n",
      "Input IDs: tensor([1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Labels: tensor([   8,    9,   10,   11,   12, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Position IDs: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24])\n",
      "Index: 1 → Articul: 74483\n",
      "Index: 2 → Articul: 34824\n",
      "Index: 3 → Articul: 200663\n",
      "Index: 4 → Articul: 46233\n",
      "Index: 5 → Articul: 85172\n",
      "Index: 6 → Articul: 53712\n",
      "Index: 7 → Articul: 101105\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n",
      "PAD\n"
     ]
    }
   ],
   "source": [
    "max_len = 25 # Maximum sequence length\n",
    "mask_prob = 0.25 # Masking probability\n",
    "batch_size = 32\n",
    "\n",
    "# Convert sequence dictionaries to list of tuples (user_id, sequence)\n",
    "train_sequences_list = list(train_sequences.items())\n",
    "test_sequences_list = list(test_sequences.items())\n",
    "\n",
    "train_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,     # <-- train for inputs\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=False,\n",
    "    external_targets=test_sequences  # <-- targets from test_df\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,)\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print('One object from `train_loader`')\n",
    "    user_ids = batch['user_id'][0]\n",
    "    input_ids = batch['input_ids'][0]\n",
    "    labels = batch['labels'][0]\n",
    "    attention_mask = batch['attention_mask'][0]\n",
    "    position_ids = batch['position_ids'][0]\n",
    "    \n",
    "    print(\"User ID:\", user_ids)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Position IDs:\", position_ids)\n",
    "    break \n",
    "\n",
    "print()\n",
    "\n",
    "for batch in test_loader:\n",
    "    print('One object from `test_dataset`')\n",
    "    user_ids = batch['user_id'][0]\n",
    "    input_ids = batch['input_ids'][0]\n",
    "    labels = batch['labels'][0]\n",
    "    attention_mask = batch['attention_mask'][0]\n",
    "    position_ids = batch['position_ids'][0]\n",
    "    \n",
    "    print(\"User ID:\", user_ids)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Position IDs:\", position_ids)\n",
    "\n",
    "    idx_to_articul = {v: k for k, v in articul_encrypred_id_to_idx.items()}\n",
    "    for idx in input_ids.tolist():\n",
    "        if idx == 0:\n",
    "            print(\"PAD\")\n",
    "        elif idx == num_items + 1:\n",
    "            print(\"MASK\")\n",
    "        else:\n",
    "            print(f\"Index: {idx} → Articul: {idx_to_articul[idx]}\")\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c8a1de09-39a3-416c-a436-ffbc2c817c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    num_epochs: int = 5,\n",
    "    log_interval: int = 50,\n",
    "    scheduler = None,\n",
    "    label_smoothing = 0.1\n",
    "):\n",
    "    # If loss == ln(num_items) -> predictions are random\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100, label_smoothing=label_smoothing)  # label_smoothing=0.1 softens targets\n",
    "    best_val_loss = float(\"inf\")\n",
    "    num_items = model.num_items\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running, acc_steps = 0.0, 0\n",
    "        for n, p in model.named_parameters():\n",
    "            assert torch.all(torch.isfinite(p)), f\"NaN in parameter {n}\"\n",
    "\n",
    "        # wrap loader with tqdm and use enumerate over it\n",
    "        pbar_train = tqdm(train_loader, total=len(train_loader), desc=f\"[Epoch {epoch}/{num_epochs}] Train\")\n",
    "        for batch_idx, batch in enumerate(pbar_train, 1):\n",
    "            try:\n",
    "                input_ids = batch['input_ids'] # no .to(device) cause DeviceDataLoader\n",
    "                attention_mask = batch['attention_mask']\n",
    "                position_ids = batch['position_ids']\n",
    "                labels = batch['labels']\n",
    "\n",
    "                # === ✅ EXTRA CHECK BEFORE LOSS ===\n",
    "                # print(f\"[Batch {batch_idx}] input_ids: min={input_ids.min().item()}, max={input_ids.max().item()}\")\n",
    "                # print(f\"[Batch {batch_idx}] labels:    min={labels[labels != -100].min().item() if (labels != -100).any() else 'n/a'}, \"\n",
    "                #     f\"max={labels[labels != -100].max().item() if (labels != -100).any() else 'n/a'}\")\n",
    "\n",
    "                # Validate label values\n",
    "                assert torch.all((labels == -100) | ((labels > 0) & (labels < num_items + 1))), \\\n",
    "                    f\"Invalid label value found! batch_idx={batch_idx}\"\n",
    "\n",
    "                assert input_ids.max() < num_items + 2, f\"input_ids contain invalid token! batch_idx={batch_idx}\"\n",
    "\n",
    "                if not (labels != -100).any():\n",
    "                    print(f\"[Batch {batch_idx}] All masked, skipping\")\n",
    "                    pbar_train.update(1)\n",
    "                    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(input_ids, attention_mask, position_ids)\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "\n",
    "                if not torch.isfinite(loss):\n",
    "                    print(f\"!!! NaN loss at epoch {epoch} batch {batch_idx}\")\n",
    "\n",
    "                    for name, p in model.named_parameters():\n",
    "                        if not torch.all(torch.isfinite(p)):\n",
    "                            bad = (~torch.isfinite(p)).sum().item()\n",
    "                            print(f\"  → {name}: {bad} bad entries\")\n",
    "                    raise RuntimeError(\"Stop: loss became NaN\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "                running += loss.item()\n",
    "                acc_steps += 1\n",
    "\n",
    "                if batch_idx == 1 or (batch_idx % (log_interval // 5) == 0):\n",
    "                    avg = running / acc_steps\n",
    "                    pbar_train.set_postfix(batch_loss=f\"{avg:.4f}\")\n",
    "\n",
    "                # log the first n / every log_interval\n",
    "                if batch_idx == 1 or (batch_idx % log_interval == 0):\n",
    "                    avg = running / acc_steps\n",
    "                    pbar_train.set_postfix(batch_loss=f\"{avg:.4f}\")\n",
    "                    train_loss_history.append(avg)\n",
    "                    wandb.log({\n",
    "                        \"train/loss\": avg,\n",
    "                        \"train/lr\": scheduler.get_last_lr()[0] if scheduler else optimizer.param_groups[0][\"lr\"],\n",
    "                        \"epoch\": epoch,\n",
    "                        \"step\": (epoch - 1) * len(train_loader) + batch_idx\n",
    "                    })\n",
    "                    current_lr = scheduler.get_last_lr()[0] if scheduler is not None else float('nan')\n",
    "                    valid_tokens = (labels != -100).sum().item()\n",
    "                    masked_ratio = valid_tokens / labels.numel()\n",
    "                    preds = outputs.argmax(dim=-1)\n",
    "                    correct = ((preds == labels) & (labels != -100)).sum().item()\n",
    "                    accuracy = correct / valid_tokens if valid_tokens else 0.0\n",
    "                    max_grad = max(p.grad.abs().max().item() for p in model.parameters() if p.grad is not None)\n",
    "                \n",
    "                    print(\n",
    "                        f\"[Batch {batch_idx}] \"\n",
    "                        f\"train/loss={avg};\\n\"\n",
    "                        f\"input_ids={input_ids.shape}, labels={labels.shape}, outputs={outputs.shape};\\n\"\n",
    "                        f\"lr={current_lr:.8f}, \"\n",
    "                        f\"valid_tokens={valid_tokens}, masked_ratio={masked_ratio:.2%}, \"\n",
    "                        f\"accuracy={accuracy:.2%}, max_grad={max_grad:.4f}\\n\"\n",
    "                    )\n",
    "                    running, acc_steps = 0.0, 0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error at batch {batch_idx}: {e}\")\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        # val_running = 0.0\n",
    "        val_running, val_batches = 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar_val = tqdm(val_loader, total=len(val_loader), desc=f\"[Epoch {epoch}/{num_epochs}] Val  \")\n",
    "            for batch in pbar_val:\n",
    "                input_ids = batch['input_ids'] # no .to(device) cause DeviceDataLoader\n",
    "                attention_mask = batch['attention_mask']\n",
    "                position_ids = batch['position_ids']\n",
    "                labels = batch['labels']\n",
    "\n",
    "                if (labels != -100).any(): # valid targets exist\n",
    "                    outputs = model(input_ids, attention_mask, position_ids)\n",
    "                    loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "                    val_running += loss.item()\n",
    "                    val_batches += 1\n",
    "                    pbar_val.set_postfix(val_loss=f\"{loss.item():.4f}\")\n",
    "                else:\n",
    "                    pbar_val.set_postfix(val_loss=\"skip\")\n",
    "\n",
    "        avg_val = val_running / val_batches if val_batches else float(\"nan\")\n",
    "        val_loss_history.append(avg_val)\n",
    "        print(f\"Epoch {epoch}: val_loss = {avg_val:.4f}\")\n",
    "\n",
    "        # save best model\n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            wandb.save(str(save_path))\n",
    "            print(f\"→ saved new best model  (val_loss {best_val_loss:.4f})\\n\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"val/loss\": avg_val,\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return model, train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "58fffa3b-2db5-4672-913d-e5c79ea47649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_loss(losses, log_interval, name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if log_interval:\n",
    "        x = [i * log_interval for i in range(len(losses))]\n",
    "    else:\n",
    "        x = [i + 1 for i in range(len(losses))]\n",
    "    \n",
    "    plt.plot(x, losses, label='Loss', marker='o', color='blue', linestyle='-', linewidth=2, markersize=5)\n",
    "    \n",
    "    plt.title(name, fontsize=16)\n",
    "    plt.xlabel('Batches', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db789e35-1a7a-4cc8-ac36-e7c13589587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "num_layers = 8\n",
    "num_heads = 4\n",
    "ffn_dim = 2048\n",
    "dropout = 0.2\n",
    "lr = 1e-5\n",
    "log_interval = max(1, len(train_loader) // 20)\n",
    "num_epochs = 5\n",
    "weight_decay = 1e-3\n",
    "\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac253c",
   "metadata": {},
   "source": [
    "#### BERT4Rec Base (self-made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "735c4fde-5420-49ab-b517-b5ac14a445de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_items,\n",
    "            max_len,\n",
    "            embedding_dim=256,\n",
    "            num_layers=6,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            ffn_dim=1024\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim # Dim of item vectors\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len # Of purchase seq\n",
    "\n",
    "        # PAD = 0; items = (1, 2, ..., num_items-1, num_items); MASK = num_items+1\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2, embedding_dim, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Project back to embedding_dim for dot-product with item embeddings\n",
    "        self.fc_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim * 2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim * 2),\n",
    "            nn.Linear(embedding_dim * 2, embedding_dim, bias=False),\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "        )\n",
    "\n",
    "        # bias for vocabulary logits\n",
    "        self.vocab_bias = nn.Parameter(torch.zeros(num_items + 2))\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # embs\n",
    "        nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
    "        nn.init.normal_(self.position_embeddings.weight, 0.0, 0.02)\n",
    "\n",
    "        # transformer\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "\n",
    "        # heads\n",
    "        nn.init.xavier_uniform_(self.fc_head[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc_head[3].weight)\n",
    "        nn.init.zeros_(self.vocab_bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        B, L = input_ids.size() # (B, L)\n",
    "\n",
    "        # 1) Embeddings + scale\n",
    "        item_embeds = self.item_embeddings(input_ids) # (B, L, embedding_dim)\n",
    "        pos_embeds  = self.position_embeddings(position_ids) # (L, embedding_dim) → broadcast → (B, L, embedding_dim)\n",
    "        x = (item_embeds + pos_embeds) * math.sqrt(self.embedding_dim) # (B, L, embedding_dim)\n",
    "        x = self.layer_norm(x) # (B, L, embedding_dim)\n",
    "        x = self.dropout(x) # (B, L, embedding_dim)\n",
    "\n",
    "        # 2) Causal + padding masks\n",
    "        src_key_padding_mask = (attention_mask == 0)  # (B, L)\n",
    "\n",
    "        # 3) Transformer\n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask) # (B, L, embedding_dim)\n",
    "\n",
    "        # 4) Head → back to embedding space\n",
    "        h = self.fc_head(x) # (B, L, embedding_dim)\n",
    "\n",
    "        # 5) Dot-product with item_embeddings + bias → logits\n",
    "        logits = torch.matmul(h, self.item_embeddings.weight.T) # (B, L, num_items + 2), weight tying\n",
    "        logits = logits + self.vocab_bias # (B, L, num_items + 2)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347caca-e80e-413c-8b1a-0963c5debeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/emtbmrhx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3b89caa40>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_base = BERT4RecModel(\n",
    "    num_items=num_items,\n",
    "    max_len=max_len,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    ffn_dim=ffn_dim,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(bert4rec_base.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = LambdaLR(optimizer,\n",
    "    lr_lambda=lambda step: (step / warmup_steps if step < warmup_steps \n",
    "                            else max(0.0, (total_steps - step) / float(max(1, total_steps - warmup_steps)))\n",
    "    )\n",
    ")\n",
    "\n",
    "save_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}.pth'\n",
    "save_path_last_batch = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}_last_batch.pth'\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Recommender_System_with_LLM\",\n",
    "    name=f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}',\n",
    "    config={\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"ffn_dim\": ffn_dim,\n",
    "        \"dropout\": dropout,\n",
    "        \"max_len\": max_len,\n",
    "        \"mask_prob\": mask_prob,\n",
    "        \"scheduler\": \"linear with warmup\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "07196eb4-b595-40fd-b09d-e59cb716234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4RecModel(\n",
       "  (item_embeddings): Embedding(216577, 512, padding_idx=0)\n",
       "  (position_embeddings): Embedding(25, 512)\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ea69b8-e4a1-430d-9dfa-04fec892529b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121a7f3fc0ce4f6c9e15ceb72c569158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1/5] Train:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] train/loss=12.286033630371094;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000009, valid_tokens=145, masked_ratio=18.12%, accuracy=0.00%, max_grad=0.0380\n",
      "\n",
      "[Batch 115] train/loss=12.282063919201232;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001000, valid_tokens=134, masked_ratio=16.75%, accuracy=0.00%, max_grad=0.0332\n",
      "\n",
      "[Batch 230] train/loss=12.162782063691512;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002000, valid_tokens=145, masked_ratio=18.12%, accuracy=0.00%, max_grad=0.0270\n",
      "\n",
      "[Batch 345] train/loss=11.942798141811204;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003000, valid_tokens=152, masked_ratio=19.00%, accuracy=0.00%, max_grad=0.0185\n",
      "\n",
      "[Batch 460] train/loss=11.917203463678774;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004000, valid_tokens=121, masked_ratio=15.12%, accuracy=0.00%, max_grad=0.0242\n",
      "\n",
      "[Batch 575] train/loss=11.833712254399838;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005000, valid_tokens=140, masked_ratio=17.50%, accuracy=0.71%, max_grad=0.0296\n",
      "\n",
      "[Batch 690] train/loss=11.786158122187075;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006000, valid_tokens=128, masked_ratio=16.00%, accuracy=0.78%, max_grad=0.0267\n",
      "\n",
      "[Batch 805] train/loss=11.768983583864959;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007000, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0403\n",
      "\n",
      "[Batch 920] train/loss=11.749068649955419;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008000, valid_tokens=139, masked_ratio=17.38%, accuracy=0.72%, max_grad=0.0442\n",
      "\n",
      "[Batch 1035] train/loss=11.758872322414232;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009000, valid_tokens=156, masked_ratio=19.50%, accuracy=0.00%, max_grad=0.0321\n",
      "\n",
      "[Batch 1150] train/loss=11.748592915742293;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00010000, valid_tokens=147, masked_ratio=18.38%, accuracy=0.00%, max_grad=0.0497\n",
      "\n",
      "[Batch 1265] train/loss=11.739539942534073;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009889, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0229\n",
      "\n",
      "[Batch 1380] train/loss=11.72164653280507;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009778, valid_tokens=140, masked_ratio=17.50%, accuracy=0.00%, max_grad=0.0352\n",
      "\n",
      "[Batch 1495] train/loss=11.696992102913235;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009667, valid_tokens=158, masked_ratio=19.75%, accuracy=0.63%, max_grad=0.0283\n",
      "\n",
      "[Batch 1610] train/loss=11.693230065055516;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009556, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0190\n",
      "\n",
      "[Batch 1725] train/loss=11.692613245093304;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009444, valid_tokens=157, masked_ratio=19.62%, accuracy=0.00%, max_grad=0.0328\n",
      "\n",
      "[Batch 1840] train/loss=11.69487244979195;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009333, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0890\n",
      "\n",
      "[Batch 1955] train/loss=11.653986582548722;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009222, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0479\n",
      "\n",
      "[Batch 2070] train/loss=11.642408097308614;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009111, valid_tokens=138, masked_ratio=17.25%, accuracy=0.72%, max_grad=0.0629\n",
      "\n",
      "[Batch 2185] train/loss=11.66180421580439;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00009000, valid_tokens=130, masked_ratio=16.25%, accuracy=0.77%, max_grad=0.0199\n",
      "\n",
      "[Batch 2300] train/loss=11.65456596042799;\n",
      "input_ids=torch.Size([29, 25]), labels=torch.Size([29, 25]), outputs=torch.Size([29, 25, 216577]);\n",
      "lr=0.00008889, valid_tokens=121, masked_ratio=16.69%, accuracy=0.00%, max_grad=0.0211\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9ce9cfd6484e418eea037e71570da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1/5] Val  :   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss = 12.4880\n",
      "→ saved new best model  (val_loss 12.4880)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946edf61228d4651aee49ff417dac70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2/5] Train:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] train/loss=11.38833236694336;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008888, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.1150\n",
      "\n",
      "[Batch 115] train/loss=11.523399001673647;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008778, valid_tokens=146, masked_ratio=18.25%, accuracy=0.00%, max_grad=0.0216\n",
      "\n",
      "[Batch 230] train/loss=11.52868715369183;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008667, valid_tokens=138, masked_ratio=17.25%, accuracy=0.00%, max_grad=0.0378\n",
      "\n",
      "[Batch 345] train/loss=11.513125718158225;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008556, valid_tokens=130, masked_ratio=16.25%, accuracy=0.00%, max_grad=0.0444\n",
      "\n",
      "[Batch 460] train/loss=11.515286992943805;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008444, valid_tokens=152, masked_ratio=19.00%, accuracy=0.00%, max_grad=0.0321\n",
      "\n",
      "[Batch 575] train/loss=11.504013409821884;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008333, valid_tokens=135, masked_ratio=16.88%, accuracy=0.00%, max_grad=0.0332\n",
      "\n",
      "[Batch 690] train/loss=11.51267497021219;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008222, valid_tokens=148, masked_ratio=18.50%, accuracy=0.00%, max_grad=0.0328\n",
      "\n",
      "[Batch 805] train/loss=11.503584579799487;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008111, valid_tokens=129, masked_ratio=16.12%, accuracy=0.00%, max_grad=0.0381\n",
      "\n",
      "[Batch 920] train/loss=11.481888331537661;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00008000, valid_tokens=105, masked_ratio=13.12%, accuracy=0.00%, max_grad=0.0231\n",
      "\n",
      "[Batch 1035] train/loss=11.481312353714653;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007889, valid_tokens=132, masked_ratio=16.50%, accuracy=0.00%, max_grad=0.0392\n",
      "\n",
      "[Batch 1150] train/loss=11.498976516723634;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007778, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0346\n",
      "\n",
      "[Batch 1265] train/loss=11.483595168072245;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007667, valid_tokens=166, masked_ratio=20.75%, accuracy=0.00%, max_grad=0.0517\n",
      "\n",
      "[Batch 1380] train/loss=11.472489473094111;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007556, valid_tokens=134, masked_ratio=16.75%, accuracy=0.00%, max_grad=0.0252\n",
      "\n",
      "[Batch 1495] train/loss=11.460352342025093;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007444, valid_tokens=136, masked_ratio=17.00%, accuracy=0.74%, max_grad=0.0349\n",
      "\n",
      "[Batch 1610] train/loss=11.444532137331755;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007333, valid_tokens=128, masked_ratio=16.00%, accuracy=0.00%, max_grad=0.0495\n",
      "\n",
      "[Batch 1725] train/loss=11.419539642333984;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007222, valid_tokens=136, masked_ratio=17.00%, accuracy=0.00%, max_grad=0.0294\n",
      "\n",
      "[Batch 1840] train/loss=11.403231048583985;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007111, valid_tokens=145, masked_ratio=18.12%, accuracy=0.00%, max_grad=0.0289\n",
      "\n",
      "[Batch 1955] train/loss=11.38632353907046;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00007000, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0427\n",
      "\n",
      "[Batch 2070] train/loss=11.380942601742952;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006889, valid_tokens=123, masked_ratio=15.38%, accuracy=0.00%, max_grad=0.0467\n",
      "\n",
      "[Batch 2185] train/loss=11.378105578215227;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006778, valid_tokens=145, masked_ratio=18.12%, accuracy=0.00%, max_grad=0.0230\n",
      "\n",
      "[Batch 2300] train/loss=11.348129230996836;\n",
      "input_ids=torch.Size([29, 25]), labels=torch.Size([29, 25]), outputs=torch.Size([29, 25, 216577]);\n",
      "lr=0.00006667, valid_tokens=113, masked_ratio=15.59%, accuracy=0.88%, max_grad=0.0419\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedc15e5983b479c822f9a2228396f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2/5] Val  :   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_loss = 12.3291\n",
      "→ saved new best model  (val_loss 12.3291)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66fd196421b43a8ab4b14b73e5f6c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3/5] Train:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] train/loss=11.48248291015625;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006666, valid_tokens=118, masked_ratio=14.75%, accuracy=0.00%, max_grad=0.0348\n",
      "\n",
      "[Batch 115] train/loss=11.257056621083041;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006556, valid_tokens=127, masked_ratio=15.88%, accuracy=0.00%, max_grad=0.0295\n",
      "\n",
      "[Batch 230] train/loss=11.243620814447818;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006444, valid_tokens=135, masked_ratio=16.88%, accuracy=0.00%, max_grad=0.0189\n",
      "\n",
      "[Batch 345] train/loss=11.23104371609895;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006333, valid_tokens=171, masked_ratio=21.38%, accuracy=0.00%, max_grad=0.0379\n",
      "\n",
      "[Batch 460] train/loss=11.225878657465396;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006222, valid_tokens=154, masked_ratio=19.25%, accuracy=0.00%, max_grad=0.0414\n",
      "\n",
      "[Batch 575] train/loss=11.209186993474546;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006111, valid_tokens=130, masked_ratio=16.25%, accuracy=0.00%, max_grad=0.0303\n",
      "\n",
      "[Batch 690] train/loss=11.23260563560154;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00006000, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0417\n",
      "\n",
      "[Batch 805] train/loss=11.193895771192468;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005889, valid_tokens=133, masked_ratio=16.62%, accuracy=0.75%, max_grad=0.0489\n",
      "\n",
      "[Batch 920] train/loss=11.212693081731382;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005778, valid_tokens=148, masked_ratio=18.50%, accuracy=0.68%, max_grad=0.0326\n",
      "\n",
      "[Batch 1035] train/loss=11.194886721735415;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005667, valid_tokens=125, masked_ratio=15.62%, accuracy=0.00%, max_grad=0.0405\n",
      "\n",
      "[Batch 1150] train/loss=11.185881399071734;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005556, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0270\n",
      "\n",
      "[Batch 1265] train/loss=11.17119894442351;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005444, valid_tokens=133, masked_ratio=16.62%, accuracy=0.00%, max_grad=0.0455\n",
      "\n",
      "[Batch 1380] train/loss=11.170567280313243;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005333, valid_tokens=139, masked_ratio=17.38%, accuracy=0.00%, max_grad=0.0348\n",
      "\n",
      "[Batch 1495] train/loss=11.177231340822965;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005222, valid_tokens=149, masked_ratio=18.62%, accuracy=0.00%, max_grad=0.0238\n",
      "\n",
      "[Batch 1610] train/loss=11.147174097144086;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005111, valid_tokens=126, masked_ratio=15.75%, accuracy=0.00%, max_grad=0.0286\n",
      "\n",
      "[Batch 1725] train/loss=11.16610453232475;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00005000, valid_tokens=147, masked_ratio=18.38%, accuracy=0.00%, max_grad=0.0434\n",
      "\n",
      "[Batch 1840] train/loss=11.146340079929518;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004889, valid_tokens=140, masked_ratio=17.50%, accuracy=0.00%, max_grad=0.0456\n",
      "\n",
      "[Batch 1955] train/loss=11.146525167382281;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004778, valid_tokens=118, masked_ratio=14.75%, accuracy=0.00%, max_grad=0.0462\n",
      "\n",
      "[Batch 2070] train/loss=11.121201365926991;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004667, valid_tokens=144, masked_ratio=18.00%, accuracy=0.00%, max_grad=0.0326\n",
      "\n",
      "[Batch 2185] train/loss=11.09901303001072;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004556, valid_tokens=124, masked_ratio=15.50%, accuracy=0.00%, max_grad=0.0216\n",
      "\n",
      "[Batch 2300] train/loss=11.108715015908945;\n",
      "input_ids=torch.Size([29, 25]), labels=torch.Size([29, 25]), outputs=torch.Size([29, 25, 216577]);\n",
      "lr=0.00004444, valid_tokens=130, masked_ratio=17.93%, accuracy=0.77%, max_grad=0.0269\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7577a1305b5a4851bf7c68ea91cc5489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3/5] Val  :   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: val_loss = 12.3370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae15b92ed0b4442eb1e3fa3e10bdec80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 4/5] Train:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] train/loss=10.90506649017334;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004443, valid_tokens=112, masked_ratio=14.00%, accuracy=1.79%, max_grad=0.0424\n",
      "\n",
      "[Batch 115] train/loss=11.011280829446358;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004333, valid_tokens=140, masked_ratio=17.50%, accuracy=0.00%, max_grad=0.0356\n",
      "\n",
      "[Batch 230] train/loss=11.008258181032927;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004222, valid_tokens=153, masked_ratio=19.12%, accuracy=0.65%, max_grad=0.0358\n",
      "\n",
      "[Batch 345] train/loss=10.993113078241763;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004111, valid_tokens=129, masked_ratio=16.12%, accuracy=0.00%, max_grad=0.0439\n",
      "\n",
      "[Batch 460] train/loss=11.015351486206054;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00004000, valid_tokens=140, masked_ratio=17.50%, accuracy=0.00%, max_grad=0.0212\n",
      "\n",
      "[Batch 575] train/loss=11.005247008282206;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003889, valid_tokens=132, masked_ratio=16.50%, accuracy=0.00%, max_grad=0.0341\n",
      "\n",
      "[Batch 690] train/loss=10.9851655130801;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003778, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0420\n",
      "\n",
      "[Batch 805] train/loss=11.008761629850968;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003667, valid_tokens=131, masked_ratio=16.38%, accuracy=0.00%, max_grad=0.0296\n",
      "\n",
      "[Batch 920] train/loss=10.980970183662746;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003556, valid_tokens=127, masked_ratio=15.88%, accuracy=0.00%, max_grad=0.0316\n",
      "\n",
      "[Batch 1035] train/loss=10.989530878481657;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003444, valid_tokens=161, masked_ratio=20.12%, accuracy=0.00%, max_grad=0.0249\n",
      "\n",
      "[Batch 1150] train/loss=10.981944722714632;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003333, valid_tokens=142, masked_ratio=17.75%, accuracy=0.00%, max_grad=0.0366\n",
      "\n",
      "[Batch 1265] train/loss=10.991916316488515;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003222, valid_tokens=150, masked_ratio=18.75%, accuracy=0.00%, max_grad=0.0377\n",
      "\n",
      "[Batch 1380] train/loss=10.952162261631178;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003111, valid_tokens=149, masked_ratio=18.62%, accuracy=0.00%, max_grad=0.0411\n",
      "\n",
      "[Batch 1495] train/loss=10.963265427299168;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00003000, valid_tokens=145, masked_ratio=18.12%, accuracy=0.69%, max_grad=0.0220\n",
      "\n",
      "[Batch 1610] train/loss=10.98454304570737;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002889, valid_tokens=171, masked_ratio=21.38%, accuracy=0.00%, max_grad=0.0313\n",
      "\n",
      "[Batch 1725] train/loss=10.971780934541123;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002778, valid_tokens=114, masked_ratio=14.25%, accuracy=0.00%, max_grad=0.0295\n",
      "\n",
      "[Batch 1840] train/loss=10.982995514247728;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002667, valid_tokens=145, masked_ratio=18.12%, accuracy=0.00%, max_grad=0.0316\n",
      "\n",
      "[Batch 1955] train/loss=10.93146335767663;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002556, valid_tokens=124, masked_ratio=15.50%, accuracy=0.00%, max_grad=0.0341\n",
      "\n",
      "[Batch 2070] train/loss=10.968462438168734;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002444, valid_tokens=134, masked_ratio=16.75%, accuracy=0.00%, max_grad=0.0336\n",
      "\n",
      "[Batch 2185] train/loss=10.94894038490627;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002333, valid_tokens=152, masked_ratio=19.00%, accuracy=0.00%, max_grad=0.0254\n",
      "\n",
      "[Batch 2300] train/loss=10.947747296872347;\n",
      "input_ids=torch.Size([29, 25]), labels=torch.Size([29, 25]), outputs=torch.Size([29, 25, 216577]);\n",
      "lr=0.00002222, valid_tokens=132, masked_ratio=18.21%, accuracy=0.00%, max_grad=0.0241\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbec8dcc85146e9bfd33710955b4dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 4/5] Val  :   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_loss = 12.3810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a6f05ae2c64a408eac061b2863b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 5/5] Train:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] train/loss=10.994050979614258;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002221, valid_tokens=134, masked_ratio=16.75%, accuracy=0.00%, max_grad=0.0341\n",
      "\n",
      "[Batch 115] train/loss=10.92693791473121;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002111, valid_tokens=161, masked_ratio=20.12%, accuracy=0.62%, max_grad=0.0455\n",
      "\n",
      "[Batch 230] train/loss=10.902174667690112;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00002000, valid_tokens=125, masked_ratio=15.62%, accuracy=0.00%, max_grad=0.0386\n",
      "\n",
      "[Batch 345] train/loss=10.896548810212508;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001889, valid_tokens=164, masked_ratio=20.50%, accuracy=0.00%, max_grad=0.0443\n",
      "\n",
      "[Batch 460] train/loss=10.880521019645359;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001778, valid_tokens=148, masked_ratio=18.50%, accuracy=0.00%, max_grad=0.0428\n",
      "\n",
      "[Batch 575] train/loss=10.894422597470491;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001667, valid_tokens=139, masked_ratio=17.38%, accuracy=0.00%, max_grad=0.0244\n",
      "\n",
      "[Batch 690] train/loss=10.892307513693105;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001556, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0262\n",
      "\n",
      "[Batch 805] train/loss=10.89024940988292;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001444, valid_tokens=124, masked_ratio=15.50%, accuracy=0.00%, max_grad=0.0400\n",
      "\n",
      "[Batch 920] train/loss=10.877038565925929;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001333, valid_tokens=120, masked_ratio=15.00%, accuracy=0.00%, max_grad=0.0353\n",
      "\n",
      "[Batch 1035] train/loss=10.876739103897759;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001222, valid_tokens=141, masked_ratio=17.62%, accuracy=0.00%, max_grad=0.0274\n",
      "\n",
      "[Batch 1150] train/loss=10.86435951564623;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001111, valid_tokens=133, masked_ratio=16.62%, accuracy=0.00%, max_grad=0.0342\n",
      "\n",
      "[Batch 1265] train/loss=10.8599958917369;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00001000, valid_tokens=143, masked_ratio=17.88%, accuracy=0.00%, max_grad=0.0368\n",
      "\n",
      "[Batch 1380] train/loss=10.873826565949813;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000889, valid_tokens=134, masked_ratio=16.75%, accuracy=0.00%, max_grad=0.0334\n",
      "\n",
      "[Batch 1495] train/loss=10.900528294107188;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000778, valid_tokens=119, masked_ratio=14.88%, accuracy=0.00%, max_grad=0.0404\n",
      "\n",
      "[Batch 1610] train/loss=10.872672744419264;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000667, valid_tokens=122, masked_ratio=15.25%, accuracy=0.00%, max_grad=0.0272\n",
      "\n",
      "[Batch 1725] train/loss=10.852135907048764;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000556, valid_tokens=131, masked_ratio=16.38%, accuracy=0.76%, max_grad=0.0386\n",
      "\n",
      "[Batch 1840] train/loss=10.870763778686523;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000444, valid_tokens=148, masked_ratio=18.50%, accuracy=0.68%, max_grad=0.0311\n",
      "\n",
      "[Batch 1955] train/loss=10.855360205277153;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000333, valid_tokens=133, masked_ratio=16.62%, accuracy=0.00%, max_grad=0.0329\n",
      "\n",
      "[Batch 2070] train/loss=10.864110905191172;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000222, valid_tokens=132, masked_ratio=16.50%, accuracy=1.52%, max_grad=0.0285\n",
      "\n",
      "[Batch 2185] train/loss=10.867465168496837;\n",
      "input_ids=torch.Size([32, 25]), labels=torch.Size([32, 25]), outputs=torch.Size([32, 25, 216577]);\n",
      "lr=0.00000111, valid_tokens=127, masked_ratio=15.88%, accuracy=0.79%, max_grad=0.0311\n",
      "\n",
      "[Batch 2300] train/loss=10.905558494899584;\n",
      "input_ids=torch.Size([29, 25]), labels=torch.Size([29, 25]), outputs=torch.Size([29, 25, 216577]);\n",
      "lr=0.00000000, valid_tokens=115, masked_ratio=15.86%, accuracy=0.00%, max_grad=0.0305\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd937a6009540fcb63e16b4013cda83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 5/5] Val  :   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: val_loss = 12.3845\n",
      "Last train loss = 10.9056\n",
      "Last val loss = 12.3845\n"
     ]
    }
   ],
   "source": [
    "trained_model, train_losses, val_losses = train_model(\n",
    "    model=bert4rec_base,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    log_interval=log_interval,\n",
    "    save_path=save_path,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "torch.save(trained_model.state_dict(), save_path_last_batch)\n",
    "\n",
    "print(f\"Last train loss = {train_losses[-1]:.4f}\")\n",
    "print(f\"Last val loss = {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "981420d9-a16e-420d-9e90-977ee915eef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_loss(losses=train_losses, log_interval=len(train_losses), name='Training Loss Over Batches, BERT4Rec (self-made)')\n",
    "plot_train_loss(losses=val_losses, log_interval=None, name='Validation Loss Over Batches, BERT4Rec (self-made)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c47e6d",
   "metadata": {},
   "source": [
    "#### BERT4Rec + Content embeddings (self-made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ca2efff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_cols = [\n",
    "#     'CLS_google_vit_huge_patch14_224_in21k',\n",
    "#     'mean_patch_google_vit_huge_patch14_224_in21k',\n",
    "#     'pooled_google_vit_huge_patch14_224_in21k',\n",
    "#     'pooled_microsoft_resnet50',\n",
    "#     'CLS_openai_clip_vit_large_patch14',\n",
    "#     'mean_patch_openai_clip_vit_large_patch14',\n",
    "#     'pooled_openai_clip_vit_large_patch14',\n",
    "#     'embedding_e5_large_v2',\n",
    "#     'embedding_bge_large_en_v15',\n",
    "#     'embedding_nomic_embed_text_v15',\n",
    "# ]\n",
    "\n",
    "# extra_numeric_cols = ['product_created_at_day', 'sales_total']\n",
    "\n",
    "# embedding_dim = sum(len(df_products_articul[col].iloc[0]) for col in embedding_cols) + len(extra_numeric_cols)\n",
    "\n",
    "# # [num_items + 2, embedding_dim]\n",
    "# item_features_matrix = np.zeros((num_items + 2, embedding_dim), dtype=np.float32)\n",
    "\n",
    "# for _, row in df_products_articul.iterrows():\n",
    "#     pid = row['articul_encrypred_id']\n",
    "#     idx = articul_encrypred_id_to_idx.get(pid)\n",
    "#     if idx is None:\n",
    "#         continue\n",
    "\n",
    "#     vec = []\n",
    "#     for col in embedding_cols:\n",
    "#         vec.extend(row[col])  # col — list with float\n",
    "#     for col in extra_numeric_cols:\n",
    "#         vec.append(float(row[col]))\n",
    "    \n",
    "#     item_features_matrix[idx] = np.array(vec, dtype=np.float32)\n",
    "\n",
    "# item_features_tensor = torch.tensor(item_features_matrix)  # [num_items + 2, embedding_dim]\n",
    "\n",
    "# assert sum(item_features_tensor[0]) == sum(item_features_tensor[-1]) == 0, f\"PAD or MASK tokens have non-zero embeddings!\"\n",
    "\n",
    "# # Save\n",
    "# np.save(interim_data_dir / 'item_features_tensor.npy', item_features_tensor.cpu().numpy())\n",
    "\n",
    "# Load\n",
    "item_features_tensor = torch.from_numpy(np.load(interim_data_dir / 'item_features_tensor.npy')).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "69f48a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecModel_with_embs(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_items,\n",
    "            max_len,\n",
    "            embedding_dim=256,\n",
    "            num_layers=6,\n",
    "            num_heads=4,\n",
    "            dropout=0.1,\n",
    "            ffn_dim=1024,\n",
    "            external_features=None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim # Dim of item vectors\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len # Of purchase seq\n",
    "        ext_dim = external_features.shape[1] # Dim of item FEATURE vectors (concat of different model`s outputs)\n",
    "        proj_dim = embedding_dim // 2 # Projection (for save from OOM error)\n",
    "\n",
    "        # PAD = 0; items = (1, 2, ..., num_items-1, num_items); MASK = num_items+1\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2, embedding_dim, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.external_embeddings = nn.Embedding.from_pretrained(external_features, freeze=True, padding_idx=0) # If Freeze false - kernel death\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.external_proj = nn.Sequential(\n",
    "            nn.Linear(ext_dim, proj_dim, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(proj_dim)\n",
    "        )\n",
    "\n",
    "        self.combine_proj = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + proj_dim, embedding_dim, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Project back to embedding_dim for dot-product with item embeddings\n",
    "        self.fc_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim * 2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim * 2),\n",
    "            nn.Linear(embedding_dim * 2, embedding_dim, bias=False),\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "        )\n",
    "\n",
    "        # bias for vocabulary logits\n",
    "        self.vocab_bias = nn.Parameter(torch.zeros(num_items + 2))\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # embs\n",
    "        nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
    "        nn.init.normal_(self.position_embeddings.weight, 0.0, 0.02)\n",
    "\n",
    "        # transformer\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "\n",
    "        # heads\n",
    "        nn.init.xavier_uniform_(self.fc_head[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc_head[3].weight)\n",
    "        nn.init.zeros_(self.vocab_bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        B, L = input_ids.size() # (B, L)\n",
    "\n",
    "        # 1) Embeddings + scale\n",
    "        external_embeds = self.external_embeddings(input_ids) # (B, L, ext_dim)\n",
    "        external_embeds = self.external_proj(external_embeds) # (B, L, proj_dim)\n",
    "        item_embeds = self.item_embeddings(input_ids) # (B, L, embedding_dim)\n",
    "        item_embeds = torch.cat([item_embeds, external_embeds], dim=-1) # (B, L, embedding_dim + proj_dim)\n",
    "        item_embeds = self.combine_proj(item_embeds) # (B, L, embedding_dim)\n",
    "        pos_embeds  = self.position_embeddings(position_ids) # (L, embedding_dim) → broadcast → (B, L, embedding_dim)\n",
    "        x = (item_embeds + pos_embeds) * math.sqrt(self.embedding_dim) # (B, L, embedding_dim)\n",
    "        x = self.layer_norm(x) # (B, L, embedding_dim)\n",
    "        x = self.dropout(x) # (B, L, embedding_dim)\n",
    "\n",
    "        # 2) Causal + padding masks\n",
    "        src_key_padding_mask = (attention_mask == 0) # (B, L)\n",
    "\n",
    "        # 3) Transformer\n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask) # (B, L, embedding_dim)\n",
    "\n",
    "        # 4) Head → back to embedding space\n",
    "        h = self.fc_head(x) # (B, L, embedding_dim)\n",
    "\n",
    "        # 5) Dot-product with item_embeddings + bias → logits\n",
    "        logits = torch.matmul(h, self.item_embeddings.weight.T) # (B, L, num_items + 2), weight tying\n",
    "        logits = logits + self.vocab_bias # (B, L, num_items + 2)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af990cb8-77df-4735-b3ca-c176636c0791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/at5utwyy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3cc7164a0>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_context = BERT4RecModel_with_embs(\n",
    "    num_items=num_items,\n",
    "    max_len=max_len,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    ffn_dim=ffn_dim,\n",
    "    dropout=dropout,\n",
    "    external_features=item_features_tensor\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(bert4rec_context.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = LambdaLR(optimizer,\n",
    "    lr_lambda=lambda step: (step / warmup_steps if step < warmup_steps \n",
    "                            else max(0.0, (total_steps - step) / float(max(1, total_steps - warmup_steps)))\n",
    "    )\n",
    ")\n",
    "\n",
    "save_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}_with_embs.pth'\n",
    "save_path_last_batch = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}_with_embs_last_batch.pth'\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Recommender_System_with_LLM\",\n",
    "    name=f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}_with_embs',\n",
    "    config={\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"ffn_dim\": ffn_dim,\n",
    "        \"dropout\": dropout,\n",
    "        \"max_len\": max_len,\n",
    "        \"mask_prob\": mask_prob,\n",
    "        \"scheduler\": \"linear with warmup\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "93cbb30a-3c7d-4d60-a203-71ea180f3fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4RecModel_with_embs(\n",
       "  (item_embeddings): Embedding(216577, 512, padding_idx=0)\n",
       "  (position_embeddings): Embedding(25, 512)\n",
       "  (external_embeddings): Embedding(216577, 11266, padding_idx=0)\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (external_proj): Sequential(\n",
       "    (0): Linear(in_features=11266, out_features=256, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (combine_proj): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cebd0dd-9183-4a2e-9950-5e4e9f2e3f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tIgnored (for causing prior/excessive GPU errors) (00000004:kIOGPUCommandBufferCallbackErrorSubmissionsIgnored)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x10dc07740>\n",
      "    label = <none> \n",
      "    device = <AGXG14CDevice: 0x1686eea00>\n",
      "        name = Apple M2 Max \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x1686efe00>\n",
      "        label = <none> \n",
      "        device = <AGXG14CDevice: 0x1686eea00>\n",
      "            name = Apple M2 Max \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN in parameter vocab_bias",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trained_model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path_last_batch)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast train loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, device, save_path, num_epochs, log_interval, scheduler, label_smoothing)\u001b[0m\n\u001b[1;32m     23\u001b[0m running, acc_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(torch\u001b[38;5;241m.\u001b[39misfinite(p)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# wrap loader with tqdm and use enumerate over it\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pbar_train \u001b[38;5;241m=\u001b[39m tqdm(train_loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: NaN in parameter vocab_bias"
     ]
    }
   ],
   "source": [
    "trained_model, train_losses, val_losses = train_model(\n",
    "    model=bert4rec_context,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    log_interval=log_interval,\n",
    "    save_path=save_path,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "torch.save(trained_model.state_dict(), save_path_last_batch)\n",
    "\n",
    "print(f\"Last train loss = {train_losses[-1]:.4f}\")\n",
    "print(f\"Last val loss = {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_loss(losses=train_losses, log_interval=len(train_losses), name='Training Loss Over Batches, BERT4Rec with 11 embeddings (self-made)')\n",
    "plot_train_loss(losses=val_losses, log_interval=None, name='Validation Loss Over Batches, BERT4Rec with 11 embeddings (self-made)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bea80",
   "metadata": {},
   "source": [
    "### BERT4Rec ([RePlay](https://developers.sber.ru/portal/products/replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97de440a-a548-45c8-b8b5-016287a5ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2417031</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wxtppsw</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417032</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wxvwqst</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417033</th>\n",
       "      <td>wyyyyqqsyyvxvvtr</td>\n",
       "      <td>wxvypwr</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  item_id  timestamp\n",
       "2417031  wyyyyqqsyyvxvvtr  wxtppsw         84\n",
       "2417032  wyyyyqqsyyvxvvtr  wxvwqst         85\n",
       "2417033  wyyyyqqsyyvxvvtr  wxvypwr         86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_articul = pd.read_csv(interim_data_dir / 'df_sales_articul.csv')\n",
    "\n",
    "# Reconstructing the articul_encrypred_id_to_idx dictionary from the dataframe\n",
    "articul_encrypred_id_to_idx = dict(df_sales_articul[['articul_encrypred_id', 'articul_encrypred_idx']].drop_duplicates().values)\n",
    "num_items = len(articul_encrypred_id_to_idx)\n",
    "\n",
    "# Add a numeric timestamp — e.g., purchase sequence number (Replay requires numeric timestamp)\n",
    "df_sales_articul[\"timestamp\"] = df_sales_articul.groupby(\"anon_id_encrypred\").cumcount()\n",
    "\n",
    "# Rename columns to match the Replay format\n",
    "df_interactions = df_sales_articul.rename(columns={\n",
    "    \"anon_id_encrypred\": \"user_id\",\n",
    "    \"articul_encrypred\": \"item_id\"\n",
    "})[[\"user_id\", \"item_id\", \"timestamp\"]]\n",
    "\n",
    "df_interactions.to_parquet(interim_data_dir / 'df_interactions_LLM.parquet', index=False)\n",
    "\n",
    "df_interactions = pd.read_parquet(interim_data_dir / 'df_interactions_LLM.parquet')\n",
    "df_interactions.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f732652d-7660-4725-a361-b9cc1f713e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RePlay data preprocessing\n",
    "base_schema = FeatureSchema([\n",
    "    FeatureInfo(\"user_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.QUERY_ID),\n",
    "    FeatureInfo(\"item_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.ITEM_ID),\n",
    "    FeatureInfo(\"timestamp\", feature_type=FeatureType.NUMERICAL, feature_hint=FeatureHint.TIMESTAMP),\n",
    "])\n",
    "\n",
    "splitter = TimeSplitter(\n",
    "    time_threshold=0.85,\n",
    "    query_column=\"user_id\",\n",
    "    timestamp_column='timestamp',\n",
    "    drop_cold_users=True, # Drop unseen users\n",
    "    drop_cold_items=True # Drop unseen items\n",
    ")\n",
    "\n",
    "train_df, test_df = splitter.split(df_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "151cffcc-527a-4fd9-88be-cbae39d902b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "batch_size = 32\n",
    "num_workers = 0  # 0 for Mac compatibility\n",
    "\n",
    "max_len = 25\n",
    "embedding_dim = 512\n",
    "max_len = 25\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "dropout = 0.2\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ed838",
   "metadata": {},
   "source": [
    "#### BERT4Rec Base ([RePlay](https://developers.sber.ru/portal/products/replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dcbe1d5-f701-40e1-ba2e-4fb59556cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build interaction datasets\n",
    "train_dataset = Dataset(\n",
    "    feature_schema=base_schema,\n",
    "    interactions=train_df,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# test_gt is what we want to predict (true future interactions)\n",
    "test_gt = Dataset(\n",
    "    feature_schema=FeatureSchema([\n",
    "        FeatureInfo(\"user_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.QUERY_ID),\n",
    "        FeatureInfo(\"item_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.ITEM_ID),\n",
    "    ]),\n",
    "    interactions=test_df,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# test_events = what model sees at prediction time (history)\n",
    "# built from train data only\n",
    "test_events = Dataset(\n",
    "    feature_schema=base_schema,\n",
    "    interactions=train_df,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# Define sequential tensor schema\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name='item_id_seq',\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[\n",
    "            TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)\n",
    "        ],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "        embedding_dim=embedding_dim\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit tokenizer on train set only\n",
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "# Transform datasets\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "sequential_test_dataset = tokenizer.transform(test_events)\n",
    "sequential_test_gt = tokenizer.transform(test_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "# Align query IDs\n",
    "sequential_test_dataset, sequential_test_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset,\n",
    "    sequential_test_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be8d635-56d9-4318-81bc-1c0cea5f8337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert4Rec(\n",
       "  (_model): Bert4RecModel(\n",
       "    (item_embedder): BertEmbedding(\n",
       "      (cat_embeddings): ModuleDict(\n",
       "        (item_id_seq): CatFeatureEmbedding(94134, 512)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (mask_embedding): Embedding(1, 512)\n",
       "      (position): PositionalEmbedding(\n",
       "        (pe): Embedding(25, 512)\n",
       "      )\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-3): 4 x TransformerBlock(\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (attention_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (attention_norm): LayerNorm()\n",
       "        (pff): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (activation): GELU()\n",
       "        )\n",
       "        (pff_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pff_norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (_head): ClassificationHead(\n",
       "      (linear): Linear(in_features=512, out_features=94134, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_base_replay = Bert4Rec(\n",
    "    tensor_schema=tensor_schema,\n",
    "    block_count=num_layers,\n",
    "    head_count=num_heads,\n",
    "    max_seq_len=max_len,\n",
    "    hidden_size=embedding_dim,\n",
    "    dropout_rate=dropout,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=lr, weight_decay=weight_decay)\n",
    ")\n",
    "\n",
    "bert4rec_base_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fb21ae5-17a3-4bc0-aeb4-e657b1391414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/hs9hx8vd5qz47th8r8718p080000gn/T/ipykernel_86503/3746494648.py:21: DeprecationWarning: Bert4RecTrainingDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  Bert4RecTrainingDataset(sequential_train_dataset, max_sequence_length=max_len),\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/models/nn/sequential/bert4rec/dataset.py:141: DeprecationWarning: TorchSequentialDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialDataset(\n",
      "/var/folders/y5/hs9hx8vd5qz47th8r8718p080000gn/T/ipykernel_86503/3746494648.py:29: DeprecationWarning: Bert4RecValidationDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  Bert4RecValidationDataset(\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/models/nn/sequential/bert4rec/dataset.py:267: DeprecationWarning: TorchSequentialValidationDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialValidationDataset(\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/data/nn/torch_sequential_dataset.py:235: DeprecationWarning: TorchSequentialDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialDataset(\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\", \"precision\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset)]\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"Bert4Rec_Replay\")\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(\n",
    "    Bert4RecTrainingDataset(sequential_train_dataset, max_sequence_length=max_len),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Bert4RecValidationDataset(\n",
    "        sequential_test_dataset,\n",
    "        sequential_test_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=max_len\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb90d4-8415-4316-9fe9-8e667cb5cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[checkpoint_callback, test_metrics_callback],\n",
    "    logger=csv_logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    bert4rec_base_replay,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "save_path_last_batch = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{max_epochs}_lr_{lr}_max_len_{max_len}_num_layers_{num_layers}_num_heads_{num_heads}_dropout_{dropout}_num_items_{num_items}_RePlay_last_batch.pth'\n",
    "torch.save(bert4rec_base_replay.state_dict(), save_path_last_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131dfcb",
   "metadata": {},
   "source": [
    "#### BERT4Rec + Content embeddings ([RePlay](https://developers.sber.ru/portal/products/replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95eafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>product_created_at_day</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_0</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_1</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_2</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_3</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_4</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_5</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_6</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_7</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_8</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_9</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_10</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_11</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_12</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_13</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_14</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_15</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_16</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_17</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_18</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_19</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_20</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k_21</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_nomic_embed_text_v15_487</th>\n",
       "      <th>embedding_nomic_embed_text_v15_488</th>\n",
       "      <th>embedding_nomic_embed_text_v15_489</th>\n",
       "      <th>embedding_nomic_embed_text_v15_490</th>\n",
       "      <th>embedding_nomic_embed_text_v15_491</th>\n",
       "      <th>embedding_nomic_embed_text_v15_492</th>\n",
       "      <th>embedding_nomic_embed_text_v15_493</th>\n",
       "      <th>embedding_nomic_embed_text_v15_494</th>\n",
       "      <th>embedding_nomic_embed_text_v15_495</th>\n",
       "      <th>embedding_nomic_embed_text_v15_496</th>\n",
       "      <th>embedding_nomic_embed_text_v15_497</th>\n",
       "      <th>embedding_nomic_embed_text_v15_498</th>\n",
       "      <th>embedding_nomic_embed_text_v15_499</th>\n",
       "      <th>embedding_nomic_embed_text_v15_500</th>\n",
       "      <th>embedding_nomic_embed_text_v15_501</th>\n",
       "      <th>embedding_nomic_embed_text_v15_502</th>\n",
       "      <th>embedding_nomic_embed_text_v15_503</th>\n",
       "      <th>embedding_nomic_embed_text_v15_504</th>\n",
       "      <th>embedding_nomic_embed_text_v15_505</th>\n",
       "      <th>embedding_nomic_embed_text_v15_506</th>\n",
       "      <th>embedding_nomic_embed_text_v15_507</th>\n",
       "      <th>embedding_nomic_embed_text_v15_508</th>\n",
       "      <th>embedding_nomic_embed_text_v15_509</th>\n",
       "      <th>embedding_nomic_embed_text_v15_510</th>\n",
       "      <th>embedding_nomic_embed_text_v15_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228216</th>\n",
       "      <td>wyyyxuy</td>\n",
       "      <td>18412</td>\n",
       "      <td>293330.55</td>\n",
       "      <td>-0.030899</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>-0.081486</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.084662</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.061334</td>\n",
       "      <td>-0.007333</td>\n",
       "      <td>-0.151542</td>\n",
       "      <td>-0.062097</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>-0.022068</td>\n",
       "      <td>0.027957</td>\n",
       "      <td>0.143590</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.197437</td>\n",
       "      <td>-0.075796</td>\n",
       "      <td>0.163928</td>\n",
       "      <td>-0.025221</td>\n",
       "      <td>0.099675</td>\n",
       "      <td>-0.016331</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.083892</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.073804</td>\n",
       "      <td>0.023145</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>-0.037417</td>\n",
       "      <td>-0.068962</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>-0.010042</td>\n",
       "      <td>0.028096</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>-0.022863</td>\n",
       "      <td>-0.017914</td>\n",
       "      <td>0.041111</td>\n",
       "      <td>-0.038293</td>\n",
       "      <td>-0.057288</td>\n",
       "      <td>-0.080569</td>\n",
       "      <td>-0.011324</td>\n",
       "      <td>0.029364</td>\n",
       "      <td>-0.018090</td>\n",
       "      <td>-0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228217</th>\n",
       "      <td>xspvtuqv</td>\n",
       "      <td>18529</td>\n",
       "      <td>9417.00</td>\n",
       "      <td>0.106859</td>\n",
       "      <td>-0.063431</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>0.078884</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>-0.105617</td>\n",
       "      <td>-0.039742</td>\n",
       "      <td>-0.045960</td>\n",
       "      <td>-0.140972</td>\n",
       "      <td>0.055377</td>\n",
       "      <td>-0.081281</td>\n",
       "      <td>-0.089487</td>\n",
       "      <td>-0.038087</td>\n",
       "      <td>0.044646</td>\n",
       "      <td>-0.150701</td>\n",
       "      <td>0.035482</td>\n",
       "      <td>-0.132598</td>\n",
       "      <td>-0.096141</td>\n",
       "      <td>-0.009017</td>\n",
       "      <td>0.033324</td>\n",
       "      <td>0.249468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>0.066430</td>\n",
       "      <td>-0.007001</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>-0.098287</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>-0.005348</td>\n",
       "      <td>0.071656</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>-0.019410</td>\n",
       "      <td>-0.009052</td>\n",
       "      <td>0.079769</td>\n",
       "      <td>-0.016199</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>-0.051635</td>\n",
       "      <td>-0.014431</td>\n",
       "      <td>-0.005289</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>0.011738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228218</th>\n",
       "      <td>xtqwuuuy</td>\n",
       "      <td>18530</td>\n",
       "      <td>19380.79</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>-0.037450</td>\n",
       "      <td>0.057177</td>\n",
       "      <td>0.102230</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.096574</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>0.081149</td>\n",
       "      <td>-0.135642</td>\n",
       "      <td>-0.038227</td>\n",
       "      <td>-0.023811</td>\n",
       "      <td>-0.051917</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.011138</td>\n",
       "      <td>0.044949</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.018704</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>-0.023290</td>\n",
       "      <td>0.078478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>0.045650</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>-0.038764</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.043996</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.094994</td>\n",
       "      <td>0.065249</td>\n",
       "      <td>0.058098</td>\n",
       "      <td>0.027968</td>\n",
       "      <td>0.025646</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>0.062732</td>\n",
       "      <td>-0.083820</td>\n",
       "      <td>-0.022749</td>\n",
       "      <td>-0.071033</td>\n",
       "      <td>-0.003976</td>\n",
       "      <td>0.047164</td>\n",
       "      <td>-0.052599</td>\n",
       "      <td>-0.013718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 11267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  product_created_at_day  sales_total  \\\n",
       "228216   wyyyxuy                   18412    293330.55   \n",
       "228217  xspvtuqv                   18529      9417.00   \n",
       "228218  xtqwuuuy                   18530     19380.79   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_0  \\\n",
       "228216                                -0.030899   \n",
       "228217                                 0.106859   \n",
       "228218                                 0.097900   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_1  \\\n",
       "228216                                 0.004474   \n",
       "228217                                -0.063431   \n",
       "228218                                -0.037450   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_2  \\\n",
       "228216                                -0.081486   \n",
       "228217                                -0.000331   \n",
       "228218                                 0.057177   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_3  \\\n",
       "228216                                 0.059778   \n",
       "228217                                -0.023781   \n",
       "228218                                 0.102230   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_4  \\\n",
       "228216                                 0.084662   \n",
       "228217                                 0.078884   \n",
       "228218                                 0.047996   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_5  \\\n",
       "228216                                 0.005976   \n",
       "228217                                 0.001931   \n",
       "228218                                 0.096574   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_6  \\\n",
       "228216                                 0.061334   \n",
       "228217                                -0.105617   \n",
       "228218                                 0.010224   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_7  \\\n",
       "228216                                -0.007333   \n",
       "228217                                -0.039742   \n",
       "228218                                 0.081149   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_8  \\\n",
       "228216                                -0.151542   \n",
       "228217                                -0.045960   \n",
       "228218                                -0.135642   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_9  \\\n",
       "228216                                -0.062097   \n",
       "228217                                -0.140972   \n",
       "228218                                -0.038227   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_10  \\\n",
       "228216                                  0.006078   \n",
       "228217                                  0.055377   \n",
       "228218                                 -0.023811   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_11  \\\n",
       "228216                                 -0.022068   \n",
       "228217                                 -0.081281   \n",
       "228218                                 -0.051917   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_12  \\\n",
       "228216                                  0.027957   \n",
       "228217                                 -0.089487   \n",
       "228218                                 -0.001963   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_13  \\\n",
       "228216                                  0.143590   \n",
       "228217                                 -0.038087   \n",
       "228218                                 -0.011138   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_14  \\\n",
       "228216                                 -0.005696   \n",
       "228217                                  0.044646   \n",
       "228218                                  0.044949   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_15  \\\n",
       "228216                                 -0.197437   \n",
       "228217                                 -0.150701   \n",
       "228218                                  0.013257   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_16  \\\n",
       "228216                                 -0.075796   \n",
       "228217                                  0.035482   \n",
       "228218                                  0.035432   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_17  \\\n",
       "228216                                  0.163928   \n",
       "228217                                 -0.132598   \n",
       "228218                                  0.109493   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_18  \\\n",
       "228216                                 -0.025221   \n",
       "228217                                 -0.096141   \n",
       "228218                                  0.018704   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_19  \\\n",
       "228216                                  0.099675   \n",
       "228217                                 -0.009017   \n",
       "228218                                 -0.017878   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_20  \\\n",
       "228216                                 -0.016331   \n",
       "228217                                  0.033324   \n",
       "228218                                 -0.023290   \n",
       "\n",
       "        CLS_google_vit_huge_patch14_224_in21k_21  ...  \\\n",
       "228216                                  0.014730  ...   \n",
       "228217                                  0.249468  ...   \n",
       "228218                                  0.078478  ...   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_487  \\\n",
       "228216                            0.022027   \n",
       "228217                            0.022216   \n",
       "228218                           -0.000949   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_488  \\\n",
       "228216                            0.083892   \n",
       "228217                            0.066430   \n",
       "228218                            0.045650   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_489  \\\n",
       "228216                            0.013018   \n",
       "228217                           -0.007001   \n",
       "228218                            0.015038   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_490  \\\n",
       "228216                            0.073804   \n",
       "228217                            0.044880   \n",
       "228218                            0.012992   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_491  \\\n",
       "228216                            0.023145   \n",
       "228217                            0.027177   \n",
       "228218                           -0.038764   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_492  \\\n",
       "228216                            0.027553   \n",
       "228217                            0.008892   \n",
       "228218                            0.040421   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_493  \\\n",
       "228216                           -0.037417   \n",
       "228217                            0.021111   \n",
       "228218                            0.002409   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_494  \\\n",
       "228216                           -0.068962   \n",
       "228217                           -0.098287   \n",
       "228218                           -0.043996   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_495  \\\n",
       "228216                            0.014783   \n",
       "228217                           -0.006610   \n",
       "228218                            0.007052   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_496  \\\n",
       "228216                           -0.010042   \n",
       "228217                           -0.005348   \n",
       "228218                           -0.014772   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_497  \\\n",
       "228216                            0.028096   \n",
       "228217                            0.071656   \n",
       "228218                            0.094994   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_498  \\\n",
       "228216                            0.040614   \n",
       "228217                            0.034570   \n",
       "228218                            0.065249   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_499  \\\n",
       "228216                            0.019241   \n",
       "228217                           -0.000758   \n",
       "228218                            0.058098   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_500  \\\n",
       "228216                           -0.028149   \n",
       "228217                            0.001923   \n",
       "228218                            0.027968   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_501  \\\n",
       "228216                            0.085963   \n",
       "228217                            0.007282   \n",
       "228218                            0.025646   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_502  \\\n",
       "228216                           -0.022863   \n",
       "228217                           -0.019410   \n",
       "228218                            0.023567   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_503  \\\n",
       "228216                           -0.017914   \n",
       "228217                           -0.009052   \n",
       "228218                           -0.001048   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_504  \\\n",
       "228216                            0.041111   \n",
       "228217                            0.079769   \n",
       "228218                            0.062732   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_505  \\\n",
       "228216                           -0.038293   \n",
       "228217                           -0.016199   \n",
       "228218                           -0.083820   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_506  \\\n",
       "228216                           -0.057288   \n",
       "228217                            0.033352   \n",
       "228218                           -0.022749   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_507  \\\n",
       "228216                           -0.080569   \n",
       "228217                           -0.051635   \n",
       "228218                           -0.071033   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_508  \\\n",
       "228216                           -0.011324   \n",
       "228217                           -0.014431   \n",
       "228218                           -0.003976   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_509  \\\n",
       "228216                            0.029364   \n",
       "228217                           -0.005289   \n",
       "228218                            0.047164   \n",
       "\n",
       "        embedding_nomic_embed_text_v15_510  embedding_nomic_embed_text_v15_511  \n",
       "228216                           -0.018090                           -0.013021  \n",
       "228217                           -0.023125                            0.011738  \n",
       "228218                           -0.052599                           -0.013718  \n",
       "\n",
       "[3 rows x 11267 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_cols = [\n",
    "#     'CLS_google_vit_huge_patch14_224_in21k',\n",
    "#     'mean_patch_google_vit_huge_patch14_224_in21k',\n",
    "#     'pooled_google_vit_huge_patch14_224_in21k',\n",
    "#     'pooled_microsoft_resnet50',\n",
    "#     'CLS_openai_clip_vit_large_patch14',\n",
    "#     'mean_patch_openai_clip_vit_large_patch14',\n",
    "#     'pooled_openai_clip_vit_large_patch14',\n",
    "#     'embedding_e5_large_v2',\n",
    "#     'embedding_bge_large_en_v15',\n",
    "#     'embedding_nomic_embed_text_v15',\n",
    "# ]\n",
    "\n",
    "\n",
    "# df_items = df_products_articul[[\n",
    "#     \"articul_encrypred\", \"product_created_at_day\", \"sales_total\"\n",
    "# ] + embedding_cols].copy()\n",
    "\n",
    "# df_items = df_items.rename(columns={\"articul_encrypred\": \"item_id\"})\n",
    "\n",
    "# # Convert vector features (lists) to flat columns\n",
    "# def flatten_embeddings(df: pd.DataFrame, embedding_cols: list[str]) -> pd.DataFrame:\n",
    "#     flat_data = {}\n",
    "#     for col in tqdm(embedding_cols):\n",
    "#         tqdm.write(f\"Processing: {col}\")\n",
    "#         emb_array = np.array(df[col].tolist()) # shape: (N, D)\n",
    "#         for i in range(emb_array.shape[1]):\n",
    "#             flat_data[f\"{col}_{i}\"] = emb_array[:, i]\n",
    "#     flat_df = pd.DataFrame(flat_data, index=df.index)\n",
    "#     return pd.concat([df.drop(columns=embedding_cols), flat_df], axis=1)\n",
    "\n",
    "# df_items_flat = flatten_embeddings(df_items, embedding_cols)\n",
    "# df_items_flat.to_parquet(interim_data_dir / 'df_items_flat_LLM.parquet', index=False)\n",
    "\n",
    "df_items_flat = pd.read_parquet(interim_data_dir / 'df_items_flat_LLM.parquet')\n",
    "df_items_flat.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e87fc312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228216</th>\n",
       "      <td>wyyyxuy</td>\n",
       "      <td>-316352.144095</td>\n",
       "      <td>654.463564</td>\n",
       "      <td>-3.916416</td>\n",
       "      <td>0.579525</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>1.262266</td>\n",
       "      <td>5.441536</td>\n",
       "      <td>0.506631</td>\n",
       "      <td>0.756005</td>\n",
       "      <td>0.375660</td>\n",
       "      <td>1.010859</td>\n",
       "      <td>-1.470811</td>\n",
       "      <td>0.793889</td>\n",
       "      <td>-0.988122</td>\n",
       "      <td>0.639303</td>\n",
       "      <td>-1.684633</td>\n",
       "      <td>-0.698577</td>\n",
       "      <td>-1.740362</td>\n",
       "      <td>1.776020</td>\n",
       "      <td>0.199129</td>\n",
       "      <td>1.131359</td>\n",
       "      <td>-3.031881</td>\n",
       "      <td>1.148105</td>\n",
       "      <td>-0.138955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038228</td>\n",
       "      <td>-0.231765</td>\n",
       "      <td>0.090180</td>\n",
       "      <td>-0.181232</td>\n",
       "      <td>0.177974</td>\n",
       "      <td>-0.097677</td>\n",
       "      <td>-0.138335</td>\n",
       "      <td>-0.064704</td>\n",
       "      <td>-0.178576</td>\n",
       "      <td>0.058839</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.159167</td>\n",
       "      <td>-0.213117</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>-0.083916</td>\n",
       "      <td>0.402408</td>\n",
       "      <td>0.123040</td>\n",
       "      <td>0.176260</td>\n",
       "      <td>0.082232</td>\n",
       "      <td>-0.017543</td>\n",
       "      <td>-0.208358</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>-0.230157</td>\n",
       "      <td>0.090199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228217</th>\n",
       "      <td>xspvtuqv</td>\n",
       "      <td>-600265.690402</td>\n",
       "      <td>780.101058</td>\n",
       "      <td>-6.253014</td>\n",
       "      <td>-1.790434</td>\n",
       "      <td>-1.379571</td>\n",
       "      <td>-3.440993</td>\n",
       "      <td>-2.127366</td>\n",
       "      <td>3.239532</td>\n",
       "      <td>2.677925</td>\n",
       "      <td>-1.818684</td>\n",
       "      <td>0.900847</td>\n",
       "      <td>1.437563</td>\n",
       "      <td>-2.250623</td>\n",
       "      <td>0.279516</td>\n",
       "      <td>2.461042</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.589115</td>\n",
       "      <td>2.042396</td>\n",
       "      <td>-0.269997</td>\n",
       "      <td>-3.026960</td>\n",
       "      <td>-0.963654</td>\n",
       "      <td>0.836733</td>\n",
       "      <td>-0.169514</td>\n",
       "      <td>2.192878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172602</td>\n",
       "      <td>0.109052</td>\n",
       "      <td>-0.329437</td>\n",
       "      <td>-0.238250</td>\n",
       "      <td>-0.148119</td>\n",
       "      <td>-0.287389</td>\n",
       "      <td>0.291216</td>\n",
       "      <td>-0.041041</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.184263</td>\n",
       "      <td>-0.087984</td>\n",
       "      <td>0.371453</td>\n",
       "      <td>-0.331210</td>\n",
       "      <td>-0.103540</td>\n",
       "      <td>-0.431693</td>\n",
       "      <td>-0.200078</td>\n",
       "      <td>-0.134067</td>\n",
       "      <td>-0.046849</td>\n",
       "      <td>0.337717</td>\n",
       "      <td>0.086990</td>\n",
       "      <td>-0.350236</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.514533</td>\n",
       "      <td>0.121188</td>\n",
       "      <td>0.247561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228218</th>\n",
       "      <td>xtqwuuuy</td>\n",
       "      <td>-590301.900376</td>\n",
       "      <td>780.800137</td>\n",
       "      <td>-8.709489</td>\n",
       "      <td>-2.638261</td>\n",
       "      <td>0.227584</td>\n",
       "      <td>-3.339476</td>\n",
       "      <td>-3.921348</td>\n",
       "      <td>0.062066</td>\n",
       "      <td>1.579867</td>\n",
       "      <td>-0.851812</td>\n",
       "      <td>-0.146972</td>\n",
       "      <td>0.805592</td>\n",
       "      <td>0.334977</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>-1.021059</td>\n",
       "      <td>2.526228</td>\n",
       "      <td>0.446303</td>\n",
       "      <td>-1.525518</td>\n",
       "      <td>3.324485</td>\n",
       "      <td>3.411422</td>\n",
       "      <td>-0.286401</td>\n",
       "      <td>-3.701665</td>\n",
       "      <td>0.352095</td>\n",
       "      <td>-1.507118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095398</td>\n",
       "      <td>-0.200223</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>-0.328356</td>\n",
       "      <td>-0.120980</td>\n",
       "      <td>-0.094648</td>\n",
       "      <td>-0.353112</td>\n",
       "      <td>-0.053770</td>\n",
       "      <td>-0.211133</td>\n",
       "      <td>0.058387</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>-0.104508</td>\n",
       "      <td>-0.240239</td>\n",
       "      <td>0.405211</td>\n",
       "      <td>-0.356057</td>\n",
       "      <td>-0.333586</td>\n",
       "      <td>-0.098402</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>0.059248</td>\n",
       "      <td>-0.092788</td>\n",
       "      <td>-0.293273</td>\n",
       "      <td>0.273428</td>\n",
       "      <td>0.386011</td>\n",
       "      <td>0.167605</td>\n",
       "      <td>-0.295807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id              0           1         2         3         4  \\\n",
       "228216   wyyyxuy -316352.144095  654.463564 -3.916416  0.579525  0.869629   \n",
       "228217  xspvtuqv -600265.690402  780.101058 -6.253014 -1.790434 -1.379571   \n",
       "228218  xtqwuuuy -590301.900376  780.800137 -8.709489 -2.638261  0.227584   \n",
       "\n",
       "               5         6         7         8         9        10        11  \\\n",
       "228216  1.262266  5.441536  0.506631  0.756005  0.375660  1.010859 -1.470811   \n",
       "228217 -3.440993 -2.127366  3.239532  2.677925 -1.818684  0.900847  1.437563   \n",
       "228218 -3.339476 -3.921348  0.062066  1.579867 -0.851812 -0.146972  0.805592   \n",
       "\n",
       "              12        13        14        15        16        17        18  \\\n",
       "228216  0.793889 -0.988122  0.639303 -1.684633 -0.698577 -1.740362  1.776020   \n",
       "228217 -2.250623  0.279516  2.461042  0.897007  0.589115  2.042396 -0.269997   \n",
       "228218  0.334977  0.591829 -1.021059  2.526228  0.446303 -1.525518  3.324485   \n",
       "\n",
       "              19        20        21        22        23  ...       487  \\\n",
       "228216  0.199129  1.131359 -3.031881  1.148105 -0.138955  ...  0.038228   \n",
       "228217 -3.026960 -0.963654  0.836733 -0.169514  2.192878  ...  0.172602   \n",
       "228218  3.411422 -0.286401 -3.701665  0.352095 -1.507118  ...  0.095398   \n",
       "\n",
       "             488       489       490       491       492       493       494  \\\n",
       "228216 -0.231765  0.090180 -0.181232  0.177974 -0.097677 -0.138335 -0.064704   \n",
       "228217  0.109052 -0.329437 -0.238250 -0.148119 -0.287389  0.291216 -0.041041   \n",
       "228218 -0.200223  0.018736 -0.328356 -0.120980 -0.094648 -0.353112 -0.053770   \n",
       "\n",
       "             495       496       497       498       499       500       501  \\\n",
       "228216 -0.178576  0.058839  0.043145  0.159167 -0.213117  0.255663 -0.083916   \n",
       "228217  0.034714  0.184263 -0.087984  0.371453 -0.331210 -0.103540 -0.431693   \n",
       "228218 -0.211133  0.058387 -0.021839 -0.104508 -0.240239  0.405211 -0.356057   \n",
       "\n",
       "             502       503       504       505       506       507       508  \\\n",
       "228216  0.402408  0.123040  0.176260  0.082232 -0.017543 -0.208358  0.003959   \n",
       "228217 -0.200078 -0.134067 -0.046849  0.337717  0.086990 -0.350236  0.051241   \n",
       "228218 -0.333586 -0.098402  0.029704  0.059248 -0.092788 -0.293273  0.273428   \n",
       "\n",
       "             509       510       511  \n",
       "228216  0.192963 -0.230157  0.090199  \n",
       "228217  0.514533  0.121188  0.247561  \n",
       "228218  0.386011  0.167605 -0.295807  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=embedding_dim)\n",
    "item_features_pca = pca.fit_transform(df_items_flat.drop(columns=[\"item_id\"]))\n",
    "df_items_flat_compressed = pd.DataFrame(item_features_pca, index=df_items_flat.index)\n",
    "df_items_flat_compressed[\"item_id\"] = df_items_flat[\"item_id\"]\n",
    "df_items_flat_compressed = df_items_flat_compressed[[\"item_id\"] + [col for col in df_items_flat_compressed.columns if col != \"item_id\"]]\n",
    "df_items_flat_compressed.to_parquet(interim_data_dir / f'df_items_flat_compressed_{embedding_dim}_dim_LLM.parquet', index=False)\n",
    "\n",
    "df_items_flat_compressed = pd.read_parquet(interim_data_dir / f'df_items_flat_compressed_{embedding_dim}_dim_LLM.parquet')\n",
    "df_items_flat_compressed.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cada2b46-bdec-4178-b570-a8b8077fb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build interaction datasets\n",
    "train_dataset = Dataset(\n",
    "    feature_schema=base_schema,\n",
    "    interactions=train_df,\n",
    "    item_features=df_items_flat_compressed,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# test_gt is what we want to predict (true future interactions)\n",
    "test_gt = Dataset(\n",
    "    feature_schema=FeatureSchema([\n",
    "        FeatureInfo(\"user_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.QUERY_ID),\n",
    "        FeatureInfo(\"item_id\", feature_type=FeatureType.CATEGORICAL, feature_hint=FeatureHint.ITEM_ID),\n",
    "    ]),\n",
    "    interactions=test_df,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# test_events = what model sees at prediction time (history)\n",
    "# built from train data only\n",
    "test_events = Dataset(\n",
    "    feature_schema=base_schema,\n",
    "    interactions=train_df,\n",
    "    item_features=df_items_flat_compressed,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False\n",
    ")\n",
    "\n",
    "# Define sequential tensor schema\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name='item_id_seq',\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[\n",
    "            TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)\n",
    "        ],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "        embedding_dim=embedding_dim\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit tokenizer on train set only\n",
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "# Transform datasets\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "sequential_test_dataset = tokenizer.transform(test_events)\n",
    "sequential_test_gt = tokenizer.transform(test_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "# Align query IDs\n",
    "sequential_test_dataset, sequential_test_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset,\n",
    "    sequential_test_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe949c0-20a2-4b48-92ee-5c3f7e9191c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert4Rec(\n",
       "  (_model): Bert4RecModel(\n",
       "    (item_embedder): BertEmbedding(\n",
       "      (cat_embeddings): ModuleDict(\n",
       "        (item_id_seq): CatFeatureEmbedding(94134, 512)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (mask_embedding): Embedding(1, 512)\n",
       "      (position): PositionalEmbedding(\n",
       "        (pe): Embedding(25, 512)\n",
       "      )\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-3): 4 x TransformerBlock(\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (attention_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (attention_norm): LayerNorm()\n",
       "        (pff): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (activation): GELU()\n",
       "        )\n",
       "        (pff_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (pff_norm): LayerNorm()\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (_head): ClassificationHead(\n",
       "      (linear): Linear(in_features=512, out_features=94134, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert4rec_context_replay = Bert4Rec(\n",
    "    tensor_schema=tensor_schema,\n",
    "    block_count=num_layers,\n",
    "    head_count=num_heads,\n",
    "    max_seq_len=max_len,\n",
    "    hidden_size=embedding_dim,\n",
    "    dropout_rate=dropout,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=lr, weight_decay=weight_decay)\n",
    ")\n",
    "\n",
    "bert4rec_context_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7134dff-4ad6-4c19-aab0-2063d245a13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/hs9hx8vd5qz47th8r8718p080000gn/T/ipykernel_86503/2847676338.py:21: DeprecationWarning: Bert4RecTrainingDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  Bert4RecTrainingDataset(sequential_train_dataset, max_sequence_length=max_len),\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/models/nn/sequential/bert4rec/dataset.py:141: DeprecationWarning: TorchSequentialDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialDataset(\n",
      "/var/folders/y5/hs9hx8vd5qz47th8r8718p080000gn/T/ipykernel_86503/2847676338.py:29: DeprecationWarning: Bert4RecValidationDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  Bert4RecValidationDataset(\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/models/nn/sequential/bert4rec/dataset.py:267: DeprecationWarning: TorchSequentialValidationDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialValidationDataset(\n",
      "/Users/dimi3tru/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.10/site-packages/replay/data/nn/torch_sequential_dataset.py:235: DeprecationWarning: TorchSequentialDataset.__init__ `padding_value` parameter will be removed in future versions. Instead, you should specify `padding_value` for each column in TensorSchema\n",
      "  self._inner = TorchSequentialDataset(\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\", \"precision\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset)]\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"Bert4Rec_Replay_with_embs\")\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(\n",
    "    Bert4RecTrainingDataset(sequential_train_dataset, max_sequence_length=max_len),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Bert4RecValidationDataset(\n",
    "        sequential_test_dataset,\n",
    "        sequential_test_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=max_len\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88c7b9-f060-40dd-bcd4-9747d3d4580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[checkpoint_callback, test_metrics_callback],\n",
    "    logger=csv_logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    bert4rec_context_replay,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=test_loader\n",
    ")\n",
    "\n",
    "save_path_last_batch = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{max_epochs}_lr_{lr}_max_len_{max_len}_num_layers_{num_layers}_num_heads_{num_heads}_dropout_{dropout}_num_items_{num_items}_RePlay_with_embs_last_batch.pth'\n",
    "torch.save(bert4rec_context_replay.state_dict(), save_path_last_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18649fe",
   "metadata": {},
   "source": [
    "#### BERT4Rec Generation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a19b4-ec48-412d-a21b-748b9d7531d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for parallel recommendation generation (input: batch from test DataLoader)\n",
    "def generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=10, device=device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        position_ids = position_ids.to(device)\n",
    "        \n",
    "        # Get model outputs: [B, seq_len, num_items+1]\n",
    "        outputs = model(input_ids, attention_mask, position_ids)\n",
    "        logits = outputs[:, -1, :]  # shape: [B, num_items+1]\n",
    "        recs = torch.topk(logits, k=k, dim=-1).indices\n",
    "    return recs\n",
    "\n",
    "# Function for sequential recommendation generation for a single user\n",
    "def generate_sequential_recommendations(model, initial_sequence, max_len, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Generates sequential (autoregressive) recommendations for a single user.\n",
    "    \n",
    "    :param initial_sequence: Initial sequence (list of int) without padding.\n",
    "    :param max_len: Maximum sequence length used during model training.\n",
    "    :param k: Number of recommendations to generate.\n",
    "    :param device: Computation device.\n",
    "    :return: List of generated recommendations.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated = []\n",
    "    current_seq = initial_sequence.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(k):\n",
    "            # If the sequence is shorter than max_len – pad with zeros on the left\n",
    "            if len(current_seq) < max_len:\n",
    "                padded_seq = [0] * (max_len - len(current_seq)) + current_seq\n",
    "            else:\n",
    "                padded_seq = current_seq[-max_len:]\n",
    "            \n",
    "            input_ids = torch.tensor(padded_seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            attention_mask = (input_ids != 0).long()\n",
    "            position_ids = torch.arange(max_len, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, position_ids)  # [1, max_len, num_items+1]\n",
    "            logits = outputs[:, -1, :]  # [1, num_items+1]\n",
    "            next_token = torch.topk(logits, k=1, dim=-1).indices.squeeze().item()\n",
    "            generated.append(next_token)\n",
    "            current_seq.append(next_token)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a46b59b3-6b92-48ce-a873-715d43d47d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel_inference(model, inference_loader, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Runs inference on the inference_loader and returns top-K recommendations for each user.\n",
    "    \n",
    "    :param model: Trained BERT4Rec model.\n",
    "    :param inference_loader: DataLoader without masked tokens (contains data from train).\n",
    "    :param k: Number of recommendations.\n",
    "    :param device: Computation device (CPU/GPU).\n",
    "    :return: List of predicted recommendations for all users.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Parallel Inference\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            position_ids = batch[\"position_ids\"].to(device)\n",
    "\n",
    "            # Generate top-k recommendations\n",
    "            recs = generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=k, device=device)\n",
    "            \n",
    "            all_recommendations.extend(recs.cpu().tolist())\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "\n",
    "def run_sequential_inference(model, inference_loader, max_len, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Runs sequential inference: for each user in inference_loader, extracts the original (unpadded) sequence\n",
    "    and generates recommendations autoregressively.\n",
    "    \n",
    "    :param model: Trained BERT4Rec model.\n",
    "    :param inference_loader: DataLoader with data (is_train=False).\n",
    "    :param max_len: Maximum sequence length.\n",
    "    :param k: Number of recommendations to generate for each user.\n",
    "    :param device: Computation device.\n",
    "    :return: Dictionary of the form {user_id: [list of recommended items]}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    user_recs = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Sequential Inference\"):\n",
    "            input_ids = batch['input_ids']             # [B, max_len]\n",
    "            attention_mask = batch['attention_mask']   # [B, max_len]\n",
    "            user_ids = batch['user_id']                # list of user_ids\n",
    "            \n",
    "            # For each user in the batch, extract the original sequence without padding\n",
    "            for i in range(input_ids.shape[0]):\n",
    "                # Move to CPU for easier list handling\n",
    "                seq = input_ids[i].cpu().tolist()\n",
    "                mask = attention_mask[i].cpu().tolist()\n",
    "                # Extract only tokens where mask == 1 (i.e., non-padding elements)\n",
    "                initial_seq = [token for token, m in zip(seq, mask) if m == 1]\n",
    "                recs = generate_sequential_recommendations(model, initial_seq, max_len, k=k, device=device)\n",
    "                user_recs[user_ids[i]] = recs\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b69d0fc1-df6e-448b-9523-16c847df9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = BERT4RecDataset(sequences=train_sequences_list, max_len=max_len, mask_prob=0.0, num_items=num_items, is_train=False)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d981883-a336-4402-9dd6-96a783fe7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert4rec_base_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}.pth'\n",
    "# bert4rec_context_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}_with_embs.pth'\n",
    "# bert4rec_base_replay_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{max_epochs}_lr_{lr}_max_len_{max_len}_num_layers_{num_layers}_num_heads_{num_heads}_dropout_{dropout}_num_items_{num_items}_RePlay_last_batch.pth'\n",
    "# bert4rec_context_replay_path = models_dir / f'bert4rec_model_articul_encrypred_id_embedding_dim_{embedding_dim}_epochs_{max_epochs}_lr_{lr}_max_len_{max_len}_num_layers_{num_layers}_num_heads_{num_heads}_dropout_{dropout}_num_items_{num_items}_RePlay_with_embs_last_batch.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76c434a1-75b9-4787-a0db-a9194cdd84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_recommendations_to_users(user_ids, recommendations):\n",
    "    \"\"\"\n",
    "    Converts a list of recommendations into a dictionary {user_id: recommendations}.\n",
    "\n",
    "    :param user_ids: List of user IDs from inference_loader.\n",
    "    :param recommendations: List of recommendations from parallel_recs.\n",
    "    :return: Dictionary {user_id: [recommendations]}.\n",
    "    \"\"\"\n",
    "    user_to_recs = {user: recs for user, recs in zip(user_ids, recommendations)}\n",
    "    return user_to_recs\n",
    "\n",
    "# Get the list of users from the inference_loader\n",
    "user_ids = inference_loader.dataset.user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edef4552-729b-4e4e-bb3e-659934b646bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Inference\n",
    "parallel_recs_bert4rec_base = run_parallel_inference(bert4rec_base, inference_loader, k=k, device=device)\n",
    "# {user_id: recommendations}\n",
    "test_user_to_parallel_recs_bert4rec_base = map_recommendations_to_users(user_ids, parallel_recs_bert4rec_base)\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_base.pkl', 'wb') as f:\n",
    "    pickle.dump(test_user_to_parallel_recs_bert4rec_base, f)\n",
    "\n",
    "parallel_recs_bert4rec_context = run_parallel_inference(bert4rec_context, inference_loader, k=k, device=device)\n",
    "test_user_to_parallel_recs_bert4rec_context = map_recommendations_to_users(user_ids, parallel_recs_bert4rec_context)\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_context.pkl', 'wb') as f:\n",
    "    pickle.dump(test_user_to_parallel_recs_bert4rec_context, f)\n",
    "\n",
    "parallel_recs_bert4rec_base_replay = run_parallel_inference(bert4rec_base_replay, inference_loader, k=k, device=device)\n",
    "test_user_to_parallel_recs_bert4rec_base_replay = map_recommendations_to_users(user_ids, parallel_recs_bert4rec_base_replay)\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_base_replay.pkl', 'wb') as f:\n",
    "    pickle.dump(test_user_to_parallel_recs_bert4rec_base_replay, f)\n",
    "\n",
    "parallel_recs_bert4rec_context_replay = run_parallel_inference(bert4rec_context_replay, inference_loader, k=k, device=device)\n",
    "test_user_to_parallel_recs_bert4rec_context_replay = map_recommendations_to_users(user_ids, parallel_recs_bert4rec_context_replay)\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_context_replay.pkl', 'wb') as f:\n",
    "    pickle.dump(test_user_to_parallel_recs_bert4rec_context_replay, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02acf32c-74a4-4135-a944-8522eda0f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_base.pkl', \"rb\") as f:\n",
    "    test_user_to_parallel_recs_bert4rec_base = pickle.load(f)\n",
    "\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_context.pkl', \"rb\") as f:\n",
    "    test_user_to_parallel_recs_bert4rec_context = pickle.load(f)\n",
    "\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_base_replay.pkl', \"rb\") as f:\n",
    "    test_user_to_parallel_recs_bert4rec_base_replay = pickle.load(f)\n",
    "\n",
    "with open(models_outputs_dir / 'bert' / 'user_recommendations_bert4rec_context_replay.pkl', \"rb\") as f:\n",
    "    test_user_to_parallel_recs_bert4rec_context_replay = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3815bdfe-b39f-4947-b7f4-6ab29f00735d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Sequential Inference\n",
    "# sequential_recs = run_sequential_inference(model, inference_loader, max_len=max_len, k=k, device=device)\n",
    "\n",
    "# # user_id: recommendations\n",
    "# test_user_to_sequential_recs = map_recommendations_to_users(user_ids, sequential_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87f0810d-990a-4a77-b949-a4b4eec3cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_dataset_bert4rec_base = RecommendationDataset(user_recommendations=test_user_to_parallel_recs_bert4rec_base, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader_bert4rec_base = DataLoader(parallel_dataset_bert4rec_base, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "parallel_dataset_bert4rec_context = RecommendationDataset(user_recommendations=test_user_to_parallel_recs_bert4rec_context, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader_bert4rec_context = DataLoader(parallel_dataset_bert4rec_context, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "parallel_dataset_bert4rec_base_replay = RecommendationDataset(user_recommendations=test_user_to_parallel_recs_bert4rec_base_replay, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader_bert4rec_base_replay = DataLoader(parallel_dataset_bert4rec_base_replay, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "parallel_dataset_bert4rec_context_replay = RecommendationDataset(user_recommendations=test_user_to_parallel_recs_bert4rec_context_replay, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader_bert4rec_context_replay = DataLoader(parallel_dataset_bert4rec_context_replay, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c84211c-6a4c-483e-afe1-8310eddd5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'top_sales' / 'user_recommendations_top_k.pkl', \"rb\") as f:\n",
    "    user_recommendations_top_k = pickle.load(f)\n",
    "\n",
    "dataset_top_k = RecommendationDataset(user_recommendations=user_recommendations_top_k, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_top_k, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395d665-4a56-4e4f-81dd-06def694b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7d91a76f35481f926cb1a401ee42fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12f4304f1224bdea24ef01b440618d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35eb6f8a724e457abdd7f043bda9a21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4498c94bc17440dd95d49fee6284be81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7474b885e748b49f4ecd53b34dd97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eca74f7aa7c4c658177fd54fe47d1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de832fea51cb49089c5c54149d85e7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe627d9bdc564239bfbd93538ef9f3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d16e3fa8d04422abdf016c44a7e6920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f2252342c341a7b8c49c2d352ea544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f383ef05cde7424f95aab5805f9eda4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7efd47eec8a47b7884b5049be9f60da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69158e5df174a8690262ea1d89c9f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d669d7e20fe440fbb1e11d2d047d4722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd49cc9235648369576e13b6dd9ca72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9ecca0fdde49d186533441cdae352b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "log_model_results(model_name='BERT4Rec Base (self-made)', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'embedding_dim': embedding_dim, 'num_layers': num_layers, 'num_heads': num_heads, 'ffn_dim': ffn_dim,\n",
    "                                'dropout': dropout, 'lr': lr, 'weight_decay': weight_decay, 'warmup': True if warmup_steps else False})\n",
    "\n",
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "log_model_results(model_name='BERT4Rec + Content embeddings (self-made)', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'embedding_dim': embedding_dim, 'external_features_dim': item_features_tensor.shape[1], 'num_layers': num_layers, 'num_heads': num_heads, 'ffn_dim': ffn_dim,\n",
    "                                'dropout': dropout, 'lr': lr, 'weight_decay': weight_decay, 'warmup': True if warmup_steps else False})\n",
    "\n",
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "log_model_results(model_name='BERT4Rec Base (RePlay)', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'embedding_dim': embedding_dim, 'num_layers': num_layers, 'num_heads': num_heads, \n",
    "                                'dropout': dropout, 'lr': lr, 'weight_decay': weight_decay, 'warmup': True if warmup_steps else False})\n",
    "\n",
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "log_model_results(model_name='BERT4Rec + Content embeddings (RePlay)', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'embedding_dim': embedding_dim, 'external_features_dim': item_features_tensor.shape[1], 'num_layers': num_layers, 'num_heads': num_heads, \n",
    "                                'dropout': dropout, 'lr': lr, 'weight_decay': weight_decay, 'warmup': True if warmup_steps else False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a987f077-49d7-4fbb-8ff9-9ec4aad1365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_users': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_items': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matrix Factorization</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>{'top_k_items': 10, 'latent_dim': 256, 'filter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BERT4Rec Base (self-made)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>{'embedding_dim': 512, 'num_layers': 8, 'num_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BERT4Rec + Content embeddings (self-made)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>{'embedding_dim': 512, 'external_features_dim'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BERT4Rec Base (RePlay)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>{'embedding_dim': 512, 'num_layers': 8, 'num_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BERT4Rec + Content embeddings (RePlay)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>{'embedding_dim': 512, 'external_features_dim'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model   k  Precision@k  Recall@k  \\\n",
       "0                                      Top-K  10     0.000750  0.000746   \n",
       "1                                     Random  10     0.000008  0.000007   \n",
       "2                                       UBCF  10     0.002063  0.002062   \n",
       "3                                       IBCF  10     0.001968  0.001773   \n",
       "4                       Matrix Factorization  10     0.003033  0.002432   \n",
       "5                  BERT4Rec Base (self-made)  10     0.008631  0.008005   \n",
       "6  BERT4Rec + Content embeddings (self-made)  10     0.012567  0.011975   \n",
       "7                     BERT4Rec Base (RePlay)  10     0.008597  0.007994   \n",
       "8     BERT4Rec + Content embeddings (RePlay)  10     0.011717  0.011167   \n",
       "\n",
       "      MAP@k    NDCG@k                              Other_hyperparameters  \n",
       "0  0.000105  0.000286                                                NaN  \n",
       "1  0.000002  0.000004                                                NaN  \n",
       "2  0.000344  0.000866  {'top_k_items': 10, 'top_n_similar_users': 20,...  \n",
       "3  0.000253  0.000643  {'top_k_items': 10, 'top_n_similar_items': 20,...  \n",
       "4  0.000304  0.000745  {'top_k_items': 10, 'latent_dim': 256, 'filter...  \n",
       "5  0.001404  0.003455  {'embedding_dim': 512, 'num_layers': 8, 'num_h...  \n",
       "6  0.002303  0.005688  {'embedding_dim': 512, 'external_features_dim'...  \n",
       "7  0.001378  0.003432  {'embedding_dim': 512, 'num_layers': 8, 'num_h...  \n",
       "8  0.002190  0.005496  {'embedding_dim': 512, 'external_features_dim'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv: Recommender System with LLM)",
   "language": "python",
   "name": "recommender_system_with_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
