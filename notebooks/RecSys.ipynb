{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca364ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>photo_analytics</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>image_path</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144513</th>\n",
       "      <td>ttqvwwy</td>\n",
       "      <td>Белый</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Домашняя, пляжная одежда</td>\n",
       "      <td>Белье</td>\n",
       "      <td>Трусы</td>\n",
       "      <td>Хлопковые хипсы</td>\n",
       "      <td>11244493</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/f9/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.07257111370563507, 0.10438919067382812, -0...</td>\n",
       "      <td>[0.005394997540861368, 0.0019367658533155918, ...</td>\n",
       "      <td>[0.15677763521671295, 0.09177983552217484, -0....</td>\n",
       "      <td>[0.008346126414835453, 0.0, 0.0, 0.01302516460...</td>\n",
       "      <td>[-0.07229193300008774, -0.08663409948348999, 0...</td>\n",
       "      <td>[0.9217937588691711, 0.9253275990486145, 0.188...</td>\n",
       "      <td>[0.42168906331062317, 0.7095676064491272, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182274</th>\n",
       "      <td>tpvpuqy</td>\n",
       "      <td>Коричневый</td>\n",
       "      <td>Brioni</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Аксессуары (крокодил)</td>\n",
       "      <td>SLG (крокодил)</td>\n",
       "      <td>Обложка из кожи аллигатора</td>\n",
       "      <td>2409199</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/b5/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.08672484755516052, -0.05610058829188347, 0...</td>\n",
       "      <td>[0.007125582080334425, -0.013315664604306221, ...</td>\n",
       "      <td>[0.08674934506416321, 0.26948854327201843, -0....</td>\n",
       "      <td>[0.08135399222373962, 0.0, 0.16632328927516937...</td>\n",
       "      <td>[0.13018156588077545, 0.4195946753025055, 0.94...</td>\n",
       "      <td>[0.7369226217269897, 0.8566548824310303, 0.243...</td>\n",
       "      <td>[0.10639699548482895, 0.611497700214386, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135385</th>\n",
       "      <td>tusvvrt</td>\n",
       "      <td>Голубой</td>\n",
       "      <td>Dal Lago</td>\n",
       "      <td>Товары для детей</td>\n",
       "      <td>Аксессуары</td>\n",
       "      <td>Галстуки</td>\n",
       "      <td>Галстук</td>\n",
       "      <td>Шелковый галстук</td>\n",
       "      <td>10356002</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/33/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[0.14586126804351807, 0.0035078078508377075, 0...</td>\n",
       "      <td>[-0.016215097159147263, 0.023879103362560272, ...</td>\n",
       "      <td>[0.28992846608161926, 0.1429639607667923, -0.6...</td>\n",
       "      <td>[0.1026008129119873, 0.0, 0.004494321532547474...</td>\n",
       "      <td>[0.003677934408187866, 0.2602979838848114, 0.9...</td>\n",
       "      <td>[1.069815754890442, 0.9146437048912048, 0.2484...</td>\n",
       "      <td>[0.29046159982681274, 0.522162139415741, 0.409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249424</th>\n",
       "      <td>wqsvuwy</td>\n",
       "      <td>Разноцветный</td>\n",
       "      <td>Lancel</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Аксессуары</td>\n",
       "      <td>Платки</td>\n",
       "      <td>Платок шелковый</td>\n",
       "      <td>Шелковый платок</td>\n",
       "      <td>13567982</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/f5/9...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[0.14456921815872192, -0.06249238923192024, -0...</td>\n",
       "      <td>[0.013126503676176071, -0.0019127298146486282,...</td>\n",
       "      <td>[0.22613008320331573, 0.1457078456878662, -0.1...</td>\n",
       "      <td>[0.030423777177929878, 0.0, 0.0, 0.08489743620...</td>\n",
       "      <td>[0.15574012696743011, -0.3459433317184448, 0.6...</td>\n",
       "      <td>[0.6875616312026978, 0.6793960332870483, 0.354...</td>\n",
       "      <td>[0.42158013582229614, 0.2945811450481415, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182254</th>\n",
       "      <td>ttquswt</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Giorgio Armani</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Бижутерия</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>11201309</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/76/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.12436471879482269, -0.030923746526241302, ...</td>\n",
       "      <td>[-0.01337357982993126, -0.0029991380870342255,...</td>\n",
       "      <td>[-0.09756504744291306, -0.15952929854393005, 0...</td>\n",
       "      <td>[0.03119073063135147, 0.0002419875527266413, 0...</td>\n",
       "      <td>[0.5343070030212402, 0.26047518849372864, 0.37...</td>\n",
       "      <td>[0.7018769979476929, 0.5926704406738281, 0.369...</td>\n",
       "      <td>[0.2984030842781067, 0.4144335687160492, -0.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred    color_base           brand               ktt1  \\\n",
       "144513           ttqvwwy         Белый   Dolce&Gabbana  Товары для мужчин   \n",
       "182274           tpvpuqy    Коричневый          Brioni  Товары для мужчин   \n",
       "135385           tusvvrt       Голубой        Dal Lago   Товары для детей   \n",
       "249424           wqsvuwy  Разноцветный          Lancel  Товары для женщин   \n",
       "182254           ttquswt        Чёрный  Giorgio Armani  Товары для женщин   \n",
       "\n",
       "                            ktt2                   ktt3             ktt4  \\\n",
       "144513  Домашняя, пляжная одежда                  Белье            Трусы   \n",
       "182274        Аксессуары из кожи  Аксессуары (крокодил)   SLG (крокодил)   \n",
       "135385                Аксессуары               Галстуки          Галстук   \n",
       "249424                Аксессуары                 Платки  Платок шелковый   \n",
       "182254                 Бижутерия                  Брошь            Брошь   \n",
       "\n",
       "                              title  product_id product_created_at  ...  \\\n",
       "144513              Хлопковые хипсы    11244493         2016-08-14  ...   \n",
       "182274  Обложка из кожи аллигатора      2409199         2013-09-12  ...   \n",
       "135385             Шелковый галстук    10356002         2015-07-20  ...   \n",
       "249424              Шелковый платок    13567982         2020-06-25  ...   \n",
       "182254                        Брошь    11201309         2016-07-26  ...   \n",
       "\n",
       "                                          photo_analytics sales_total  \\\n",
       "144513  https://st-cdn.tsum.com/int/height/1526//i/f9/...        0.01   \n",
       "182274  https://st-cdn.tsum.com/int/height/1526//i/b5/...        0.01   \n",
       "135385  https://st-cdn.tsum.com/int/height/1526//i/33/...        0.01   \n",
       "249424  https://st-cdn.tsum.com/int/height/1526/i/f5/9...        0.01   \n",
       "182254  https://st-cdn.tsum.com/int/height/1526//i/76/...        0.01   \n",
       "\n",
       "                                               image_path  \\\n",
       "144513  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "182274  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "135385  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "249424  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "182254  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "144513  [-0.07257111370563507, 0.10438919067382812, -0...   \n",
       "182274  [-0.08672484755516052, -0.05610058829188347, 0...   \n",
       "135385  [0.14586126804351807, 0.0035078078508377075, 0...   \n",
       "249424  [0.14456921815872192, -0.06249238923192024, -0...   \n",
       "182254  [-0.12436471879482269, -0.030923746526241302, ...   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "144513  [0.005394997540861368, 0.0019367658533155918, ...   \n",
       "182274  [0.007125582080334425, -0.013315664604306221, ...   \n",
       "135385  [-0.016215097159147263, 0.023879103362560272, ...   \n",
       "249424  [0.013126503676176071, -0.0019127298146486282,...   \n",
       "182254  [-0.01337357982993126, -0.0029991380870342255,...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "144513  [0.15677763521671295, 0.09177983552217484, -0....   \n",
       "182274  [0.08674934506416321, 0.26948854327201843, -0....   \n",
       "135385  [0.28992846608161926, 0.1429639607667923, -0.6...   \n",
       "249424  [0.22613008320331573, 0.1457078456878662, -0.1...   \n",
       "182254  [-0.09756504744291306, -0.15952929854393005, 0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "144513  [0.008346126414835453, 0.0, 0.0, 0.01302516460...   \n",
       "182274  [0.08135399222373962, 0.0, 0.16632328927516937...   \n",
       "135385  [0.1026008129119873, 0.0, 0.004494321532547474...   \n",
       "249424  [0.030423777177929878, 0.0, 0.0, 0.08489743620...   \n",
       "182254  [0.03119073063135147, 0.0002419875527266413, 0...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "144513  [-0.07229193300008774, -0.08663409948348999, 0...   \n",
       "182274  [0.13018156588077545, 0.4195946753025055, 0.94...   \n",
       "135385  [0.003677934408187866, 0.2602979838848114, 0.9...   \n",
       "249424  [0.15574012696743011, -0.3459433317184448, 0.6...   \n",
       "182254  [0.5343070030212402, 0.26047518849372864, 0.37...   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "144513  [0.9217937588691711, 0.9253275990486145, 0.188...   \n",
       "182274  [0.7369226217269897, 0.8566548824310303, 0.243...   \n",
       "135385  [1.069815754890442, 0.9146437048912048, 0.2484...   \n",
       "249424  [0.6875616312026978, 0.6793960332870483, 0.354...   \n",
       "182254  [0.7018769979476929, 0.5926704406738281, 0.369...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \n",
       "144513  [0.42168906331062317, 0.7095676064491272, 0.10...  \n",
       "182274  [0.10639699548482895, 0.611497700214386, -0.01...  \n",
       "135385  [0.29046159982681274, 0.522162139415741, 0.409...  \n",
       "249424  [0.42158013582229614, 0.2945811450481415, 0.35...  \n",
       "182254  [0.2984030842781067, 0.4144335687160492, -0.12...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ViTImageProcessor, ViTModel, AutoImageProcessor, ResNetModel, CLIPProcessor, CLIPModel\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "file_path = Path().resolve() # Path(__file__).resolve()\n",
    "project_dir = file_path.parent\n",
    "raw_data_path = project_dir / 'data' / 'raw'\n",
    "products_data_dir = project_dir / 'data' / 'interim' / 'products_data'\n",
    "processed_images_dir = products_data_dir / 'processed_images_224x224'\n",
    "products_data_file = products_data_dir / 'products_data.parquet'\n",
    "products_data_csv = products_data_dir / 'products_data.csv'\n",
    "processed_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_parq = pd.read_parquet(products_data_file)\n",
    "df_parq.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48105b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "articul_encrypred                                                                         twuwvxs\n",
       "color_base                                                                                  Белый\n",
       "brand                                                                               Dolce&Gabbana\n",
       "ktt1                                                                            Товары для женщин\n",
       "ktt2                                                                                        Обувь\n",
       "ktt3                                                                                    Кроссовки\n",
       "ktt4                                                                                    Кроссовки\n",
       "title                                                         Комбинированные кроссовки Airmaster\n",
       "product_id                                                                               12883630\n",
       "product_created_at                                                                     2018-08-16\n",
       "slug                                            5646792-kombinirovannye-krossovki-airmaster-do...\n",
       "photo_analytics                                 https://st-cdn.tsum.com/int/height/1526/i/6e/9...\n",
       "sales_total                                                                           71904201.59\n",
       "image_path                                      /Users/dimi3tru/Downloads/Downloads/my_python_...\n",
       "CLS_google_vit_huge_patch14_224_in21k           [-0.04274410009384155, -0.0033653834834694862,...\n",
       "mean_patch_google_vit_huge_patch14_224_in21k    [0.03472045063972473, -0.01858200877904892, -0...\n",
       "pooled_google_vit_huge_patch14_224_in21k        [0.23270520567893982, 0.09708333760499954, 0.1...\n",
       "pooled_microsoft_resnet50                       [0.0, 0.0, 0.0015442443545907736, 0.0213666912...\n",
       "CLS_openai_clip_vit_large_patch14               [0.11746317148208618, -0.15724299848079681, 0....\n",
       "mean_patch_openai_clip_vit_large_patch14        [0.9459919333457947, 0.929914116859436, 0.2576...\n",
       "pooled_openai_clip_vit_large_patch14            [0.23329006135463715, 0.6403837203979492, 0.08...\n",
       "Name: 15814, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parq.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54324ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>photo_analytics</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>image_path</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>twuwvxs</td>\n",
       "      <td>Белый</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Обувь</td>\n",
       "      <td>Кроссовки</td>\n",
       "      <td>Кроссовки</td>\n",
       "      <td>Комбинированные кроссовки Airmaster</td>\n",
       "      <td>12883630</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/6e/9...</td>\n",
       "      <td>71904201.59</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.04274410009384155, -0.0033653834834694862,...</td>\n",
       "      <td>[0.03472045063972473, -0.01858200877904892, -0...</td>\n",
       "      <td>[0.23270520567893982, 0.09708333760499954, 0.1...</td>\n",
       "      <td>[0.0, 0.0, 0.0015442443545907736, 0.0213666912...</td>\n",
       "      <td>[0.11746317148208618, -0.15724299848079681, 0....</td>\n",
       "      <td>[0.9459919333457947, 0.929914116859436, 0.2576...</td>\n",
       "      <td>[0.23329006135463715, 0.6403837203979492, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>ttxswyq</td>\n",
       "      <td>Белый</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Обувь</td>\n",
       "      <td>Кроссовки</td>\n",
       "      <td>Кроссовки</td>\n",
       "      <td>Комбинированные кроссовки Daymaster</td>\n",
       "      <td>12233752</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/e1/a...</td>\n",
       "      <td>64809068.81</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.010253552347421646, -0.07573072612285614, ...</td>\n",
       "      <td>[0.01124664768576622, -0.021048562601208687, -...</td>\n",
       "      <td>[0.03662307187914848, 0.13447153568267822, 0.1...</td>\n",
       "      <td>[0.007274515461176634, 0.0, 0.0511035621166229...</td>\n",
       "      <td>[0.41813188791275024, -0.3611399531364441, 0.4...</td>\n",
       "      <td>[0.8358477354049683, 0.86273193359375, 0.24902...</td>\n",
       "      <td>[0.1594328135251999, 0.6418282985687256, 0.079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128629</th>\n",
       "      <td>wqtxrpy</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Обувь</td>\n",
       "      <td>Кеды</td>\n",
       "      <td>Кеды</td>\n",
       "      <td>Кожаные кеды Portofino</td>\n",
       "      <td>13387503</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/58/b...</td>\n",
       "      <td>62727148.93</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.05949850007891655, -0.008946864865720272, ...</td>\n",
       "      <td>[0.00728317117318511, 0.008306711912155151, -0...</td>\n",
       "      <td>[-0.08969734609127045, 0.318795382976532, -0.0...</td>\n",
       "      <td>[0.03766823187470436, 0.0, 0.02403734065592289...</td>\n",
       "      <td>[0.7070037722587585, -0.03052520751953125, 0.5...</td>\n",
       "      <td>[0.8207688331604004, 0.940047025680542, 0.2712...</td>\n",
       "      <td>[0.11110363155603409, 0.6902651786804199, 0.37...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred color_base          brand               ktt1   ktt2  \\\n",
       "15814            twuwvxs      Белый  Dolce&Gabbana  Товары для женщин  Обувь   \n",
       "3124             ttxswyq      Белый  Dolce&Gabbana  Товары для женщин  Обувь   \n",
       "128629           wqtxrpy     Чёрный  Dolce&Gabbana  Товары для мужчин  Обувь   \n",
       "\n",
       "             ktt3       ktt4                                title  product_id  \\\n",
       "15814   Кроссовки  Кроссовки  Комбинированные кроссовки Airmaster    12883630   \n",
       "3124    Кроссовки  Кроссовки  Комбинированные кроссовки Daymaster    12233752   \n",
       "128629       Кеды       Кеды               Кожаные кеды Portofino    13387503   \n",
       "\n",
       "       product_created_at  ...  \\\n",
       "15814          2018-08-16  ...   \n",
       "3124           2017-08-17  ...   \n",
       "128629         2019-07-24  ...   \n",
       "\n",
       "                                          photo_analytics  sales_total  \\\n",
       "15814   https://st-cdn.tsum.com/int/height/1526/i/6e/9...  71904201.59   \n",
       "3124    https://st-cdn.tsum.com/int/height/1526/i/e1/a...  64809068.81   \n",
       "128629  https://st-cdn.tsum.com/int/height/1526/i/58/b...  62727148.93   \n",
       "\n",
       "                                               image_path  \\\n",
       "15814   /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "3124    /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "128629  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "15814   [-0.04274410009384155, -0.0033653834834694862,...   \n",
       "3124    [-0.010253552347421646, -0.07573072612285614, ...   \n",
       "128629  [-0.05949850007891655, -0.008946864865720272, ...   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "15814   [0.03472045063972473, -0.01858200877904892, -0...   \n",
       "3124    [0.01124664768576622, -0.021048562601208687, -...   \n",
       "128629  [0.00728317117318511, 0.008306711912155151, -0...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "15814   [0.23270520567893982, 0.09708333760499954, 0.1...   \n",
       "3124    [0.03662307187914848, 0.13447153568267822, 0.1...   \n",
       "128629  [-0.08969734609127045, 0.318795382976532, -0.0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "15814   [0.0, 0.0, 0.0015442443545907736, 0.0213666912...   \n",
       "3124    [0.007274515461176634, 0.0, 0.0511035621166229...   \n",
       "128629  [0.03766823187470436, 0.0, 0.02403734065592289...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "15814   [0.11746317148208618, -0.15724299848079681, 0....   \n",
       "3124    [0.41813188791275024, -0.3611399531364441, 0.4...   \n",
       "128629  [0.7070037722587585, -0.03052520751953125, 0.5...   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "15814   [0.9459919333457947, 0.929914116859436, 0.2576...   \n",
       "3124    [0.8358477354049683, 0.86273193359375, 0.24902...   \n",
       "128629  [0.8207688331604004, 0.940047025680542, 0.2712...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \n",
       "15814   [0.23329006135463715, 0.6403837203979492, 0.08...  \n",
       "3124    [0.1594328135251999, 0.6418282985687256, 0.079...  \n",
       "128629  [0.11110363155603409, 0.6902651786804199, 0.37...  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parq[df_parq['pooled_microsoft_resnet50'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243da8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parq[df_parq['pooled_microsoft_resnet50'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7df648-b540-4c5f-a119-0f341dc3c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые импорты\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import random\n",
    "# from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Импорты для RecSys\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "# from surprise import SVD, Dataset, Reader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.set_per_process_memory_fraction(0.95)  # Ограничение памяти до 80%\n",
    "# torch.mps.empty_cache()\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7e6c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7a4dda-0964-49d1-8812-6c0bb98246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import weakref\n",
    "\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "#             ref = weakref.ref(obj)\n",
    "#             del obj\n",
    "#             del ref\n",
    "#     except ReferenceError:\n",
    "#         pass\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps:\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931cb14-3e62-4c69-b4cc-b034940382c2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0547cd-2267-4636-b82d-752f33e3c2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>sizeid</th>\n",
       "      <th>size_title</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>base_price</th>\n",
       "      <th>net_price</th>\n",
       "      <th>sale_percentage</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3485910</th>\n",
       "      <td>wyyypqqtpqqyuqqx</td>\n",
       "      <td>vqquspp</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда верхняя</td>\n",
       "      <td>Жилеты</td>\n",
       "      <td>Утепленный жилет</td>\n",
       "      <td>13627178</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7004211-uteplennyi-zhilet-dolce-gabbana-chernyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/ad/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485911</th>\n",
       "      <td>wyyyrqqtqqrruyyp</td>\n",
       "      <td>vqsywtp</td>\n",
       "      <td>Серый</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>The Attico</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда джинсовая</td>\n",
       "      <td>Куртка джинсовая</td>\n",
       "      <td>Джинсовая куртка</td>\n",
       "      <td>13661506</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>238500.0</td>\n",
       "      <td>222965.8</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>7028651-dzhinsovaya-kurtka-the-attico-temno-seryi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/7c/7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred color_base sizeid size_title  \\\n",
       "3485910  wyyypqqtpqqyuqqx           vqquspp     Чёрный     48         48   \n",
       "3485911  wyyyrqqtqqrruyyp           vqsywtp      Серый     40         42   \n",
       "\n",
       "         order_date store          brand               ktt1    ktt2  \\\n",
       "3485910  2021-02-18     T  Dolce&Gabbana  Товары для мужчин  Одежда   \n",
       "3485911  2021-02-18     T     The Attico  Товары для женщин  Одежда   \n",
       "\n",
       "                     ktt3              ktt4             title  product_id  \\\n",
       "3485910    Одежда верхняя            Жилеты  Утепленный жилет    13627178   \n",
       "3485911  Одежда джинсовая  Куртка джинсовая  Джинсовая куртка    13661506   \n",
       "\n",
       "        product_created_at  base_price  net_price  sale_percentage  \\\n",
       "3485910         2020-10-21    124500.0   124500.0         0.000000   \n",
       "3485911         2021-02-01    238500.0   222965.8         0.065133   \n",
       "\n",
       "                                                      slug  \\\n",
       "3485910    7004211-uteplennyi-zhilet-dolce-gabbana-chernyi   \n",
       "3485911  7028651-dzhinsovaya-kurtka-the-attico-temno-seryi   \n",
       "\n",
       "                                           photo_analytics  \n",
       "3485910  https://st-cdn.tsum.com/int/height/1526/i/ad/b...  \n",
       "3485911  https://st-cdn.tsum.com/int/height/1526/i/7c/7...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_path = Path().resolve()\n",
    "project_dir = notebook_path.parent\n",
    "\n",
    "raw_data_path = project_dir / 'data' / 'raw'\n",
    "\n",
    "# df_parsed = pd.read_csv(raw_data_path / 'all.csv', sep=';')\n",
    "# df_sales = pd.read_csv(raw_data_path / 'all_orders_encrypted_2020_small_30012024_3.csv', sep=',')\n",
    "# df_assortment = pd.read_csv(raw_data_path / 'tsum_assortment_31012025.csv', sep=',')\n",
    "df_full_order = pd.read_csv(raw_data_path / 'full_orders_v6.csv', sep=None, engine='python')\n",
    "\n",
    "# display(df_parsed.tail(2), df_sales.tail(2), df_assortment.tail(2), df_full_order.tail(2))\n",
    "df_full_order.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715321d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anon_id_encrypred', 'articul_encrypred', 'color_base', 'sizeid',\n",
       "       'size_title', 'order_date', 'store', 'brand', 'ktt1', 'ktt2', 'ktt3',\n",
       "       'ktt4', 'title', 'product_id', 'product_created_at', 'base_price',\n",
       "       'net_price', 'sale_percentage', 'slug', 'photo_analytics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_order.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892ffb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314113, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_order[['articul_encrypred', 'product_id']].drop_duplicates(ignore_index=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012507, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_order[['articul_encrypred', 'color_base', 'sizeid', 'size_title', 'brand', 'ktt1', 'ktt2', 'ktt3', 'ktt4', \n",
    "               'title', 'product_id', 'product_created_at', 'slug', 'photo_analytics']].drop_duplicates(ignore_index=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55c4162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306976, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_order[['articul_encrypred', 'color_base', 'brand', 'ktt1', 'ktt2', 'ktt3', 'ktt4', \n",
    "               'title', 'product_id', 'product_created_at', 'slug', 'photo_analytics']].dropna(subset=['photo_analytics']).drop_duplicates(ignore_index=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba3df99b-df71-4157-8c56-0825361a43cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>sizeid</th>\n",
       "      <th>size_title</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>base_price</th>\n",
       "      <th>net_price</th>\n",
       "      <th>sale_percentage</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3231100</th>\n",
       "      <td>wyyypqqtpqqyuqqx</td>\n",
       "      <td>vqquspp</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда верхняя</td>\n",
       "      <td>Жилеты</td>\n",
       "      <td>Утепленный жилет</td>\n",
       "      <td>13627178</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7004211-uteplennyi-zhilet-dolce-gabbana-chernyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/ad/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231101</th>\n",
       "      <td>wyyyrqqtqqrruyyp</td>\n",
       "      <td>vqsywtp</td>\n",
       "      <td>Серый</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>The Attico</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда джинсовая</td>\n",
       "      <td>Куртка джинсовая</td>\n",
       "      <td>Джинсовая куртка</td>\n",
       "      <td>13661506</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>238500.0</td>\n",
       "      <td>222965.8</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>7028651-dzhinsovaya-kurtka-the-attico-temno-seryi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/7c/7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred color_base sizeid size_title  \\\n",
       "3231100  wyyypqqtpqqyuqqx           vqquspp     Чёрный     48         48   \n",
       "3231101  wyyyrqqtqqrruyyp           vqsywtp      Серый     40         42   \n",
       "\n",
       "         order_date store          brand               ktt1    ktt2  \\\n",
       "3231100  2021-02-18     T  Dolce&Gabbana  Товары для мужчин  Одежда   \n",
       "3231101  2021-02-18     T     The Attico  Товары для женщин  Одежда   \n",
       "\n",
       "                     ktt3              ktt4             title  product_id  \\\n",
       "3231100    Одежда верхняя            Жилеты  Утепленный жилет    13627178   \n",
       "3231101  Одежда джинсовая  Куртка джинсовая  Джинсовая куртка    13661506   \n",
       "\n",
       "        product_created_at  base_price  net_price  sale_percentage  \\\n",
       "3231100         2020-10-21    124500.0   124500.0         0.000000   \n",
       "3231101         2021-02-01    238500.0   222965.8         0.065133   \n",
       "\n",
       "                                                      slug  \\\n",
       "3231100    7004211-uteplennyi-zhilet-dolce-gabbana-chernyi   \n",
       "3231101  7028651-dzhinsovaya-kurtka-the-attico-temno-seryi   \n",
       "\n",
       "                                           photo_analytics  \n",
       "3231100  https://st-cdn.tsum.com/int/height/1526/i/ad/b...  \n",
       "3231101  https://st-cdn.tsum.com/int/height/1526/i/7c/7...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_purchase_days_per_user = 100 # Максимальное количество покупок для включения в выборку (покупка - уникальная связка user-day)\n",
    "min_purchases_per_user = 2 # Минимальное количество покупок для включения в выборку (покупка - взаимодействие user-item)\n",
    "\n",
    "# Исключаем \"реселлеров\" (пользователей с большим количеством уникальных дней покупок, покупка 5 айтемов в 1 день - 1 покупка)\n",
    "purchase_days = df_full_order.groupby('anon_id_encrypred')['order_date'].nunique().reset_index()\n",
    "purchase_days.columns = ['anon_id_encrypred', 'unique_purchase_days']\n",
    "resellers = purchase_days[purchase_days['unique_purchase_days'] > max_purchase_days_per_user]['anon_id_encrypred']\n",
    "\n",
    "# Исключаем пользователей с недостаточным количеством покупок (покупка 5 айтемов в 1 день - 5 покупок)\n",
    "user_purchase_counts = df_full_order['anon_id_encrypred'].value_counts()\n",
    "\n",
    "df_filtered = (df_full_order[~df_full_order['anon_id_encrypred'].isin(resellers)]\n",
    "               [df_full_order['anon_id_encrypred'].isin(user_purchase_counts[user_purchase_counts >= min_purchases_per_user].index)]).reset_index(drop=True)\n",
    "\n",
    "del df_full_order\n",
    "\n",
    "df_filtered.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c3fb1-d990-47f8-a8e3-aa0ff9260640",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76daa2ba-dbc4-43d1-b2f2-7217b2d6007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, user_recommendations, user_to_true_items, k):\n",
    "        self.users = list(user_recommendations.keys())\n",
    "        self.recommendations = [torch.LongTensor(recs) for recs in user_recommendations.values()]\n",
    "        self.true_items = [torch.LongTensor(list(user_to_true_items.get(u, []))) for u in self.users]\n",
    "        self.k = k\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'recs': self.recommendations[idx][:self.k],\n",
    "            'true': self.true_items[idx]\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'recs': torch.stack([item['recs'] for item in batch]),\n",
    "        'true': [item['true'] for item in batch]\n",
    "    }\n",
    "\n",
    "\n",
    "def precision_at_k_gpu(loader, k=5, batch_size=256, device=device):\n",
    "    precision_sum = 0\n",
    "    total_users = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Precision@K'):\n",
    "            recs = batch['recs'].to(device)  # Рекомендации\n",
    "            \n",
    "            # Преобразуем true_items в тензор и перемещаем на устройство\n",
    "            true_items = [torch.tensor(items) for items in batch['true']]  # Преобразуем каждый список в тензор\n",
    "            true_items = [items.to(device) for items in true_items]  # Перемещаем каждый тензор на устройство\n",
    "            \n",
    "            # Ограничиваем рекомендации первыми k элементами\n",
    "            recs = recs[:, :k]\n",
    "            \n",
    "            # Вычисляем precision@k для каждого пользователя в батче\n",
    "            batch_precision = 0\n",
    "            for i in range(len(recs)):\n",
    "                # Создаем маску для истинных элементов\n",
    "                true_mask = torch.isin(recs[i], true_items[i])\n",
    "                # Вот тут минимум из-за того, что в тесте может быть кейс, когда клиент сделал 1 покупку, мы её угадали, но получаем всего 1/k пресижна вместо 1\n",
    "                precision = true_mask.float().sum() / min(k, len(true_items[i]))  \n",
    "                batch_precision += precision.item()  # Используем .item() для получения числа\n",
    "            \n",
    "            # Суммируем precision для всех пользователей\n",
    "            precision_sum += batch_precision\n",
    "            total_users += len(recs)\n",
    "    \n",
    "    return precision_sum / total_users\n",
    "\n",
    "def recall_at_k_gpu(loader, k=5, batch_size=256, device=device):\n",
    "    recall_sum = 0\n",
    "    total_users = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Recall@K'):\n",
    "            recs = batch['recs'].to(device)  # Рекомендации\n",
    "            \n",
    "            # Преобразуем true_items в тензоры сразу на устройстве\n",
    "            true_items = [torch.tensor(items, device=device) for items in batch['true']]\n",
    "            \n",
    "            # Ограничиваем рекомендации первыми k элементами\n",
    "            recs = recs[:, :k]\n",
    "            \n",
    "            # Вычисляем recall@k для каждого пользователя в батче\n",
    "            batch_recall = 0\n",
    "            for i in range(len(recs)):\n",
    "                if len(true_items[i]) > 0:\n",
    "                    true_mask = torch.isin(recs[i], true_items[i])\n",
    "                    recall = true_mask.sum().item() / len(true_items[i])  # Оптимизированное вычисление\n",
    "                    batch_recall += recall\n",
    "            \n",
    "            # Суммируем recall для всех пользователей\n",
    "            recall_sum += batch_recall\n",
    "            total_users += len(recs)\n",
    "    \n",
    "    return recall_sum / total_users\n",
    "    \n",
    "\n",
    "def map_at_k_gpu(loader, k=5, batch_size=256, device=device):\n",
    "    map_sum = 0\n",
    "    total_users = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='MAP@K'):\n",
    "            recs = batch['recs'].to(device)  # Рекомендации\n",
    "            \n",
    "            # Преобразуем true_items в тензоры сразу на устройстве\n",
    "            true_items = [torch.tensor(items, device=device) for items in batch['true']]\n",
    "            \n",
    "            # Ограничиваем рекомендации первыми k элементами\n",
    "            recs = recs[:, :k]\n",
    "            \n",
    "            # Вычисляем MAP@K для каждого пользователя в батче\n",
    "            batch_map = 0\n",
    "            for i in range(len(recs)):\n",
    "                if len(true_items[i]) > 0:\n",
    "                    hits = 0\n",
    "                    sum_precisions = 0\n",
    "                    \n",
    "                    for j, item in enumerate(recs[i]):  # Перебираем топ-K рекомендаций\n",
    "                        if item in true_items[i]:  # Если товар релевантен\n",
    "                            hits += 1\n",
    "                            sum_precisions += hits / (j + 1)  # AP@j = rel@j / j\n",
    "                            \n",
    "                    user_map = sum_precisions / min(len(true_items[i]), k) if hits > 0 else 0\n",
    "                    batch_map += user_map\n",
    "            \n",
    "            # Суммируем MAP для всех пользователей\n",
    "            map_sum += batch_map\n",
    "            total_users += len(recs)\n",
    "    \n",
    "    return map_sum / total_users\n",
    "\n",
    "\n",
    "def ndcg_at_k_gpu(loader, k=5, batch_size=256, device=device):\n",
    "    ndcg_sum = 0\n",
    "    total_users = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='NDCG@K'):\n",
    "            recs = batch['recs'].to(device)  # Рекомендации\n",
    "            \n",
    "            # Преобразуем true_items в тензоры сразу на устройстве\n",
    "            true_items = [torch.tensor(items, device=device) for items in batch['true']]\n",
    "            \n",
    "            # Ограничиваем рекомендации первыми k элементами\n",
    "            recs = recs[:, :k]\n",
    "            \n",
    "            # Вычисляем NDCG@K для каждого пользователя в батче\n",
    "            batch_ndcg = 0\n",
    "            for i in range(len(recs)):\n",
    "                if len(true_items[i]) > 0:\n",
    "                    # DCG@K\n",
    "                    dcg = 0\n",
    "                    for j, item in enumerate(recs[i]):  # Перебираем топ-K рекомендации\n",
    "                        if item in true_items[i]:\n",
    "                            dcg += 1 / torch.log2(torch.tensor(j + 2.0, device=device))\n",
    "\n",
    "                    # IDCG@K\n",
    "                    ideal_dcg = sum(1 / torch.log2(torch.tensor(j + 2.0, device=device)) for j in range(min(len(true_items[i]), k)))\n",
    "\n",
    "                    # NDCG@K\n",
    "                    ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "                    batch_ndcg += ndcg.item()\n",
    "            \n",
    "            # Суммируем NDCG для всех пользователей\n",
    "            ndcg_sum += batch_ndcg\n",
    "            total_users += len(recs)\n",
    "\n",
    "    return ndcg_sum / total_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a47c837-d7ec-4526-ae3b-f39c8a630f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_results(model_name, precision_k, recall_k, map_k, ndcg_k, k, hyperparameters=None, round_level=4):\n",
    "    '''\n",
    "    Добавляет результаты оценки модели в датафрейм.\n",
    "    \n",
    "    model_name: str – название модели\n",
    "    precision_k, recall_k, map_k, ndcg_k: torch.Tensor или float – метрики\n",
    "    k: int – значение K для метрик\n",
    "    hyperparameters: dict – гиперпараметры модели (опционально)\n",
    "    round_level: int – количество знаков после запятой для округления (по умолчанию 4)\n",
    "    '''\n",
    "    global df_metrics\n",
    "    \n",
    "    # Преобразуем тензоры в обычные числа и округляем (если они тензоры)\n",
    "    precision_k = round(precision_k.item() if isinstance(precision_k, torch.Tensor) else precision_k, round_level)\n",
    "    recall_k = round(recall_k.item() if isinstance(recall_k, torch.Tensor) else recall_k, round_level)\n",
    "    map_k = round(map_k.item() if isinstance(map_k, torch.Tensor) else map_k, round_level)\n",
    "    ndcg_k = round(ndcg_k.item() if isinstance(ndcg_k, torch.Tensor) else ndcg_k, round_level)\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'k': k,\n",
    "        'Precision@k': precision_k,\n",
    "        'Recall@k': recall_k,\n",
    "        'MAP@k': map_k,\n",
    "        'NDCG@k': ndcg_k,\n",
    "        'Other_hyperparameters': hyperparameters\n",
    "    }])\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics, new_row], ignore_index=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(columns=['Model', 'k', 'Precision@k', 'Recall@k', 'MAP@k', 'NDCG@k', 'Other_hyperparameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d3648-7b10-4194-86be-59363065dc73",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1259b4-022b-416e-8cb2-f955bfc6e142",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7e8cd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/dimi3tru/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = project_dir / 'data' / 'raw' / 'full_orders_v6.csv'\n",
    "project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512df89-a9ef-4132-b136-08aa155ee5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сортируем данные по времени и бьём на трейн и тест\n",
    "# df_filtered['order_date'] = pd.to_datetime(df_filtered['order_date'])\n",
    "# df_filtered = df_filtered.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "\n",
    "# for user, user_df in df_filtered.groupby('anon_id_encrypred'):\n",
    "#     split_idx = int(len(user_df) * 0.8)\n",
    "#     train_data.append(user_df.iloc[:split_idx])\n",
    "#     test_data.append(user_df.iloc[split_idx:])\n",
    "\n",
    "# train_df = pd.concat(train_data)\n",
    "# test_df = pd.concat(test_data)\n",
    "\n",
    "# interim_data_path = project_dir / 'data' / 'interim'\n",
    "# df_filtered.to_csv(interim_data_path / 'df_filtered.csv', index=False)\n",
    "# train_df.to_csv(interim_data_path / 'train_data_by_users.csv', index=False)\n",
    "# test_df.to_csv(interim_data_path / 'test_data_by_users.csv', index=False)\n",
    "\n",
    "# df_filtered = pd.read_csv(interim_data_path / 'df_filtered.csv')\n",
    "# train_df = pd.read_csv(interim_data_path / 'train_data_by_users.csv')\n",
    "# test_df = pd.read_csv(interim_data_path / 'test_data_by_users.csv')\n",
    "\n",
    "# print(f\"Train shape: {train_df.shape}\")\n",
    "# print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "816c5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2019-01-01 00:00:00\n",
      "Max date: 2021-02-18 00:00:00\n",
      "Threshold date (80.0%): 2020-09-15 00:00:00\n",
      "Train shape: (2526624, 20)\n",
      "Test shape: (704478, 20)\n"
     ]
    }
   ],
   "source": [
    "df_filtered['order_date'] = pd.to_datetime(df_filtered['order_date'])\n",
    "df_filtered = df_filtered.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "threshold_level = 0.8\n",
    "min_date = df_filtered['order_date'].min()\n",
    "max_date = df_filtered['order_date'].max()\n",
    "\n",
    "print(f\"Min date: {min_date}\")\n",
    "print(f\"Max date: {max_date}\")\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "threshold_days = int(total_days * threshold_level)\n",
    "threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "train_df = df_filtered[df_filtered['order_date'] < threshold_date]\n",
    "test_df = df_filtered[df_filtered['order_date'] >= threshold_date]\n",
    "\n",
    "interim_data_path = project_dir / 'data' / 'interim'\n",
    "df_filtered.to_csv(interim_data_path / 'df_filtered.csv', index=False)\n",
    "train_df.to_csv(interim_data_path / 'train_data_by_threshold_date.csv', index=False)\n",
    "test_df.to_csv(interim_data_path / 'test_data_by_threshold_date.csv', index=False)\n",
    "\n",
    "df_filtered = pd.read_csv(interim_data_path / 'df_filtered.csv')\n",
    "train_df = pd.read_csv(interim_data_path / 'train_data_by_threshold_date.csv')\n",
    "test_df = pd.read_csv(interim_data_path / 'test_data_by_threshold_date.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75999f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего пользователей: 273287\n",
      "Пользователей в тренировочной выборке: 242532\n",
      "Пользователей в тестовой выборке: 142987\n"
     ]
    }
   ],
   "source": [
    "# assert (len(train_df['anon_id_encrypred'].unique()) == \n",
    "#         len(test_df['anon_id_encrypred'].unique()) == \n",
    "#         len(df_filtered['anon_id_encrypred'].unique())), \"В выборках разное кол-во пользователей\"\n",
    "\n",
    "print(f\"Всего пользователей: {len(df_filtered['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тренировочной выборке: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тестовой выборке: {len(test_df['anon_id_encrypred'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b032b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee83965f75b3401b8b85aa80bbc94596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing test data:   0%|          | 0/142987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Для каждого пользователя формируем список покупок: (product_id, order_date)\n",
    "# test_user_to_true_items = {}\n",
    "# for user, user_df in tqdm(test_df.groupby('anon_id_encrypred'), desc='Preparing test data'):\n",
    "#     # user_df = user_df.sort_values(by='order_date')\n",
    "#     purchases = list(zip(user_df['product_id'], user_df['order_date']))\n",
    "#     test_user_to_true_items[user] = purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edc970-1bd8-411a-a29f-10c11418a180",
   "metadata": {},
   "source": [
    "### 1. Top-K Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa9a3e-3dd8-4ecd-ab58-a28a3e1d5031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bee16e7ec64405b90aa3fb9be74e3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "k = 6\n",
    "\n",
    "popular_items = train_df['product_id'].value_counts().index.tolist()\n",
    "\n",
    "def recommend_top_k(top_k_items=k):\n",
    "    return popular_items[:top_k_items]\n",
    "\n",
    "user_recommendations_top_k = {user: recommend_top_k(top_k_items=k) for user in tqdm(test_df['anon_id_encrypred'].unique())}\n",
    "\n",
    "dataset_top_k = RecommendationDataset(user_recommendations=user_recommendations_top_k, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_top_k, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3cf2548-9d9b-482d-936d-b017c7766712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbfa5c559484a82808382d0b2da8a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a34065bcec04b0e99854f56b775dfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.002409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45037e039cb452bb518e6868d6aeecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5344b99fd84c5ca96deb6d0b24e724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k: 0.00221\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c85fe4e-ef69-4bc8-aaeb-15879d72bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  k  Precision@k  Recall@k   MAP@k  NDCG@k Other_hyperparameters\n",
       "0  Top-K  6       0.0026    0.0024  0.0014  0.0022                  None"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Top-K', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996d325-c77b-434d-ba15-eb17e2608809",
   "metadata": {},
   "source": [
    "### 2. Random Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb35dc09-640d-46ed-ae31-0f4b3cc6e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35323020138e44d3b0305fddf5bbd086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning recommendations:   0%|          | 0/142987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "k = 6\n",
    "\n",
    "def recommend_random(df, top_k_items=k):\n",
    "    return np.random.choice(df.unique(), size=min(top_k_items, len(df.unique())), replace=False)\n",
    "\n",
    "random_recommendations = recommend_random(df=train_df['product_id'], top_k_items=k)\n",
    "user_recommendations_random = {user: random_recommendations for user in tqdm(test_df['anon_id_encrypred'].unique(), desc='Assigning recommendations')}\n",
    "\n",
    "dataset_random = RecommendationDataset(user_recommendations=user_recommendations_random, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_random, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfdb09d3-1cff-4823-b614-a75af109b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf78ef48a0184947981168d9fc89f839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28406e75f29248b89f473d2beb39fd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.000011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06a0f94f3d54f53a4bdbb655ce1e64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7c4bbcba4a4d968884ab927f9a7039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k: 0.00001\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d17403b2-e74b-4e05-bccd-50f65e603fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  k  Precision@k  Recall@k   MAP@k  NDCG@k Other_hyperparameters\n",
       "0   Top-K  6       0.0026    0.0024  0.0014  0.0022                  None\n",
       "1  Random  6       0.0000    0.0000  0.0000  0.0000                  None"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Random', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861ad65-6435-47bf-ad54-085126a7ba8a",
   "metadata": {},
   "source": [
    "### 3. User-Based Collaborative Filtering (UBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 142987/142987 [05:44<00:00, 414.96it/s]  \n"
     ]
    }
   ],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # Устройство – используем CPU, т.к. MPS не поддерживает sparse операции\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# # 1. Функция создания user-item матрицы (без изменений)\n",
    "# def create_user_item_matrix(df):\n",
    "#     user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "#     u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "#     p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "#     data = user_item_counts['count'].values\n",
    "#     user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "#     return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "# # 2. Вычисление низкоразмерных представлений пользователей с помощью Truncated SVD\n",
    "# def compute_user_embeddings(df, n_components=128):\n",
    "#     user_item_matrix, u_labels, _ = create_user_item_matrix(df)\n",
    "#     # Применяем логарифмическое сглаживание\n",
    "#     user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "#     svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "#     user_embeddings = svd.fit_transform(user_item_matrix)\n",
    "#     # Нормализуем каждую строку для косинусного сходства\n",
    "#     norms = np.linalg.norm(user_embeddings, axis=1, keepdims=True)\n",
    "#     norms[norms == 0] = 1.0\n",
    "#     user_embeddings_normalized = user_embeddings / norms\n",
    "#     # Переводим в torch.tensor\n",
    "#     user_embeddings_tensor = torch.tensor(user_embeddings_normalized, dtype=torch.float32, device=device)\n",
    "#     return user_embeddings_tensor, u_labels\n",
    "\n",
    "# # 3. Рекомендации на основе плотного косинусного сходства\n",
    "# def recommend_user_based_dense(\n",
    "#     user_ids,\n",
    "#     user_embeddings,\n",
    "#     user_labels,\n",
    "#     df, \n",
    "#     top_k_items=6,\n",
    "#     top_n_similar_users=20,\n",
    "#     filter_already_purchased=True\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Для каждого пользователя из user_ids вычисляем cosine similarity на основе user_embeddings,\n",
    "#     затем находим топ-N похожих пользователей и собираем их покупки.\n",
    "#     Если для пользователя нет данных (например, он отсутствует в тренировке),\n",
    "#     возвращаем дефолтные рекомендации — топ-k популярных товаров.\n",
    "#     \"\"\"\n",
    "#     # Собираем покупки из train_df\n",
    "#     user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "#     user_labels_index = pd.Index(user_labels)\n",
    "#     most_popular_items = df['product_id'].value_counts().index.tolist()\n",
    "#     recommendations = {}\n",
    "    \n",
    "#     for user_id in tqdm(user_ids, desc=\"Generating recommendations\"):\n",
    "#         try:\n",
    "#             u_idx = user_labels_index.get_loc(user_id)\n",
    "#         except KeyError:\n",
    "#             # Если пользователя нет в тренировочных данных, возвращаем дефолтные рекомендации\n",
    "#             recommendations[user_id] = np.array(most_popular_items[:top_k_items])\n",
    "#             continue\n",
    "        \n",
    "#         u_embedding = user_embeddings[u_idx].unsqueeze(0)  # shape (1, d)\n",
    "#         sim_vector = torch.mm(u_embedding, user_embeddings.t()).flatten()\n",
    "#         sim_vector[u_idx] = -float('inf')\n",
    "#         top_sim_scores, top_sim_indices = torch.topk(sim_vector, top_n_similar_users)\n",
    "#         similar_users_ids = user_labels[top_sim_indices.cpu().numpy()]\n",
    "#         user_bought = user_purchases.get(user_id, set())\n",
    "        \n",
    "#         product_counter = Counter()\n",
    "#         for sim_u in similar_users_ids:\n",
    "#             sim_bought = user_purchases.get(sim_u, set())\n",
    "#             new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "#             product_counter.update(new_items)\n",
    "        \n",
    "#         recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "        \n",
    "#         # Если полученных рекомендаций меньше, чем нужно, добиваем дефолтными популярными товарами\n",
    "#         if len(recommended_products) < top_k_items:\n",
    "#             needed_items = top_k_items - len(recommended_products)\n",
    "#             additional_items = [p for p in most_popular_items if p not in recommended_products and (p not in user_bought)]\n",
    "#             recommended_products.extend(additional_items[:needed_items])\n",
    "            \n",
    "#         recommendations[user_id] = np.array(recommended_products[:top_k_items])\n",
    "        \n",
    "#     return recommendations\n",
    "\n",
    "# # --- Пример использования ---\n",
    "# # Предполагаем, что у вас уже выполнен temporal split и у вас есть train_df и test_df.\n",
    "# # Вычисляем представления пользователей на train_df\n",
    "# user_embeddings, user_labels = compute_user_embeddings(train_df, n_components=128)\n",
    "\n",
    "# # Получаем уникальные user_ids из тестового набора\n",
    "# user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "# # Генерируем рекомендации для тестовых пользователей на основе dense similarity\n",
    "# user_recommendations_ubcf_svd = recommend_user_based_dense(\n",
    "#     user_ids=user_ids,\n",
    "#     user_embeddings=user_embeddings,\n",
    "#     user_labels=user_labels,\n",
    "#     df=train_df,\n",
    "#     top_k_items=6,\n",
    "#     top_n_similar_users=20,\n",
    "#     filter_already_purchased=filter_already_purchased\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ubcf_svd = RecommendationDataset(user_recommendations=user_recommendations_ubcf_svd, user_to_true_items=test_user_to_true_items, k=k)\n",
    "# loader = DataLoader(dataset_ubcf, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2af02504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "# recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "# map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "# ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4fae8f-9af4-4e6b-a35a-03ad6457aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6  # top_k_items\n",
    "n = 20  # top_n_similar_users\n",
    "batch_size = 1024\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_users = 1\n",
    "# Важно!!! Если у вас GPU desktop - комментируйте строку ниже\n",
    "device = torch.device(\"cpu\") # На macbook не работает sparce на msp\n",
    "\n",
    "# 1. Функция для создания user-item матрицы\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "\n",
    "# 2. Функция для вычисления матрицы сходства пользователей на GPU\n",
    "def compute_user_similarity(df):\n",
    "    \"\"\"\n",
    "    Создает user-item матрицу, логарифмирует count для сглаживания, \n",
    "    преобразует в sparse-тензор PyTorch, вычисляет косинусное сходство.\n",
    "    Возвращает user_similarity (sparse.mm результат) и user_labels.\n",
    "    \"\"\"\n",
    "    # Создаем user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Применяем log(1 + count), чтобы уменьшить влияние частых покупок\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # Преобразуем разреженную матрицу в PyTorch sparse_coo_tensor\n",
    "    # indices:  shape = (2, количество ненулевых элементов)\n",
    "    # values:   shape = (количество ненулевых элементов,)\n",
    "    # size:     (число пользователей, число товаров)\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # Нормализуем пользователей построчно для косинусного сходства\n",
    "    # row_norms.shape = (num_users,)\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(user_item_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Делим значения на норму соответствующей строки\n",
    "    # user_item_tensor.indices()[0] = индексы строк (пользователи)\n",
    "    normalized_values = user_item_tensor.values() / row_norms[user_item_tensor.indices()[0]]\n",
    "    user_item_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        user_item_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=user_item_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # Вычисляем матрицу сходства как M * M^T (косинусное сходство)\n",
    "    user_similarity = torch.sparse.mm(user_item_tensor_normalized, user_item_tensor_normalized.t())\n",
    "    \n",
    "    return user_similarity, user_labels  # product_labels не нужен для UBCF\n",
    "\n",
    "\n",
    "# 3. Функция рекомендаций (User-Based CF) на GPU с построчной обработкой\n",
    "def recommend_user_based_batch(\n",
    "    user_ids,\n",
    "    user_similarity,\n",
    "    user_labels,\n",
    "    df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_users=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации, основанные на top-N похожих пользователях.\n",
    "    \"\"\"\n",
    "    # Для быстрого поиска индекса пользователя по user_id\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    \n",
    "    # Список (или словарь) всех покупок пользователя\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Словарь: user_id -> список рекомендованных товаров\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Разбиваем на батчи только user_ids (чтобы не выделять память под всю dense-матрицу сразу)\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "    \n",
    "        # Для каждого пользователя в батче по очереди вытащим строку сходства (sparse)\n",
    "        for user_id in batch_user_ids:\n",
    "            # Получаем индекс пользователя в матрице user_similarity\n",
    "            try:\n",
    "                u_idx = user_labels_index.get_loc(user_id)\n",
    "            except KeyError:\n",
    "                # Если вдруг пользователя не оказалось в user_labels\n",
    "                recommendations[user_id] = np.array([])\n",
    "                continue\n",
    "    \n",
    "            # Извлекаем строку u_idx из user_similarity — это shape (1, num_users) (sparse)\n",
    "            row_sparse = user_similarity[u_idx]  # submatrix (1, U)\n",
    "            # Превращаем её в dense-вектор [U], но только для одного пользователя\n",
    "            row_dense = row_sparse.to_dense().flatten()  # теперь shape = [num_users]\n",
    "    \n",
    "            # Начинаем с базового `top_n_similar_users`\n",
    "            num_similar_users = top_n_similar_users\n",
    "            recommended_products = []\n",
    "            expansion_step = 0  # Количество расширений\n",
    "    \n",
    "            # Проверяем, нужно ли использовать динамическое увеличение top_n_similar_users\n",
    "            while (len(recommended_products) < top_k_items \n",
    "                    and n_iter_x5_top_n_similar_users is not None \n",
    "                    and n_iter_x5_top_n_similar_users > 0 \n",
    "                    and expansion_step <= n_iter_x5_top_n_similar_users):\n",
    "    \n",
    "                # Находим топ-N похожих пользователей (динамически увеличивая N)\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, num_similar_users + 1, dim=0)\n",
    "    \n",
    "                # Убираем самого пользователя (сходство с собой = 1)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask]\n",
    "    \n",
    "                # Превращаем индексы похожих пользователей в user_id\n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "    \n",
    "                # Собираем уникальные товары, которые есть у похожих пользователей\n",
    "                product_counter = Counter()  # Считаем частоту товаров среди похожих пользователей\n",
    "    \n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    # **Фильтруем только если filter_already_purchased=True**\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Увеличиваем счётчик\n",
    "    \n",
    "                # Берём топ-K товаров по частоте\n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "                if len(recommended_products) >= top_k_items:\n",
    "                    break  # Если набрали `top_k_items`, останавливаемся\n",
    "    \n",
    "                # Увеличиваем число похожих пользователей в 5 раз\n",
    "                num_similar_users *= 5\n",
    "                expansion_step += 1\n",
    "    \n",
    "            # Если n_iter_x5_top_n_similar_users=None → НЕ выполняем расширение\n",
    "            if n_iter_x5_top_n_similar_users is None or n_iter_x5_top_n_similar_users <= 0:\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, top_n_similar_users + 1, dim=0)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask][:top_n_similar_users]\n",
    "    \n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "    \n",
    "                product_counter = Counter()\n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Увеличиваем счётчик\n",
    "    \n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "            # Если всё равно товаров не хватает → используем популярные товары\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                # Вычисляем популярные товары (их нужно хранить больше чем `top_k_items`, чтобы фильтрация работала)\n",
    "                most_popular_items = df['product_id'].value_counts().index.tolist()  # Оптимизируем\n",
    "                # Используем генераторное выражение + islice для эффективной остановки после нужного количества товаров\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items if p not in recommended_products and \n",
    "                     (p not in user_bought if filter_already_purchased else True)),  \n",
    "                    needed_items\n",
    "                ))\n",
    "                recommended_products.extend(additional_items)\n",
    "    \n",
    "            # Сохраняем результат в np.array\n",
    "            recommendations[user_id] = np.array(list(recommended_products)[:top_k_items])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf2811c5-4abb-46c5-8469-359c3bc21d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327b71899b0a46bfbc28f41308290ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 2) Генерация рекомендаций для всех пользователей\u001b[39;00m\n\u001b[32m      5\u001b[39m user_ids = test_df[\u001b[33m'\u001b[39m\u001b[33manon_id_encrypred\u001b[39m\u001b[33m'\u001b[39m].unique()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m user_recommendations_ubcf = \u001b[43mrecommend_user_based_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_similarity\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_similarity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_n_similar_users\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_already_purchased\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_already_purchased\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter_x5_top_n_similar_users\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter_x5_top_n_similar_users\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mrecommend_user_based_batch\u001b[39m\u001b[34m(user_ids, user_similarity, user_labels, df, top_k_items, top_n_similar_users, batch_size, filter_already_purchased, n_iter_x5_top_n_similar_users)\u001b[39m\n\u001b[32m    113\u001b[39m row_sparse = user_similarity[u_idx]  \u001b[38;5;66;03m# submatrix (1, U)\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Превращаем её в dense-вектор [U], но только для одного пользователя\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m row_dense = \u001b[43mrow_sparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.flatten()  \u001b[38;5;66;03m# теперь shape = [num_users]\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Начинаем с базового `top_n_similar_users`\u001b[39;00m\n\u001b[32m    118\u001b[39m num_similar_users = top_n_similar_users\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1) Вычисляем матрицу сходства пользователей на GPU\n",
    "user_similarity, user_labels = compute_user_similarity(train_df)\n",
    "\n",
    "# 2) Генерация рекомендаций для всех пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ubcf = recommend_user_based_batch(\n",
    "    user_ids=user_ids,\n",
    "    user_similarity=user_similarity,\n",
    "    user_labels=user_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_users=n_iter_x5_top_n_similar_users\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f5fad0c-74ca-403f-8e7a-1a512c642b69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_recommendations_ubcf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_ubcf = RecommendationDataset(user_recommendations=\u001b[43muser_recommendations_ubcf\u001b[49m, user_to_true_items=test_user_to_true_items, k=k)\n\u001b[32m      2\u001b[39m loader = DataLoader(dataset_ubcf, batch_size=batch_size, collate_fn=collate_fn, num_workers=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'user_recommendations_ubcf' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_ubcf = RecommendationDataset(user_recommendations=user_recommendations_ubcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ubcf, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30715fd4-48dc-4dfb-b9dd-0adc7155fe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981a5d21fb0e4d829f916c232166760f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.02001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f793852a257c4d8fbf38809cda8281c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.019904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae8538d0d6943eb82bc1ac666bf330f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.01490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc71f431543140319eea552482a3943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k: 0.01685\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c273a11-ce6b-499c-97a1-e2a7b8334d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>{'top_k_items': 5, 'top_n_similar_users': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>{'top_k_items': 6, 'top_n_similar_users': 20, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  k  Precision@k  Recall@k   MAP@k  NDCG@k  \\\n",
       "0   Top-K  5       0.0026    0.0024  0.0014  0.0020   \n",
       "1  Random  5       0.0000    0.0000  0.0000  0.0000   \n",
       "2    UBCF  5       0.0182    0.0181  0.0140  0.0156   \n",
       "3   Top-K  6       0.0030    0.0028  0.0014  0.0021   \n",
       "4  Random  6       0.0000    0.0000  0.0000  0.0000   \n",
       "5    UBCF  6       0.0200    0.0199  0.0149  0.0169   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2      {'top_k_items': 5, 'top_n_similar_users': 20}  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5  {'top_k_items': 6, 'top_n_similar_users': 20, ...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='UBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_users': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_users': n_iter_x5_top_n_similar_users})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab1e79-dc3b-4da9-bf3c-deeeacd47e72",
   "metadata": {},
   "source": [
    "### 4. Item-Based Collaborative Filtering (IBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0a7c584-a282-44da-88ce-b0da9e4455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6  # top_k_items\n",
    "n = 20  # top_n_similar_items\n",
    "batch_size = 1024\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_items = 1\n",
    "# Важно!!! Если у вас GPU desktop - комментируйте строку ниже\n",
    "device = torch.device(\"cpu\") # На macbook не работает sparce на msp\n",
    "\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "def compute_item_similarity(df):\n",
    "    \"\"\"\n",
    "    Создает user-item матрицу, логарифмирует count для сглаживания,\n",
    "    транспонирует в (items x users), вычисляет косинусное сходство между товарами.\n",
    "    Возвращает item_similarity (sparse.mm результат) и product_labels.\n",
    "    \"\"\"\n",
    "    # 1) Cоздаём user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Применяем log(1 + count), чтобы уменьшить влияние частых покупок\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # 2) Преобразуем в PyTorch sparse_coo_tensor\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    # user_item_matrix.shape = (num_users, num_items)\n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # 3) Транспонируем, чтобы получить item-user матрицу (shape = (num_items, num_users))\n",
    "    # В PyTorch sparse_coo_tensor можно сделать sparse.transpose(dim0=0, dim1=1)\n",
    "    item_user_tensor = user_item_tensor.transpose(0, 1).coalesce()\n",
    "    \n",
    "    # 4) Нормируем строки (т.е. товары) для косинусного сходства\n",
    "    #    теперь каждую \"строку\" item_user_tensor мы считаем l2-норму\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(item_user_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Делим значения на норму соответствующей строки (товара)\n",
    "    normalized_values = item_user_tensor.values() / row_norms[item_user_tensor.indices()[0]]\n",
    "    item_user_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        item_user_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=item_user_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # 5) Вычисляем матрицу сходства товаров (item x item): M * M^T\n",
    "    item_similarity = torch.sparse.mm(item_user_tensor_normalized, item_user_tensor_normalized.t())\n",
    "    \n",
    "    # Возвращаем item_similarity и product_labels\n",
    "    # (user_labels не нужны для Item-Based)\n",
    "    return item_similarity, product_labels\n",
    "\n",
    "\n",
    "def recommend_item_based_batch(\n",
    "    user_ids,\n",
    "    item_similarity,\n",
    "    item_labels,\n",
    "    df,\n",
    "    top_k_items=k,                  # Сколько товаров рекомендуем\n",
    "    top_n_similar_items=n,          # Сколько похожих товаров ищем для каждого купленного\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_items=None  # Аналогично n_iter_x5_top_n_similar_users\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации на основе похожих товаров (Item-Based).\n",
    "    Аналогия с User-Based, но вместо топ-N похожих пользователей ищем топ-N похожих товаров\n",
    "    для каждого товара, который купил пользователь.\n",
    "    \"\"\"\n",
    "    # Для быстрого поиска индекса товара по product_id\n",
    "    item_labels_index = pd.Index(item_labels)\n",
    "    \n",
    "    # Список всех покупок пользователя (anon_id_encrypred -> set(product_id))\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Словарь: user_id -> список рекомендованных товаров\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Получаем популярные товары (для fallback)\n",
    "    most_popular_items_all = df['product_id'].value_counts().index.tolist()\n",
    "    \n",
    "    # Разбиваем на батчи только user_ids\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating Item-Based recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            user_bought = user_purchases.get(user_id, set())\n",
    "            if len(user_bought) == 0:\n",
    "                # Если пользователь ничего не покупал, рекомендуем популярные товары\n",
    "                needed_items = top_k_items\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if (p not in user_bought if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommendations[user_id] = np.array(additional_items)\n",
    "                continue\n",
    "            \n",
    "            product_counter = Counter()\n",
    "            \n",
    "            # Для каждого товара, который купил пользователь, ищем похожие товары\n",
    "            for purchased_item in user_bought:\n",
    "                # Ищем индекс purchased_item в item_labels_index\n",
    "                try:\n",
    "                    i_idx = item_labels_index.get_loc(purchased_item)\n",
    "                except KeyError:\n",
    "                    # Если вдруг товара нет в item_labels\n",
    "                    continue\n",
    "                \n",
    "                row_sparse = item_similarity[i_idx]  # submatrix (1, num_items) (sparse)\n",
    "                row_dense = row_sparse.to_dense().flatten()\n",
    "                \n",
    "                # Начинаем с базового top_n_similar_items\n",
    "                num_similar_items = top_n_similar_items\n",
    "                similar_items_list = []\n",
    "                expansion_step = 0\n",
    "                \n",
    "                # Аналогично логике User-Based: расширяем, пока не наберём top_k_items (в совокупности)\n",
    "                while (len(similar_items_list) < top_k_items\n",
    "                       and n_iter_x5_top_n_similar_items is not None\n",
    "                       and n_iter_x5_top_n_similar_items > 0\n",
    "                       and expansion_step <= n_iter_x5_top_n_similar_items):\n",
    "                    \n",
    "                    # Находим top-(num_similar_items+1)\n",
    "                    # ( +1 чтобы исключить сам товар, если он попал в топ)\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, num_similar_items + 1, dim=0)\n",
    "                    \n",
    "                    # Убираем сам товар purchased_item (если он внутри)\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask]\n",
    "                    \n",
    "                    # Превращаем индексы похожих товаров в product_id\n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    \n",
    "                    # Если filter_already_purchased=True, убираем товары, которые уже купил пользователь\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in user_bought:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                    \n",
    "                    if len(similar_items_list) >= top_k_items:\n",
    "                        break\n",
    "                    \n",
    "                    # Увеличиваем число похожих товаров в 5 раз\n",
    "                    num_similar_items *= 5\n",
    "                    expansion_step += 1\n",
    "                \n",
    "                # Если n_iter_x5_top_n_similar_items=None → НЕ выполняем расширение\n",
    "                if n_iter_x5_top_n_similar_items is None or n_iter_x5_top_n_similar_items <= 0:\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, top_n_similar_items + 1, dim=0)\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask][:top_n_similar_items]\n",
    "                    \n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in user_bought:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                \n",
    "                # Подсчитаем, насколько часто встречаются эти похожие товары\n",
    "                product_counter.update(similar_items_list)\n",
    "            \n",
    "            # Берём топ-K товаров по частоте среди ВСЕХ собранных\n",
    "            recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "            \n",
    "            # Если всё равно товаров не хватает → используем популярные товары\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if p not in recommended_products and (p not in user_bought if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommended_products.extend(additional_items)\n",
    "            \n",
    "            recommendations[user_id] = np.array(recommended_products[:top_k_items])\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a5888-09d1-4269-ba4f-7329f10aeec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118de2c96ab041e8ac5593e0bfc61acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Item-Based recommendations:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 2) Генерация рекомендаций для всех пользователей\u001b[39;00m\n\u001b[32m      5\u001b[39m user_ids = test_df[\u001b[33m'\u001b[39m\u001b[33manon_id_encrypred\u001b[39m\u001b[33m'\u001b[39m].unique()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m user_recommendations_ibcf = \u001b[43mrecommend_item_based_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mitem_similarity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitem_similarity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mitem_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitem_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_n_similar_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_already_purchased\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_already_purchased\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter_x5_top_n_similar_items\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter_x5_top_n_similar_users\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mrecommend_item_based_batch\u001b[39m\u001b[34m(user_ids, item_similarity, item_labels, df, top_k_items, top_n_similar_items, batch_size, filter_already_purchased, n_iter_x5_top_n_similar_items)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    132\u001b[39m row_sparse = item_similarity[i_idx]  \u001b[38;5;66;03m# submatrix (1, num_items) (sparse)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m row_dense = \u001b[43mrow_sparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.flatten()\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Начинаем с базового top_n_similar_items\u001b[39;00m\n\u001b[32m    136\u001b[39m num_similar_items = top_n_similar_items\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1) Вычисляем матрицу сходства товаров на GPU\n",
    "item_similarity, item_labels = compute_item_similarity(train_df)\n",
    "\n",
    "# 2) Генерация рекомендаций для всех пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ibcf = recommend_item_based_batch(\n",
    "    user_ids=user_ids, # [:len(user_ids) // 50]\n",
    "    item_similarity=item_similarity,\n",
    "    item_labels=item_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_items=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_items=n_iter_x5_top_n_similar_users\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e2c098fa-14ac-4395-b28c-68add56459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibcf = RecommendationDataset(user_recommendations=user_recommendations_ibcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ibcf, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5d3b920e-e22e-4424-a525-ba83016b7a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5cbf4a8f4a4d1188c384d80598b9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466617dfc1da4602bbb66e87004c5cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.008442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487549af60324b7794f2ce146d31c6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05025d276fb746bf83de4c79ea2c1cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k: 0.00777\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a15377d8-dde8-4a44-a256-84b18c95d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>{'top_k_items': 5, 'top_n_similar_users': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>{'top_k_items': 6, 'top_n_similar_users': 20, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IBCF</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>{'top_k_items': 6, 'top_n_similar_items': 20, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  k  Precision@k  Recall@k   MAP@k  NDCG@k  \\\n",
       "0   Top-K  5       0.0026    0.0024  0.0014  0.0020   \n",
       "1  Random  5       0.0000    0.0000  0.0000  0.0000   \n",
       "2    UBCF  5       0.0182    0.0181  0.0140  0.0156   \n",
       "3   Top-K  6       0.0030    0.0028  0.0014  0.0021   \n",
       "4  Random  6       0.0000    0.0000  0.0000  0.0000   \n",
       "5    UBCF  6       0.0200    0.0199  0.0149  0.0169   \n",
       "6    IBCF  6       0.0085    0.0084  0.0070  0.0078   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2      {'top_k_items': 5, 'top_n_similar_users': 20}  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5  {'top_k_items': 6, 'top_n_similar_users': 20, ...  \n",
       "6  {'top_k_items': 6, 'top_n_similar_items': 20, ...  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='IBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_items': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_items': n_iter_x5_top_n_similar_items})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02406f-cf6c-4a83-b0a7-ecbea66cb300",
   "metadata": {},
   "source": [
    "### 5. Matrix Factorization (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3887ba5-79ed-4648-aa34-f8a2ea829fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open(\"user_recommendations_random.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_recommendations_random, f)\n",
    "\n",
    "# with open(\"user_recommendations_top_k.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_recommendations_top_k, f)\n",
    "\n",
    "# with open(\"user_recommendations_ubcf.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_recommendations_ubcf, f)\n",
    "\n",
    "# with open(\"user_recommendations_ibcf.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_recommendations_ibcf, f)\n",
    "\n",
    "# with open(\"user_recommendations_mf.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_recommendations_mf, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"user_recommendations_random.pkl\", \"rb\") as f:\n",
    "    user_recommendations_random = pickle.load(f)\n",
    "\n",
    "with open(\"user_recommendations_top_k.pkl\", \"rb\") as f:\n",
    "    user_recommendations_top_k = pickle.load(f)\n",
    "\n",
    "with open(\"user_recommendations_ubcf.pkl\", \"rb\") as f:\n",
    "    user_recommendations_ubcf = pickle.load(f)\n",
    "\n",
    "with open(\"user_recommendations_ibcf.pkl\", \"rb\") as f:\n",
    "    user_recommendations_ibcf = pickle.load(f)\n",
    "\n",
    "with open(\"user_recommendations_mf.pkl\", \"rb\") as f:\n",
    "    user_recommendations_mf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.set_per_process_memory_fraction(0.95)  # Ограничение памяти до 80%\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3fe85a64-294d-4e05-b095-c8222a9ab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb724ebc-b55a-4daa-8fe6-1aad44b89231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, latent_dim)\n",
    "        \n",
    "        # Инициализируем факторы (например, Xavier uniform)\n",
    "        nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        user_indices: LongTensor (batch_size,)\n",
    "        item_indices: LongTensor (batch_size,)\n",
    "        Возвращаем предсказанный рейтинг (скалярное произведение эмбеддингов).\n",
    "        \"\"\"\n",
    "        user_embedding = self.user_factors(user_indices)   # (batch_size, latent_dim)\n",
    "        item_embedding = self.item_factors(item_indices)   # (batch_size, latent_dim)\n",
    "        rating_pred = (user_embedding * item_embedding).sum(dim=1)  # (batch_size,)\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d21e0d00-734d-4118-a1a7-f2337c88fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matrix_factorization(\n",
    "    df,\n",
    "    latent_dim=256,\n",
    "    epochs=10,\n",
    "    lr=0.01,\n",
    "    batch_size=1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Обучает матричную факторизацию (SVD с градиентным спуском) на user-item матрице.\n",
    "    Возвращает модель, а также user_labels и product_labels для инференса.\n",
    "    \"\"\"\n",
    "    # 1) Создаем user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Логарифмируем, чтобы сгладить влияние больших count\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "\n",
    "    # 2) Создаём модель\n",
    "    model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "    # 3) Формируем обучающий датасет\n",
    "    coo = user_item_matrix.tocoo()\n",
    "    user_indices = torch.tensor(coo.row, dtype=torch.long, device=device)\n",
    "    item_indices = torch.tensor(coo.col, dtype=torch.long, device=device)\n",
    "    ratings = torch.tensor(coo.data, dtype=torch.float32, device=device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(user_indices, item_indices, ratings)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 4) Задаём оптимизатор и функцию потерь\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 5) Тренировка\n",
    "    model.train()\n",
    "\n",
    "    # Для трекинга лосса\n",
    "    batch_losses = []\n",
    "    batch_avg_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Training Matrix Factorization (epochs)'):\n",
    "        total_loss = 0.0\n",
    "        epoch_losses = []\n",
    "        verbose = len(dataloader) // 10\n",
    "        for batch_idx, (batch_user, batch_item, batch_rating) in enumerate(tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}\")):\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_user, batch_item)\n",
    "            loss = criterion(preds, batch_rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "            # Каждые 50 батчей сохраняем средний лосс\n",
    "            if (batch_idx + 1) % verbose == 0:\n",
    "                avg_loss = sum(epoch_losses[-50:]) / 50\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "                batch_avg_losses.append(avg_loss)\n",
    "                print(f\"Step {batch_idx + 1}, last AVG loss: {avg_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {total_loss:.4f}\")\n",
    "        batch_losses.extend(epoch_losses)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(len(batch_avg_losses)), batch_avg_losses, label='Avg Loss per 50 batches')\n",
    "    plt.xlabel('Logging step (every 50 batches)')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title('Training Loss Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return model, user_labels, product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "001adee4-6610-4e0d-9076-b92e0334da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_mf_batch(\n",
    "    user_ids,\n",
    "    model,\n",
    "    user_labels,\n",
    "    product_labels,\n",
    "    df,\n",
    "    top_k_items=6,\n",
    "    batch_size=1024,\n",
    "    filter_already_purchased=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации, основанные на матричной факторизации.\n",
    "    Логика схожа с User-Based/Item-Based:\n",
    "      1) Считаем оценки для всех товаров\n",
    "      2) Если filter_already_purchased=True, убираем товары, которые пользователь уже покупал\n",
    "      3) Берём top-K\n",
    "      4) Если не хватает, добавляем популярные товары\n",
    "    \"\"\"\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    product_labels_index = pd.Index(product_labels)\n",
    "\n",
    "    # Собираем покупки пользователя\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "\n",
    "    # Популярные товары (для fallback)\n",
    "    most_popular_items = df['product_id'].value_counts().index.tolist()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating MF recommendations'):\n",
    "            batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "\n",
    "            # Конвертируем user_ids в user_indices\n",
    "            valid_indices = []\n",
    "            valid_user_ids = []\n",
    "            for uid in batch_user_ids:\n",
    "                try:\n",
    "                    uidx = user_labels_index.get_loc(uid)\n",
    "                    valid_indices.append(uidx)\n",
    "                    valid_user_ids.append(uid)\n",
    "                except KeyError: \n",
    "                    # Если пользователя нет в train_df - это холодный старт, подставляем fallback – топ‑k популярных товаров\n",
    "                    recommendations[uid] = np.array(most_popular_items[:top_k_items])\n",
    "            \n",
    "            if len(valid_indices) == 0:\n",
    "                continue  # Все пользователи в этом батче невалидны\n",
    "\n",
    "            user_tensor = torch.tensor(valid_indices, dtype=torch.long, device=device)\n",
    "            item_tensor = torch.arange(len(product_labels), dtype=torch.long, device=device)\n",
    "\n",
    "            # Предсказываем рейтинги для (batch_users x все товары)\n",
    "            # Расширяем user_tensor, чтобы сделать все комбинации\n",
    "            # user_tensor.shape -> (batch_size_valid,)\n",
    "            # item_tensor.shape -> (num_items,)\n",
    "\n",
    "            # predictions.shape -> (batch_size_valid, num_items)\n",
    "            predictions = model(\n",
    "                user_tensor.unsqueeze(1).expand(-1, len(item_tensor)).flatten(),\n",
    "                item_tensor.repeat(len(user_tensor))\n",
    "            )\n",
    "            predictions = predictions.view(len(user_tensor), len(item_tensor))\n",
    "\n",
    "            # Для каждого пользователя выбираем top-K\n",
    "            for i, uid in enumerate(valid_user_ids):\n",
    "                user_bought = user_purchases.get(uid, set())\n",
    "\n",
    "                # Если filter_already_purchased=True, фильтруем уже купленные\n",
    "                if filter_already_purchased:\n",
    "                    mask = torch.tensor(\n",
    "                        [product_labels[j] not in user_bought for j in range(len(product_labels))],\n",
    "                        dtype=torch.bool,\n",
    "                        device=device\n",
    "                    )\n",
    "                    # Присваиваем -inf товарам, которые нужно исключить\n",
    "                    predictions[i][~mask] = float('-inf')\n",
    "\n",
    "                # Находим top-K\n",
    "                top_k_indices = torch.topk(predictions[i], top_k_items).indices\n",
    "                top_k_products = [product_labels[idx.item()] for idx in top_k_indices]\n",
    "\n",
    "                # Если меньше K рекомендаций (теоретически при сильной фильтрации?), берём популярные\n",
    "                # (Хотя в MF обычно много товаров, так что пусто не будет)\n",
    "                if len(top_k_products) < top_k_items:\n",
    "                    needed = top_k_items - len(top_k_products)\n",
    "                    fallback = list(itertools.islice(\n",
    "                        (p for p in most_popular_items if p not in top_k_products and\n",
    "                         (p not in user_bought if filter_already_purchased else True)),\n",
    "                        needed\n",
    "                    ))\n",
    "\n",
    "                    # Если fallback пуст, подставляем просто топ популярных товаров\n",
    "                    if top_k_items - len(top_k_products) - len(fallback) != 0:\n",
    "                        needed = top_k_items - len(top_k_products) - len(fallback)\n",
    "                        fallback = most_popular_items[:needed]\n",
    "                    top_k_products.extend(fallback)\n",
    "\n",
    "                recommendations[uid] = np.array(top_k_products[:top_k_items])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0138a94e-7069-4832-8ccc-f3e61e421825",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6  # top_k_items\n",
    "batch_size = 1024  # Размер батча\n",
    "filter_already_purchased = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a25dbef-1823-41f5-9773-80ba4e627d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38433001e660491499f87d9089e19557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Matrix Factorization (epochs):   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c20868e6304853849349a95d0e2137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 237, Avg Loss: 0.5106\n",
      "Step 237, last AVG loss: 0.5106\n",
      "Epoch 1, Batch 474, Avg Loss: 0.5090\n",
      "Step 474, last AVG loss: 0.5090\n",
      "Epoch 1, Batch 711, Avg Loss: 0.4980\n",
      "Step 711, last AVG loss: 0.4980\n",
      "Epoch 1, Batch 948, Avg Loss: 0.4531\n",
      "Step 948, last AVG loss: 0.4531\n",
      "Epoch 1, Batch 1185, Avg Loss: 0.3592\n",
      "Step 1185, last AVG loss: 0.3592\n",
      "Epoch 1, Batch 1422, Avg Loss: 0.2659\n",
      "Step 1422, last AVG loss: 0.2659\n",
      "Epoch 1, Batch 1659, Avg Loss: 0.1983\n",
      "Step 1659, last AVG loss: 0.1983\n",
      "Epoch 1, Batch 1896, Avg Loss: 0.1515\n",
      "Step 1896, last AVG loss: 0.1515\n",
      "Epoch 1, Batch 2133, Avg Loss: 0.1218\n",
      "Step 2133, last AVG loss: 0.1218\n",
      "Epoch 1, Batch 2370, Avg Loss: 0.1013\n",
      "Step 2370, last AVG loss: 0.1013\n",
      "Epoch 1/2, Total Loss: 789.3036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eab1a742c849c0a163391592b707af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 237, Avg Loss: 0.1406\n",
      "Step 237, last AVG loss: 0.1406\n",
      "Epoch 2, Batch 474, Avg Loss: 0.1051\n",
      "Step 474, last AVG loss: 0.1051\n",
      "Epoch 2, Batch 711, Avg Loss: 0.0885\n",
      "Step 711, last AVG loss: 0.0885\n",
      "Epoch 2, Batch 948, Avg Loss: 0.0770\n",
      "Step 948, last AVG loss: 0.0770\n",
      "Epoch 2, Batch 1185, Avg Loss: 0.0694\n",
      "Step 1185, last AVG loss: 0.0694\n",
      "Epoch 2, Batch 1422, Avg Loss: 0.0650\n",
      "Step 1422, last AVG loss: 0.0650\n",
      "Epoch 2, Batch 1659, Avg Loss: 0.0607\n",
      "Step 1659, last AVG loss: 0.0607\n",
      "Epoch 2, Batch 1896, Avg Loss: 0.0579\n",
      "Step 1896, last AVG loss: 0.0579\n",
      "Epoch 2, Batch 2133, Avg Loss: 0.0559\n",
      "Step 2133, last AVG loss: 0.0559\n",
      "Epoch 2, Batch 2370, Avg Loss: 0.0537\n",
      "Step 2370, last AVG loss: 0.0537\n",
      "Epoch 2/2, Total Loss: 200.2546\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAIjCAYAAAB/OVoZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhKxJREFUeJzt3Qd0FNXbx/EnvScQQgi9996LAipNQAUbCCoqgooVsaGvYv9jAysCoohYARUrIoj03nvvHUJJ79n3PDdsTCCBBJLMbvb7OWfIltndu3N3E35zm5vNZrMJAAAAAACwnLvVBQAAAAAAABkI6QAAAAAAOAhCOgAAAAAADoKQDgAAAACAgyCkAwAAAADgIAjpAAAAAAA4CEI6AAAAAAAOgpAOAAAAAICDIKQDAAAAAOAgCOkAAOTBvffeK1WqVLmsx77yyivi5uZW4GUCAADFDyEdAODUNPzmZZs3b5646smFwMBAcXTXXHNNtvoKDQ2Vli1bysSJEyU9Pd3q4gEAUGQ8i+6lAAAoeF9//XW265MnT5bZs2dfcHvdunWv6HUmTJhw2WHxxRdflOHDh1/R67uCChUqyMiRI83lkydPmrq8//77ZceOHfLWW29ZXTwAAIqEm81msxXNSwEAUPgeffRRGTNmjFzqz1t8fLz4+/uLK7Sk//jjjxIbGyuO3pIeGRkpmzZtylZHtWvXljNnzpjNy8vrgsfpiZPk5GTx9fUt9DLqZyoxMVH8/PwK/bUAAK6L7u4AgGJPA2CDBg1k9erV0qFDBxPOX3jhBXPfr7/+Kj179pRy5cqJj4+PVK9eXV5//XVJS0u76Jj0ffv2mW7Z7733nnz22Wfmcfp47aK9cuXKS45J1+t6QuGXX34xZdPH1q9fX2bOnHlB+bWrfosWLUwQ1dcZP358gY9znzZtmjRv3twE0LCwMLnrrrvk8OHD2fY5duyY3HfffabFW8tbtmxZ6dWrlzkWdqtWrZJu3bqZ59Dnqlq1qgwcOPCyyqT11KZNG4mLizMt61mP27fffmuOl5bDfszWrl0r3bt3l+DgYNPFv1OnTrJs2bILnnfDhg3SsWNHUz59L2+88YZ8+eWX5rmzvhet7xtuuEH+/vtvc/x1fz326uzZszJ06FCpWLGiKUONGjXk7bffvqC3xQ8//GCOa1BQkClXw4YN5cMPP8y8PyUlRV599VWpWbOmqd9SpUrJ1VdfbXqDAABcE93dAQAu4dSpUybA3XHHHSaAlilTxtw+adIkE+iGDRtmfv77778yYsQIiY6OlnffffeSz/vdd99JTEyMPPjggybkvfPOO3LLLbfInj17cmz5zWrRokXy888/y8MPP2xC3EcffSS33nqrHDhwwIQ1e/C8/vrrTSDWMKcnD1577TUpXbp0AR2ZjGOg4VtPMGh38+PHj5sguXjxYvP6JUqUMPtp2TZv3iyPPfaYCbAnTpwwYVLLa7/etWtXUzbt3q+P09Cr7/Fy6XH08PDILIPSOpo6daoJ63oyQF9by9W+fXsThJ999llz7DVQ6wma+fPnS+vWrc1j9cTDtddea+rq+eefl4CAAPn8889N0M7J9u3bpV+/fqZ+Bw8ebFr2tYVfQ74+l95eqVIlWbJkiXm+o0ePygcffGAeq8dGH6snCzTAq61bt5rj+sQTT5jrerJFj/mgQYOkVatW5nOnJzrWrFkjXbp0uezjBgBwYtrdHQCA4uKRRx7Rfu7ZbuvYsaO5bdy4cRfsHx8ff8FtDz74oM3f39+WmJiYeds999xjq1y5cub1vXv3mucsVaqU7fTp05m3//rrr+b233//PfO2l19++YIy6XVvb2/brl27Mm9bv369uf3jjz/OvO3GG280ZTl8+HDmbTt37rR5enpe8Jw50XIHBATken9ycrItPDzc1qBBA1tCQkLm7X/88Yd5/hEjRpjrZ86cMdfffffdXJ9r+vTpZp+VK1fa8kvrqE6dOraTJ0+abevWrbbHH3/cPJ8eAzu97u7ubtu8eXO2x/fu3dscz927d2feduTIEVtQUJCtQ4cOmbc99thjNjc3N9vatWszbzt16pQtNDTUPLfWq53Wt942c+bMbK/1+uuvm2O6Y8eObLcPHz7c5uHhYTtw4IC5/sQTT9iCg4Ntqampub7vxo0b23r27JnPowUAKM7o7g4AcAnaUqqtxefLOr5YW8R1XLS2yGpr6bZt2y75vH379pWSJUtmXtfH2luAL6Vz586m+7pdo0aNTEuw/bHaav7PP/9I7969TXd8O+1arb0CCoK22moLuLbmZx3XrUMA6tSpI3/++WfmcfL29jZd73V8eE7srd1//PGH6cadX3q8tRVeN53o7+OPPzbl0Bnes9JW7Hr16mVe1+M0a9Ysc5yqVauWebv2Pujfv7/psaAt1Eq7xrdt21aaNGmSuZ/OJH/nnXfmWCbtrq/d988fGqD1rPWunxf7pvWpZVmwYEHm8dCu+hfruq77aC+AnTt35vt4AQCKJ0I6AMAllC9f3oTM82lAuvnmmyUkJMQEZA2I2h1eRUVFXfJ5tatzVvbAnluQvdhj7Y+3P1bDc0JCggnl58vptsuxf/9+81O7cZ9PQ7r9fj3JoV22//rrLzNUQMf2a9d+HaeeNTxrl3jtlq/d0HW8uo71TkpKylNZtNu6Blo9MaHBWp9bA78+1/nBOSsdr26fZO58GvZ1nPjBgwcz329+juf5r6U0UGvYt59QsG8a0u31pvTER61atcwJFR37rmPzz59zQIcu6Ph23U/Hqz/zzDNmzDwAwHUR0gEALiGnGbk1HGmwXL9+vQlLv//+uwmJ9vHDeVlyTcdL5yQvi6dcyWOtoBOl6XJoOoZaW91feuklE4J13LrScd46k/zSpUvNeHEds63BVCdOy8vs8jo+XIOujuG+6qqrJDw8PMf9inJ29ZxeSz8XOl5cPys5bXqiQmn5161bJ7/99pvcdNNNMnfuXBPY77nnnszn0pMdu3fvNr0FdAJBHR/frFkz8xMA4JoI6QAAl6Vdt3VCOZ04TSfy0pm8NSRm7b5uJQ15GoZ37dp1wX053XY5KleunDlB2vn0Nvv9dto9/6mnnjLdy3W5NF3+bNSoUdn20RnZ33zzTdOVXmdh194KOst5YdFWbJ0JPqf3oF3o3d3dzSzsSt/PlR5PPQZ60kE/KzltWXtIaO+NG2+8UT799FMTxnWiOV3/PevraXd7HYrx/fffmxZ/HfagE8oBAFwTIR0A4LLsLdlZW641dGqgcpTyaejTZdqOHDmSebsGPO12XhB0aTE9GTBu3Lhs3dL1+XUmch0TrrQ7ua4Rfn5Y1Vnp7Y/Tbvrn9wKwj/3Oa5f3yz1OOqu8LqeXdQk1naVeZ9/XJc10KIPS8eXa0q8t3HanT582JxPyqk+fPuY5dGm2nHpnpKammst6AigrPVmgATzr8Th/H11hQLveF+bxAgA4NpZgAwC4rHbt2plWc+1+/Pjjj5vu2l9//bVDdTfXFlVttdbu30OGDDETk33yySema3TWoHkxOombrgV+Pm3B1XHT2r1fW3K1678uGWZfgk3HiD/55JNmX+3mrt3QNaDqpG2enp4yffp0s68ua6e++uorc4JDx/hrgNeJ+CZMmGACco8ePaQw6fvTruYayPU9afl0CTYNuzp23k6XZ/vmm29Md3VdSs6+BJu2fmtYz8va8zpuXLuwa8+Le++913Tn1wniNm7caLr764kCHUevy6rpc1533XVmTLqOh9fJ8PTEhQ4TUHosdZk4fQ6tD+19oM+hwwUAAK6JkA4AcFm6FrlOTKbdt1988UUT2HXSOA2j58/obRUNb9qq/fTTT5sx4NptW8fPayt3Xmaft/cO0MeeT4O0BloNmtpd/K233pLnnnvOBFcN2hre7TO26+tqgJ8zZ445kaEhWCeW0/XK7WOwNeSvWLHCdG3X8K6T8ena39pKndMEbAWpfv36snDhQrNWuY6Z13Hjuja6BnL7Gun296Fjw/WkzP/+9z/TVf6RRx4x71lvyzrDfW70WOna6/p4neldu6/riQid/E0nzdP3rfSz9Nlnn5kTF9rCHhERYVYD0BMv2qqu9DU18OuJGD2hoN3x9YSDnggAALgmN12HzepCAACA/NHlxli6q2AnxdOWdx1rntuEfgAAFAXGpAMA4OB0GbasNJjPmDHDdJPGlR9PHReuvQO0qzwBHQBgNVrSAQBwcGXLljVd0qtVq2bGNY8dO9Z0jdalz2rWrGl18ZyOjgnXExw6Lly75X/xxRdmYj7tyq9LogEAYCXGpAMA4OCuv/56szzXsWPHxMfHR9q2bWvGQxPQL49OYqeTs+l4cZ0oTtcl16BOQAcAOAJa0gEAAAAAcBCMSQcAAAAAwEEQ0gEAAAAAcBAuNyZd103VyWGCgoLMODQAAAAAAAqTjjKPiYmRcuXKibv7xdvKXS6ka0CvWLGi1cUAAAAAALiYgwcPSoUKFS66j8uFdG1Btx+c4OBgcWQpKSkya9Ys6dq1q3h5eVldHOQDdee8qDvnRd05N+rPeVF3zou6c17UnfOJjo42jcX2PHoxLhfS7V3cNaA7Q0j39/c35eTL51yoO+dF3Tkv6s65UX/Oi7pzXtSd86LunFdehlwzcRwAAAAAAA6CkA4AAAAAgIMgpAMAAAAA4CBcbkw6AAAA4KpLQKWmpkpaWlrmuGZPT09JTEzMvA3OgbpzTDo/gIeHxxU/DyEdAAAAKOaSk5Pl6NGjEh8fny20R0REmFWP8jKZFRwHdeeYtC50ebXAwMAreh5COgAAAFCMpaeny969e00LX7ly5cTb29uECb09NjbWBAp3d0bBOhPqzjFPnJw8eVIOHTokNWvWvKIWdUI6AAAAUMxb0TXU6RrNumyXnd6m9/n6+hL0nAx155hKly4t+/btM8MRriSkU6MAAACACyDMAYWroIYe8E0FAAAAAMBBENIBAAAAAHAQhHQAAAAAQKF55ZVXpEmTJpa8dpUqVeSDDz4QZ0JIBwAAAODQli5daibi6tmzZ5G83qRJk6REiRLianTSMx1Xff62bNmybPtNmzZN6tSpYyaua9iwocyYMaNIyufm5ia//PKLFHeEdAAAAAAO7YsvvpDHHntMFixYIEeOHLG6OE5PZ4a/mH/++UeOHj2auTVv3jzzviVLlki/fv3k/vvvl7Vr10rv3r3NtmnTpiIouWsgpAMAAAAuuKZzfHKqJCSnmZ9Ftenr5peuBz5lyhQZMmSIaUnXVm67/v37S9++fbPtr8tfhYWFyeTJk831mJgYufPOOyUgIEDKli0r77//vlxzzTUydOjQyz5+Bw4ckF69epl1yoODg6VPnz5y/PjxzPvXr18v1157rQQFBZn7NeSuWrXK3Ld//3658cYbpWTJkqZM9evXv2hLtHbXfv31100w1v3Lly8vn376abZ9zp49K4MGDTJLgOnrXXfddaYM53c3//zzz6Vq1aqmBfxiSpUqJREREZmbl5dX5n0ffvihXH/99fLMM89I3bp1TdmaNWsmn3zyySWP2/jx4zOXAtRjFhUVlXnfypUrpUuXLqbuQkJCpGPHjrJmzZpsx0HdfPPNpkXdfl39/vvv0rJlS/O+9PG6T1bx8fEycOBAUx+VKlWSzz77LNv9Bw8eNOXR3hOhoaGmbrVXgd28efOkVatW5vjrPldddZWpx8LCOukAAACAi0lISZMGr8wu8tfd8lo38ffOXwSZOnWq6Vpdu3Ztueuuu0y4fv75501Q0/B9++23myCvgVn9/fffJpTZg9qwYcNk8eLF8ttvv0mZMmVkxIgRJvxd7hhpXaPcHtDnz58vqamp8sgjj5iTBRrmlJaradOmMnbsWNNNf926dZlBV/fVlmztFaChb8uWLZllz827774rL7zwgrz66qvm/ekx0LCu5VB6DPz8/OSvv/4yAVfDcKdOnWTHjh0mdKpdu3bJTz/9JD///PMl1/C+6aabJDExUWrVqiXPPvusuZ516IEe06y6det2yW7o+vpalxqoo6OjTUv8ww8/LN9++23myZR77rlHPv74Y3MyZ9SoUdKjRw/ZuXOnCdca4sPDw+XLL780Jwns7+HPP/80df1///d/5sSMHtvzT3roc+nJBD2GP/74oznhoycB9DOlJ3W0/G3btpWFCxeKp6envPHGG+Y1NmzYYJYu1J4CgwcPlu+//948/4oVKwpsubWcENIBAAAAOHRXdw3nSoOTtr5qONbWcA1XGnSnT58ud999t9nnu+++M6FSg50Gv6+++srcpqFVacgrV67cZZdnzpw5snHjRtm7d69pFVYaDrVFXIOktuhqS7u2NOvJBVWzZs3Mx+t9t956qxnLrapVq3bJ19SW2+HDh5vLGpwXLVpkWtM1pOtlDY0nTpwQHx8fs897771nQrMG0gceeMDcpuFSy6mt7bnRkwUaaPX1NJxqqNeAqs9lD+rHjh0zJzuy0ut6+8Vo6NfX15MLSsO49ozQ19PWem39z+qzzz4zrdZa1zfccENmufU23d/uzTfflDvuuMOcwLBr3LhxtufSsK8nBNRzzz1nelPMnTvXhHTtpaEnXrSXgT1462dEX0dPurRo0cJ85rQM1atXN/drD4LCREh3ULtOxMjWI1Gy+YyblNxzSgJ8fcTH0118vdzFx9NDfM791OveHu6FeiYHAAAAxYufl4dseqWLxETHSFBwkAlkRfW6+bF9+3YTQDWEK23l1BZrDe4a0vW6dlPW1lgN6XFxcfLrr7/KDz/8YPbfs2ePaSnVrsp22tKs4exybd261YRze0BX9erVM6FO79OQri3N2v3866+/ls6dO5uWbnvAe/zxx01L7qxZs8x9GtgbNWp00dfUVt7zr2vQVNqtXXsSaBf1rBISEmT37t2Z1ytXrnzRgK60q3jWVnJ9LzoHgLbkZ21Nvxzazdwe0O3vQcOx1rGGbh0u8OKLL5pgrCcc0tLSTI8IPalxMdpLQVu5Lybr8dXcpK+nr2E/ftrKryd1zj+poMeva9eucu+995oTQtodX+tMP3M6dKKwENId1IyNx2T07B0i4iGfbVt90X01n2uAN+HdBPnsPzXQ+54L9vafWYN+jo85/7YsJwWyPsbDnZMDAAAAzkaDinY7T/X2MD+LKqTnl4Zx7U6eteVbu0Jri7GOgdbArV3Lteuyhq7Zs2ebbt/a4m4lHQOu4+W1K7Z2QX/55ZfNiQPtlq3hXQOf3qdBfeTIkaY1WSfGuxwa0DUw2rvaZ5V1hnrtcXA5WrdubY6rnT1QZ6XXs7ZuXw7t6n7q1Ckz5l1PKGgda5C/1CR3Wt+XknVMvf3zrycI7MdP5wywd7vPyn5SQ1vW9eTKzJkzTcu7nkzQY9KmTRspDIR0BxUR7CstKpeQ45FnxDcgUJLTbJKYkiZJqemZP+3zbujPxBS9PeODVpQ83d2yBfvwYF9pXrlk5lYm+OKTUgAAAAA50XCu3aM1wGprZlbaBVvHBz/00EPSrl0706qt4UkDsbZa20OZdiXXy9oNXVtylXZd1rHaHTp0uKxyaVdnnWhMN3truo4r18nbtEXdTrul6/bkk0+aSd806NnHyevjtOy66fj6CRMmXDSkn78Eml7X51Y6aZt2NddeBVknUyso2lKdtdVYg7N2+c868Z4G1vNb+8+nLeLaKm8/4aLvQU8O2Xs16LwB2oW/R48e5roe38jIyGzPoXWpLeznt5Jree67777Len96/PSzo+PdddK93OgcA7ppfel71SEUhHQX06dlRbm5SYSZ9KBHj6suOPujZxBTNLinpklSyn/BPSk1zYR1/Wmunxfss+6b22P+u//cbVl+6uvp69qlptskNilVYpMyrh+JSpR1B8/KF4v2muvlS/hJiyoZgb1ZpZJSJyJIPD0c80wtAAAAHMcff/whZ86cMROMaYt5VtpFXFvZNeQqbbUeN26cCd861thOuzBrC62OD9cJ1DSIaau2hsNLDRfVMKgBNStt3dXuzjqeXFvwP/jgA3MyQcc7a2u+jl/Wbub6erfddpuZSf3QoUPmJIGWWWm47d69uwnZ+v60vJca46wB9p133jEnJzQQ61hzDZZKy6OhUe/TffR5NQzbJ1TTMuWVjt/39vY2YVTpJHMTJ04047XtnnjiCfNe9eSJjinXHgI6c/35M6afT2de17rQ8fI6cZy2TGu3cXsLvI7b1+EBLVq0MPfrMTy/lVxPQmgg1zHzWhc6Q77Wp843oMMJdGy61odmKB17nhdaj9qdX8f3v/baa1KhQgUzc7u+d500T4dL6HvT7v56gkG75+tkdgMGDJDCQkh3UvpLxdtTN3eRIm6sTku3SXIOIV+v7zsVJ6v3nzHb1qPRcvhsghxelyC/rstYz9Lf20OaVCwhLTS0Vy4pTSuVlBC/7CcgAAAAAA3hGkDPD+hKA68GUp19W1tSNWjpBGLaTVoDXFajR482YV4n/tKWUg1e2kp7qWXItBu0PazaaRDU8cs67l1bvrU1XgO/dq/XidCUzjqu3bY1xGk3cB3nfcstt2RObKbhX2d41/Cu5dHH2seX5+app54yQVifQx+jAdk+EZ7mAg2lOru5tiafPHnSBF8t2/kTvOWFzoKuIVVb5nXiOz0ZoCcc7LTngrYia5dvnS1dw7VOLNegQYOLPm+NGjXMcdCW8tOnT5v6yLqUnNa3TnLXrFkz09Pgf//7nzz99NPZnkPft46Z154HOr5dl0nTuQmmTZtmyv3WW2+Z45OfXhK6HJzOtK+hXsunkw3qc+vx1efSky7btm0zJzC0XrVXgdbfgw8+KIXFzXY5ixU6MT0ro1907eZyse4MjkDP2mS0pPe4oCXdGWgL+/qDZzND+5oDZyQmMTXbPnoCs2Z4oDSvHJrZRb5KKX+nnwjP2evOlVF3zou6c27Un/Oi7hyfToClM5Gfvz62jsnV/xvr/4kddUx6YdDJ5TSEaeDTVnpHp63H2vqetXu5q9ads37X8ptDaUlHoQn08ZSraoSZTaWn22TniVgT2FftPy1r9p+RfafiZcfxWLN9vyJj5sbQAG/TNd7eTb5h+RAz7h0AAADIr7Vr15qWUJ3hXQOSdmlW9jXGAUdDSEeRcXd3k9oRQWbr3zpj4o7I2CQT1u2t7RsOR8npuGT5Z+txsykvDzepXy7EdJG3t7brBHUAAABAXug4aB1LrOOtdSbvhQsXmm7ogCNyiJA+ZswYM1hfZyXUhed1PEfWtQyzmjRp0gUz9+mkAdq1AM4nLNBHutaPMJvS8e2bj0TL6n0ZoX3V/jMmyOtkdLp9fm5Cugol/TJDu45trxMRzHJwAAAAuICOK1+9+uJLGjsyHXcN12J5SNeJCHTwv87GqGvw6QyJum6gnunS2Rdzon349X47Zx+/jP/oGuza1V23wedmsT90JsF0j89obT8r249Fm9t0++XchHQB3h5mErpm54J700olJNiXcXEAAAAAnIvlIV1nWxw8eHBm67iGdV0uQKf6Hz58eI6P0VBun6r/UpKSksyWdcC+fZIT3RyZvXyOXs7CFhHkJTc0KGM2pZPPrT8UJWsPnJU1B8/K2oNnJS4pTRbtijRb5oR0pQOlWeUS0qxiCWlWqYRUCvUrshM61J3zou6cF3Xn3Kg/50XdOT5dkkobPnRWcZ1wzM4+f7T+zHo7HB9155j0O6Z1ot+5838n5ud3pKWzuycnJ5sp73WdP13Xz07Xzzt79qxZ2iCn7u6DBg0yMzLqB1Kn6Nfp+evXr5/ja7zyyiuZyx1kpcsG6GvD+aXbRI7Gi+yNcZN9MW6yJ8ZNTiVdGMYDPW1SNei/rWKgiBeTYQIAgGJOGyl02Sht5NJ1wwEUjvj4eLNG/dGjRy84eaL39e/fP0+zu1sa0vUNaNhesmSJtG3bNvN2Xbtw/vz5snz58gses3TpUrN4vK6HqG9QJ4HQde02b95sFp7PS0u6rrsXGRnpFEuwzZ49W7p06cKSJvl0MibJtLCv0db2A2dl05FoSUnL/lHXCel05vhhnWtI66qhBfr61J3zou6cF3Xn3Kg/50XdOQddr1v/H1y6dGnTUKXBXWOALkcWEBDA8FEnQ905Hg3lGs51fXnNuOfXi37/dLLCYrkEm4b5rIG+Xbt2UrduXRk/frxZwP58OqmcbufTPyLO8ofEmcrqKMqFekm50EDp2TjjxE1iik5IF5UxGd2+jDXbI2OTTYAf+NUa+ahfU7m+Qd6GUOQHdee8qDvnRd05N+rPeVF3jk1Dg4eHh2moyhr0EhISxM+v6IYEomBQd45J16zX75quInC+/Px+tDSk65kE/WWhZ/ay0ut5HXOub1ZnbNy1a1chlRLFga6z3rxyqNke6JDxi+3A6XgZOWObzNx8TB7+drW8dUsj6dOyotVFBQAAKLQu7zoxc9Z5BLRHaocOHTjB4mSoO8ek4VyD+pWyNKTb1ymcM2dO5ph07Sag1x999NE8D87fuHGj9OjRo5BLi+L2h6pyqQD5pH9T+b/pm2TKqoPy7E8bJCohRQZ3qGZ18QAAAAqFNpDpZr+sE1z5+voS9JwMdVe8Wd7dXZdf04niWrRoYdZG1yXYdHyFfbb3AQMGmC4DI0eONNdfe+01adOmjdSoUcNMLqfrq+/fv99MJgfkl6eHu7x1a0Mp4e8l4xfskTdnbJUz8cnyTLfadB0CAAAA4HohvW/fvnLy5EkZMWKEHDt2TJo0aSIzZ86UMmUylts6cOBAti4DZ86cMUu26b4lS5Y0LfE68Vy9evUsfBdwZhrGn+9RV0r4e8vbM7fJp/N2y9mEFHm9VwPxcCeoAwAAAHChkK60a3tu3dvnzZuX7fr7779vNqCgDbmmuoT4ecn//bJRvlt+wHR9f79PE/H2ZJ02AAAAAEWD9AFk0b91JfmkXzOzPNufG47K/V+tlPjkVKuLBQAAAMBFENKB8/RsVFa+uKel+Hl5yMKdkXLX58vlbHyy1cUCAAAA4AII6UAOOtQqLd8Mam26v+ta6n3HL5MT0YlWFwsAAABAMUdIB3LRvHJJmfpgWwkP8pHtx2Pk1nFLZP+pOKuLBQAAAKAYI6QDF1E7Ikh+GtJOKpfyl4OnE+S2cUtl69Foq4sFAAAAoJgipAOXUDHUX6Y91FbqRATJyZgk6Tt+qazef9rqYgEAAAAohgjpQB6EB/nKlAfami7w0Ympcufny2Xe9hNWFwsAAABAMUNIB/IoxN9Lvr6/lXSsVVoSU9Jl8ORV8vv6I1YXCwAAAEAxQkgH8sHf21MmDGghNzYuJylpNnn8h7XyzbL9VhcLAAAAQDFBSAfyydvTXT7o20TualNJbDaRF3/ZJGPm7hKbXgEAAACAK0BIBy6Dh7ubvN6rgTx2XQ1z/d2/t8ubf24lqAMAAAC4IoR04DK5ubnJU11ry4s965rrny/aK8/+uEFS09KtLhoAAAAAJ0VIB67QoPbV5L3bG5vW9WmrD8nD366RpJQ0q4sFAAAAwAkR0oECcFvzCjL2zmZmvPqsLcdl0NdrJJGcDgAAACCfCOlAAelaP0Im3ddSArw9ZNneM/LJZg85HZdsdbEAAAAAOBFCOlCA2lUPk+8faCMl/b3kYJyb9Pt8pRw5m2B1sQAAAAA4CUI6UMAaVSgh3w9qJSW8bbInMk5uH7dUdp+MtbpYAAAAAJwAIR0oBNVLB8gTDdKkail/OXw2QfqMWyqbDkdZXSwAAAAADo6QDhSSUB+R7we1lAblg+VUXLLc8dkyWbbnlNXFAgAAAODACOlAISoV6CPfD24jrauGSmxSqtwzcYX8s+W41cUCAAAA4KAI6UAhC/L1kq8GtpLOdctIUmq6PPjNavl5zSGriwUAAADAARHSgSLg6+Uh4+5qJrc0Ky9p6TYZNnW9TFy01+piAQAAAHAwhHSgiHh6uMt7tzWW+66qYq6/9scWGT17h9hsNquLBgAAAMBBENKBIuTu7iYjbqgnw7rUMtc/mrNTXvlts6SnE9QBAAAAENKBIufm5iaPd6opr/eqL25uIl8t3S9PTl0nKWnpVhcNAAAAgMUI6YBF7m5bRT7o20Q83d3k13VH5MGvV0tCcprVxQIAAABgIUI6YKFeTcrLhAEtxMfTXf7ddkIGTFwuUQkpVhcLAAAAgEUI6YDFrq0TLt8Mai1Bvp6yct8Z6ffZMjkZk2R1sQAAAABYgJAOOICWVUJlygNtJSzQR7YcjZbbxy2Rg6fjrS4WAAAAgCJGSAccRL1ywfLjQ22lQkk/2XcqXm4bt0R2Ho+xulgAAAAAihAhHXAgVcIC5MeH2knN8EA5Hp0kt49fKusOnrW6WAAAAACKCCEdcDARIb4y9cG20qRiCTkbnyL9JyyTRTsjrS4WAAAAgCJASAccUMkAb/l2UGu5ukaYxCenycBJK2XmpqNWFwsAAABAISOkAw4qwMdTvri3hXRvECHJaeny8LdrZMrKA1YXCwAAAEAhIqQDDszH00M+6d9M7mhZUdJtIs/9tFEmLNhjdbEAAAAAFBJCOuDgPNzdZOQtDeWhjtXN9TdnbJWNh6KsLhYAAACAQkBIB5yAm5ubDO9eR25qXM5cHz17u9VFAgAAAFAICOmAExnWpZZpWZ+7/aSs3n/a6uIAAAAAKGCEdMDJ1lG/vXkFc3nUrB1WFwcAAABAASOkA07msU41xdvDXZbsPiVLdrF+OgAAAFCcENIBJ1O+hJ/0a1XRXB41e4fYbDariwQAAACggBDSASf0yLU1xMfTXVbvPyPzdpy0ujgAAAAACgghHXBC4cG+ck+7Kuby6Fm0pgMAAADFBSEdcFIPdqgmAd4esvFwlMzactzq4gAAAAAoAIR0wEmVCvSRgVdXzWxNT0+nNR0AAABwdoR0wIkNal9Ngn09ZfvxGPlj41GriwMAAADgChHSAScW4uclD3SoZi5/MHuHpKalW10kAAAAAFeAkA44uXuvqiqhAd6yJzJOpq89bHVxAAAAAFwBQjrg5AJ9PGVIx+rm8odzdkpyKq3pAAAAgLMipAPFwF1tKkt4kI8cOpMgU1cdtLo4AAAAAC4TIR0oBvy8PeTR62qYyx//u1MSU9KsLhIAAACAy0BIB4qJvi0rSvkSfnI8Okm+XX7A6uIAAAAAuAyEdKCY8PH0kMc7ZbSmj523S+KSUq0uEgAAAIB8IqQDxcgtzSpIlVL+EhmbLF8t3Wd1cQAAAADkEyEdKEa8PNxlaOda5vL4+XskOjHF6iIBAAAAyAdCOlDM3Ni4nNQMD5SohBT5YuFeq4sDAAAAIB8I6UAx4+HuJsO6ZLSmf7For5yJS7a6SAAAAADyiJAOFEPd6kdI/XLBEpuUKuMX7LG6OAAAAADyiJAOFEPu7m7yVNeM1vRJS/bKiZhEq4sEAAAAIA8I6UAxdW3tcGlaqYQkpqTL2Hm7rS4OAAAAgDwgpAPFlJubmzzdtba5/O2yA3LkbILVRQIAAABwCYR0oBhrV72UtKkWKslp6fLJ3F1WFwcAAADAJRDSgWLemv7Uudb0qSsPyoFT8VYXCQAAAMBFENKBYq5llVDpWKu0pKbb5MM5O60uDgAAAICLIKQDLsA+0/v0tYdk14lYq4sDAAAAIBeEdMAFNKpQQrrWKyPpNpEP/tlhdXEAAAAA5IKQDriIYV1riZubyB8bjsrWo9FWFwcAAABADgjpgIuoExEsPRuWNZdHz6Y1HQAAAHBEhHTAhQztXEvc3URmbzku6w+etbo4AAAAAM5DSAdcSI3wQLm5aQVzeRSt6QAAAIDDIaQDLuaJTjXF091NFuw4KSv2nra6OAAAAACyIKQDLqZSKX/p07KiufzerO1is9msLhIAAACAcwjpgAt67Loa4u3pblrSF+86ZXVxAAAAAJxDSAdcUNkQP7mzdSVzmdZ0AAAAwHEQ0gEXNeSa6uLn5SHrDp6VudtPWF0cAAAAAIR0wHWFB/nKPe2qmMujZu2Q9HRa0wEAAACrEdIBF/Zgh2oS6OMpm49Ey9+bj1ldHAAAAMDlEdIBF1YywFvuv7qquTx69g5JozUdAAAAsBQhHXBx97evKiF+XrLzRKz8vv6I1cUBAAAAXBohHXBxwb5e8mDHaubyB//skJS0dKuLBAAAALgshwjpY8aMkSpVqoivr6+0bt1aVqxYkafH/fDDD+Lm5ia9e/cu9DICxdm97apIWKC37DsVLz+vOWR1cQAAAACXZXlInzJligwbNkxefvllWbNmjTRu3Fi6desmJ05cfEmoffv2ydNPPy3t27cvsrICxZW/t6cMuaaGufzRnF2SlJpmdZEAAAAAl2R5SB89erQMHjxY7rvvPqlXr56MGzdO/P39ZeLEibk+Ji0tTe6880559dVXpVq1jG66AK7Mna0rSUSwrxw+myBTVh60ujgAAACAS/K08sWTk5Nl9erV8vzzz2fe5u7uLp07d5alS5fm+rjXXntNwsPD5f7775eFCxde9DWSkpLMZhcdHW1+pqSkmM2R2cvn6OVE8ag7DxEZ0rGqvPz7Vvl4zk7p3ShC/Lz1VtfijHWHDNSdc6P+nBd157yoO+dF3Tmf/NSVpSE9MjLStIqXKVMm2+16fdu2bTk+ZtGiRfLFF1/IunXr8vQaI0eONC3u55s1a5ZpsXcGs2fPtroIcJG6C0wXCfXxkJOxyfLS5FlyXTnXXZLN2eoO/6HunBv157yoO+dF3Tkv6s55xMfHO0dIz6+YmBi5++67ZcKECRIWFpanx2grvY55z9qSXrFiRenatasEBweLo59t0S9ely5dxMvLy+riwEXqLqXcYRk+fbMsOOkrr9zdXgJ9nOrXhEvXnauj7pwb9ee8qDvnRd05L+rO+dh7dOeFpf/71qDt4eEhx48fz3a7Xo+IiLhg/927d5sJ42688cbM29LTM5aL8vT0lO3bt0v16tWzPcbHx8ds59MPs7N8oJ2prHD+urutRSX5bOE+2RMZJ9+uOCSPXldTXJEz1h0yUHfOjfpzXtSd86LunBd15zzyU0+WThzn7e0tzZs3lzlz5mQL3Xq9bdu2F+xfp04d2bhxo+nqbt9uuukmufbaa81lbSEHcGU8PdxlaJda5vL4BXskKp6xTgAAAEBRsbwfq3ZFv+eee6RFixbSqlUr+eCDDyQuLs7M9q4GDBgg5cuXN2PLdR31Bg0aZHt8iRIlzM/zbwdw+W5oWFbG/LtLth+Pkc8X7ZGnuta2ukgAAACAS7B8Cba+ffvKe++9JyNGjJAmTZqYFvGZM2dmTiZ34MABOXr0qNXFBFyKu7ubDOua0Zo+cdFeORX73woJAAAAAIpxS7p69NFHzZaTefPmXfSxkyZNKqRSAa6ta70y0rB8iGw8HGW6vb/Qo67VRQIAAACKPctb0gE4Jjc3N3nqXGv6V0v2yYnoRKuLBAAAABR7hHQAuepYq7S0qFxSklLTZczcXVYXBwAAACj2COkALtGanjFp3HcrDsihM/FWFwkAAAAo1gjpAC6qbfVSclWNUpKSZpNP/qU1HQAAAChMhHQAlzSsS0Zr+rTVh2RfZJzVxQEAAACKLUI6gEtqXrmkXFcnXNLSbfLhnJ1WFwcAAAAotgjpAPJkWJeMmd5/WXdYdh6Psbo4AAAAQLFESAeQJw3Kh0j3BhFis4m8/88Oq4sDAAAAFEuEdAB59mSXWuLmJjJj4zHZdDjK6uIAAAAAxQ4hHUCe1SoTJL0alzOX359NazoAAABQ0AjpAPLlic61xMPdTeZsOyFrDpyxujgAAABAsUJIB5AvVcMC5LZmFczl0bNoTQcAAAAKEiEdQL491qmGeHm4yaJdkbJ09ymriwMAAAAUG4R0APlWoaS/9GtVyVwePXu72HTKdwAAAABXjJAO4LI8cm0N8fF0l5X7zsjCnZFWFwcAAAAoFgjpAC5LmWBfGdC2srk8ahat6QAAAEBBIKQDuGwPdawu/t4esv5QlPyz9YTVxQEAAACcHiEdwGUrFegj911VJbM1PT2d1nQAAADgShDSAVyRB9pXlyBfT9l2LEZmbDpqdXEAAAAAp0ZIB3BFQvy9ZHD7auby6Nk7JDUt3eoiAQAAAE6LkA7gimmX95L+XrLnZJz8uu6I1cUBAAAAnBYhHcAVC/L1MpPIqQ/m7JAUWtMBAACAy0JIB1AgBrStImGBPnLwdIJMW3XI6uIAAAAATomQDqBA+Hl7yKPXZrSmf/zvTklMSbO6SAAAAIDTIaQDKDD9WleSciG+cjQqUb5fccDq4gAAAABOh5AOoMD4eHrIY51qmstj5u6W+ORUq4sEAAAAOBVCOoACdVvzClIp1F8iY5Nk8tL9VhcHAAAAcCqEdAAFysvDXYZ2zmhNHzd/t8QkplhdJAAAAMBpENIBFLheTcpL9dIBcjY+RSYu2md1cQAAAACnQUgHUOA83N1kWJfa5vLnC/fI2fhkq4sEAAAAOAVCOoBC0b1BhNQtGywxSakyfsEeq4sDAAAAOAVCOoBC4e7uJk91qWUuT1q8T07GJFldJAAAAMDhEdIBFJpOdcOlScUSkpCSJp/O22V1cQAAAACHR0gHUGjc3Nzk6a4ZY9O/XXZAjpxNsLpIAAAAgEMjpAMoVFfVKCVtqoVKclq6fPzvTquLAwAAADg0QjqAQm9Nf6ZbRmv61FWHZF9knNVFAgAAABwWIR1AoWteOVSurV1a0tJt8uEcWtMBAACA3BDSARSJp86NTf9l3WHZcTzG6uIAAAAADomQDqBINCgfYtZOt9lERs/aYXVxAAAAAIdESAdQZIZ1qSVubiIzNx+TjYeirC4OAAAA4HAI6QCKTM0yQXJzk/Lm8nuztltdHAAAAMDhENIBFKmhnWuJp7ubzN9xUlbuO211cQAAAACHQkgHUKQqlfKXPi0rmsvv/b1dbDpIHQAAAIBBSAdQ5B67roZ4e7rL8r2nZdGuSKuLAwAAADgMQjqAIlc2xE/ual3ZXKY1HQAAAPgPIR2AJR6+trr4e3vI+kNRMnvLcauLAwAAADgEQjoAS4QF+sh9V1Uxl0fP3iHp6bSmAwAAAIR0AJZ5oH11CfL1lG3HYuSPjUetLg4AAABgOUI6AMuE+HvJA+2rmcsfzN4hqWnpVhcJAAAAsBQhHYCl7ru6qoQGeMueyDj5ec1hq4sDAAAAWIqQDsBSgT6e8vA11c3lD+fslKTUNKuLBAAAAFiGkA7Acne1qSxlgn3k8NkEmbLyoNXFAQAAACxDSAdgOV8vD3nsuprm8sf/7pKEZFrTAQAA4JoI6QAcQp8WFaVCST85GZMkk5fus7o4AAAAgCUI6QAcgrenuwztXMtcHjt/t8QkplhdJAAAAKDIEdIBOIybm5aX6qUD5Gx8inyxaK/VxQEAAACKHCEdgMPwcHeTYV1qm8tfLNwrZ+KSrS4SAAAAUKQI6QAcSvcGEVK3bLDEJKXK+AV7rC4OAAAAUKQI6QAciru7mzzdNWNs+qQle+VETKLVRQIAAACKDCEdgMO5rk64NK1UQhJT0uXTubutLg4AAABQZAjpAByOm5ubPNM1Y2z6d8sPyOGzCVYXCQAAACgShHQADqldjTBpV72UJKely8dzdlpdHAAAAKBIENIBOKynzrWmT1t9SPZGxlldHAAAAKDQEdIBOKzmlUua8elp6Tb54J8dVhcHAAAAKHSEdAAO7alzM73/tv6IbD8WY3VxAAAAgEJFSAfg0OqXC5GeDcuKzSYyatZ2q4sDAAAAFCpCOgCH92SXmuLuJjJry3FZf/Cs1cUBAAAACg0hHYDDqxEeJL2bljeXR81mbDoAAACKL0I6AKcwtFMt8XR3kwU7TsqKvaetLg4AAABQKAjpAJxCpVL+0rdlRXP5vb+3i00HqQMAAADFDCEdgNN47Lqa4uPpLiv2nZYFOyOtLg4AAABgfUhPSEiQ+Pj4zOv79++XDz74QGbNmlXQZQOAbCJCfOXuNpXNZZ3pndZ0AAAAiKuH9F69esnkyZPN5bNnz0rr1q1l1KhR5vaxY8cWRhkBINND11QXf28P2XAoysz2DgAAALh0SF+zZo20b9/eXP7xxx+lTJkypjVdg/tHH31UGGUEgExhgT4y8Kqq5vLoWTskLZ3WdAAAALhwSNeu7kFBQeaydnG/5ZZbxN3dXdq0aWPCOgAUtsEdqkmwr6dsPx4jf2w4YnVxAAAAAOtCeo0aNeSXX36RgwcPyt9//y1du3Y1t584cUKCg4MLrmQAkIsQPy95sGN1c/n92TskJS3d6iIBAAAA1oT0ESNGyNNPPy1VqlQx49Hbtm2b2aretGnTgikVAFzCve2qSKkAb9l3Kl5+Wn3I6uIAAAAA1oT02267TQ4cOCCrVq2SmTNnZt7eqVMnef/99wumVABwCQE+njLkmozW9I/m7JSk1DSriwQAAABYs056RESEaTXXsejR0dGm+7uOU69Tp86VlwgA8uiuNpUlIthXjkQlyvfLD1hdHAAAAKDoQ3qfPn3kk08+yVwzvUWLFua2Ro0ayU8//XTlJQKAPPL18pDHOtUwlz+Zu1vik1OtLhIAAABQtCF9wYIFmUuwTZ8+XWw2m1kvXZdfe+ONN66sNACQT31aVJRKof4SGZskXy1hhQkAAAC4WEiPioqS0NBQc1nHpN96663i7+8vPXv2lJ07d15WIcaMGWMmovP19TWT0a1YsSLXfX/++WfTel+iRAkJCAiQJk2ayNdff31ZrwvA+Xl5uMsTnWqay+Pm75boxBSriwQAAAAUXUivWLGiLF26VOLi4kxIty/BdubMGROy82vKlCkybNgwefnll2XNmjXSuHFj6datm1nSLSd6guD//u//TBk2bNgg9913n9l0OTgArql30/JSIzxQohJS5IuFe60uDgAAAFB0IX3o0KFy5513SoUKFaRcuXJyzTXXZHaDb9iwYb4LMHr0aBk8eLAJ2vXq1ZNx48aZlvmJEyfmuL++3s033yx169aV6tWryxNPPGHGwy9atCjfrw2gePBwd5NhXWqZy18s2itn4pKtLhIAAABwWTzz+4CHH35YWrVqJQcPHpQuXbqYGd5VtWrV8j0mPTk5WVavXi3PP/985m36fJ07dzYt5Zei4+H//fdf2b59u7z99ts57pOUlGQ2O52NXqWkpJjNkdnL5+jlxIWou6LXqVYpqVc2SLYcjZExc3fKc90yQnt+UXfOi7pzbtSf86LunBd157yoO+eTn7pys2nSvUz2h7q5uV3W448cOSLly5eXJUuWSNu2bTNvf/bZZ2X+/PmyfPnyXMfF6+M0fHt4eMinn34qAwcOzHHfV155RV599dULbv/uu+9Miz2A4mPzGTf5bJuHeLnb5KWmaRLibXWJAAAAAJH4+Hjp37+/ybLBwcEF25KuJk+eLO+++27mRHG1atWSZ555Ru6++24pCrom+7p16yQ2NlbmzJljxrRrS769631W2kqv92dtSddx9TqW/lIHxxHOtsyePdv0WPDy8rK6OMgH6s4a3W02WTlhhaw9GCU7PKvKyz3q5vs5qDvnRd05N+rPeVF3zou6c17UnfOx9+jOC8/LGUP+0ksvyaOPPipXXXWVuU3Hgz/00EMSGRkpTz75ZJ6fKywszLSEHz9+PNvtej0iIiLXx2mX+Bo1MtZG1tndt27dKiNHjswxpPv4+JjtfPphdpYPtDOVFdlRd0XvmevrSP8Jy2XKqkPy0DU1pELJy+sxQ905L+rOuVF/zou6c17UnfOi7pxHfuop3xPHffzxxzJ27FgzBvymm24y2zvvvGO6nOta6fnh7e0tzZs3N63hdunp6eZ61u7vl6KPyTruHIDralc9TK6qUUpS0mzy0ZzLWxYSAAAAsEq+Q/rRo0elXbt2F9yut+l9+aVd0SdMmCBfffWVaREfMmSIWd5NZ3tXAwYMyDaxnLaYa9eOPXv2mP1HjRpl1km/66678v3aAIqnp7vWNj9/WnNY9pyMtbo4AAAAQOF1d9du5lOnTpUXXnjhgvXOa9asmd+nk759+8rJkydlxIgRcuzYMdN9XddfL1OmjLn/wIEDmTPIKw3wOsP8oUOHxM/PT+rUqSPffPONeR4AUE0rlZTOdcPln60n5P1/dsrH/ZpaXSQAAACgcEK6zpSugVjXRbePSV+8eLHpoq7h/XLo+HbdcjJv3rxs13WZt/wu9QbA9TzZpZYJ6b+vPyIPX1Nd6pZ17IkiAQAAgMvq7n7rrbeapdF00rdffvnFbHp5xYoVcvPNN3NUATiE+uVCpGejsuby6Nk7rC4OAAAAUDghXelkb9rFfPXq1WbTy7pu+f/+97/LeToAKBRPdq4l7m4is7ccl3UHz1pdHAAAAKBwQnpOdNI4XZoNABxFjfBAuaVZBXN51KztVhcHAAAAKLqQDgCO6IlONcXLw00W7oyUZXtOWV0cAAAA4KII6QCKtYqh/tK3ZUVz+b2/t4vNZrO6SAAAAECuCOkAir3HrqspPp7usmr/GZm346TVxQEAAACufAm2YcOGXfR+XescABxRmWBfGdC2skxYuNeMTb+mVmlxc3OzulgAAADA5Yf0tWvXXnKfDh065PXpAKBIPdSxuny3/IBsOhwtf28+Jtc3yFieDQAAAHDKkD537tzCLQkAFKJSgT4y8Oqq8vG/u2TUrB3SpV6EeOj6bAAAAIADYUw6AJcxqH01Cfb1lJ0nYuW39YetLg4AAABwAUI6AJcR4uclD3asbi6/P3unpKSlW10kAAAAIBtCOgCXct9VVSQs0FsOnI6XH1cfsro4AAAAQDaEdAAuxd/bUx6+poa5/NGcnZKYkmZ1kQAAAIBMhHQALqd/60pSNsRXjkYlmhnfAQAAAKcL6e+8844kJCRkXl+8eLEkJSVlXo+JiZGHH3644EsIAAXM18tDHruuprn86bxdEp+canWRAAAAgPyF9Oeff94Ecbvu3bvL4cP/zY4cHx8v48ePz+vTAYClbm9RQSqX8pfI2GT5cvE+q4sDAAAA5C+k22y2i14HAGfi5eEuQztntKaPn79bohJSrC4SAAAAwJh0AK7rpsblpWZ4oEQnpsoXC/dYXRwAAACAkA7AdXm4u8mwLrXM5S8W7ZVTsf/NswEAAABYwTM/O3/++ecSGBhoLqempsqkSZMkLCzMXM86Xh0AnMX1DSKkQflg2XQ4WsbN3y3Pds3oAg8AAAA4dEivVKmSTJgwIfN6RESEfP311xfsAwDOxM3NTZ7qWlvu+3KlTF66X+5pU9HqIgEAAMCF5Tmk79vH7McAiqdrapWWFpVLyqr9Z2Ts/L3SysPqEgEAAMBVMSYdgMvT1vSnu9U2l6euPiSnEq0uEQAAAFxVnkP60qVL5Y8//sh22+TJk6Vq1aoSHh4uDzzwgCQlMekSAOfUplopubpGmKSk2WTmIc5fAgAAwBp5/p/oa6+9Jps3b868vnHjRrn//vulc+fOMnz4cPn9999l5MiRhVVOACh09tb0lSfdTNd3AAAAwGFD+rp166RTp06Z13/44Qdp3bq1mUxu2LBh8tFHH8nUqVMLq5wAUOiaVCwhNzctJzZxk6embZSohBSriwQAAAAXk+eQfubMGSlTpkzm9fnz50v37t0zr7ds2VIOHjxY8CUEgCI0omcdKeVjkyNRifLiL5vEZrNZXSQAAAC4kDyHdA3oe/fuNZeTk5NlzZo10qZNm8z7dZ10Ly+vwiklABSRQB9PGVAzTTzc3eT39Ufk5zWHrS4SAAAAXEieQ3qPHj3M2POFCxfK888/L/7+/tK+ffvM+zds2CDVq1cvrHICQJGpEiTy+LUZv89G/LpJ9kXGWV0kAAAAuIg8h/TXX39dPD09pWPHjmYcum7e3t6Z90+cOFG6du1aWOUEgCL1YIeq0qpqqMQlp8kTU9ZJSlq61UUCAACAC/DM645hYWGyYMECiYqKksDAQPHw8Mh2/7Rp08ztAFAcaHf39/s2ke4fLJD1B8/Kh//szJz9HQAAACgs+V4MOCQk5IKArkJDQ7O1rAOAsytfwk/+d0tDc3nMvF2ybM8pq4sEAACAYi7PLekDBw7M037a7R0AiosbGpWT+dtPyrTVh+TJKetk5hMdJMSfSTIBAABgcUifNGmSVK5cWZo2bcqSRABcyis31ZeV+07LvlPx8vz0DTKmfzNxc3OzulgAAABw5ZA+ZMgQ+f77780ybPfdd5/cddddpos7ABR3AT6e8uEdTeXWsUtkxsZjMm3VIenTsqLVxQIAAIArj0kfM2aMHD16VJ599ln5/fffpWLFitKnTx/5+++/aVkHUOw1rlhChnWtZS6/8vtm2cuybAAAALB64jgfHx/p16+fzJ49W7Zs2SL169eXhx9+WKpUqSKxsbGFUT4AcBgPdqgubauVknhdlu2HtZKcyrJsAAAAsHh298wHurubMZnaip6WllawpQIAB12WbXTfxhLi5yUbDkXJ6Nk7rC4SAAAAXDmkJyUlmXHpXbp0kVq1asnGjRvlk08+kQMHDrBGOgCXUDbET96+NWNZtvELdsuS3ZFWFwkAAACuGNK1W3vZsmXlrbfekhtuuEEOHjwo06ZNkx49ephWdQBwFdc3KCv9WlUUnY5j2JT1ciYu2eoiAQAAwNVmdx83bpxUqlRJqlWrJvPnzzdbTn7++eeCLB8AOKSXbqgny/eelj0n42T4zxtk3F3NWZYNAAAARRfSBwwYwH9AAeAcf29P+eiOpnLzp4vl783H5YeVB6Vfq0pWFwsAAACuEtInTZpUuCUBACfToHyIPNOttvxvxjZ59ffN0rJKqNQIZ34OAAAAXD4GkwPAFRh0dTW5ukaYJKakm2XZklJZ7QIAAACXj5AOAFfA3d1NRvVpLCX9vWTzkWgZNYtl2QAAAHD5COkAcIXKBPvK27c2Mpc/W7BHFu48aXWRAAAA4KQI6QBQALrWj5A7W2dMHPfU1PVymmXZAAAAcBkI6QBQQF7sWc9MHHciJkme/XGD2HQhdQAAACAfCOkAUED8vD3kwzuaiLeHu/yz9bh8s/yA1UUCAACAkyGkA0ABql8uRJ69vra5/MYfW2Tn8RiriwQAAAAnQkgHgAI28Kqq0r5mmCSlpsvjP6yTxBSWZQMAAEDeENIBoJCWZSsV4C1bj0bLOzO3W10kAAAAOAlCOgAUgvAgX3nntoxl2SYu3ivztp+wukgAAABwAoR0ACgkneqWkQFtK5vLT0/bIJGxSVYXCQAAAA6OkA4AheiFHnWlVplAE9CfmbaeZdkAAABwUYR0AChEvl4e8lG/puLt6S5zt5+UyUv3W10kAAAAODBCOgAUsjoRwfJ89zrm8psztsr2YyzLBgAAgJwR0gGgCNzbropcU7u0JOuybN+vZVk2AAAA5IiQDgBFwM3NTd67vbGEBXrL9uMx8tZf26wuEgAAABwQIR0AikhYoI+8e3tjc3nSkn3y77bjVhcJAAAADoaQDgBF6Nra4XLfVVXM5WembZATMYlWFwkAAAAOhJAOAEXsuevrSJ2IIDkVl2yCeno6y7IBAAAgAyEdACxals3H013m7zhpur4DAAAAipAOABaoVSZIXuxZ11zWSeS2HIm2ukgAAABwAIR0ALDIXW0qS+e64ZKcli5P/MCybAAAACCkA4Cly7K9fWsjKR3kIztPxMqbf261ukgAAACwGCEdACxUKtBHRvfJWJbt62X7ZfYWlmUDAABwZYR0ALBY+5qlZdDVVc3lZ39cL8ejWZYNAADAVRHSAcABPHN9balXNljOxKfIU1PXsywbAACAiyKkA4AD8PHMWJbN18tdFu2KlC8W7bW6SAAAALAAIR0AHESN8EB56YZ65vI7f2+TTYejrC4SAAAAihghHQAcSP9WlaRrvTKSkmaTx39YK/HJqVYXCQAAAEWIkA4ADrgsW5lgH9lzMk5e/4Nl2QAAAFwJIR0AHEzJAG8Z3aeJuLmJfL/igMzcdMzqIgEAAKCIENIBwAFdVSNMHuhQzVwe/vMGORbFsmwAAACugJAOAA7qqS61pWH5EDkbnyLDpq5jWTYAAAAXQEgHAAfl7ekuH9zRRPy8PGTJ7lPy2cI9VhcJAAAAhYyQDgAOrHrpQHnlpoxl2d77e7tsOHTW6iIBAACgEBHSAcDB9WlRUbo3iJDUdJs88cM6iUtiWTYAAIDiipAOAE6wLNvIWxpK2RBf2RsZJ6/9vsXqIgEAAKCQENIBwAmU8P9vWbYpqw7KjI1HrS4SAAAAimtIHzNmjFSpUkV8fX2ldevWsmLFilz3nTBhgrRv315Klixpts6dO190fwAoLtpWLyVDOlY3l4f/tEGOnE2wukgAAAAobiF9ypQpMmzYMHn55ZdlzZo10rhxY+nWrZucOHEix/3nzZsn/fr1k7lz58rSpUulYsWK0rVrVzl8+HCRlx0AitqTXWpJ4wohEp2YKk9OWSdpLMsGAABQrFge0kePHi2DBw+W++67T+rVqyfjxo0Tf39/mThxYo77f/vtt/Lwww9LkyZNpE6dOvL5559Lenq6zJkzp8jLDgBFzcvDXT68o6n4e3vI8r2nZdz83VYXCQAAAAXIUyyUnJwsq1evlueffz7zNnd3d9OFXVvJ8yI+Pl5SUlIkNDQ0x/uTkpLMZhcdHW1+6mN0c2T28jl6OXEh6s55OUPdlQ/xlhE968jw6Zvl/dk7pHWVEqZ13dU5Q90hd9Sf86LunBd157yoO+eTn7pys9lslvWVPHLkiJQvX16WLFkibdu2zbz92Weflfnz58vy5csv+Rzaqv7333/L5s2bzZj2873yyivy6quvXnD7d999Z1rsAcAZ6W/ur3a6y9pT7hLmY5NnGqeJr4fVpQIAAEBujcv9+/eXqKgoCQ4OFodtSb9Sb731lvzwww9mnHpOAV1pK72Oec/akm4fx36pg+MIZ1tmz54tXbp0ES8vL6uLg3yg7pyXM9Xd1QkpctOYpXIkKlF+P11GPu3XRPy8XTepO1Pd4ULUn/Oi7pwXdee8qDvnY+/RnReWhvSwsDDx8PCQ48ePZ7tdr0dERFz0se+9954J6f/88480atQo1/18fHzMdj79MDvLB9qZyorsqDvn5Qx1F+blJR/3byZ3f7FcFu06JQ98u1a+uKelBPg49flXl6g75I76c17UnfOi7pwXdec88lNPlk4c5+3tLc2bN8826Zt9Eris3d/P984778jrr78uM2fOlBYtWhRRaQHA8TSvXFImD2wlgT6esmzPaRkwcYVEJzI+DQAAwFlZPru7dkXXtc+/+uor2bp1qwwZMkTi4uLMbO9qwIAB2SaWe/vtt+Wll14ys7/r2urHjh0zW2xsrIXvAgCs06JKqHw7qLUE+3rK6v1n5K7Pl8vZ+GSriwUAAABnDOl9+/Y1XddHjBhhllVbt26daSEvU6aMuf/AgQNy9OjRzP3Hjh1rZoW/7bbbpGzZspmbPgcAuKrGFUvI9w+0kdAAb9lwKEr6TVgup2L/W9kCAAAAzsEhBi4++uijZsuJTgqX1b59+4qoVADgXOqXC5EfHmgjd36+XLYejZa+ny2T7wa1lvDgnCfWBAAAgOOxvCUdAFBwapUJkikPtJGyIb6y60Ss9Bm/VI6cTbC6WAAAAMgjQjoAFDPVSgfK1AfbSoWSfrLvVLwJ6gdPx1tdLAAAAOQBIR0AiqGKof4mqFcNC5BDZxLk9nFLZc9JJtgEAABwdIR0ACimypXwM13fa4QHyrHoROkzfpnsOB5jdbEAAABwEYR0ACjGdNI4nUyuTkSQRMYmyR2fLZPNR6KsLhYAAAByQUgHgGIuLNDHBPVGFULkdFyy9Ptsmaw/eNbqYgEAACAHhHQAcAEl/L3lm0GtpXnlkhKdmGqWaVu177TVxQIAAMB5COkA4CKCfb1k8sBW0qZaqMQmpcqAiStkye5Iq4sFAACALAjpAOBCAnw85ct7W0n7mmESn5wm9325UuZtP2F1sQAAAHAOIR0AXIyft4dMGNBCOtcNl6TUdHlg8mqZtfmY1cUCAAAAIR0AXJOvl4d8emdz6d4gQpLT0uXhb9fInxuOWl0sAAAAl0dIBwAX5e3pLh/3ayq9m5ST1HSbPPb9Gpm+9pDVxQIAAHBphHQAcGGeHu4yqk8T6duioqTbRIZNXS8/rDhgdbEAAABcFiEdAFych7ubjLylodzdprLYbCLDf94ok5fus7pYAAAALomQDgAQd3c3ea1XfRncvqq5PuLXzfLZgt1WFwsAAMDlENIBAIabm5u80KOuPHptDXP9fzO2ycdzdlpdLAAAAJdCSAcAZAvqT3erLU91qWWuj5q9Q979e5vYtB88AAAACh0hHQBwgcc61ZT/61HXXB4zd7e88edWgjoAAEARIKQDAHI0uEM1M05dfbFor7z06yZJ1yngAQAAUGgI6QCAXA1oW0XevrWhuLmJfLPsgAz/eYOkEdQBAAAKDSEdAHBRfVtWktF9Gou7m8jUVYdk2NR1kpqWbnWxAAAAiiVCOgDgkm5uWkE+7tdMPN3d5Nd1R+Sx79dKcipBHQAAoKAR0gEAedKzUVkZe1dz8fZwl782HZMh36yWxJQ0q4sFAABQrBDSAQB51qVeGZlwTwvx8XSXOdtOyODJqyQhmaAOAABQUAjpAIB86VirtHx5X0vx9/aQhTsj5d4vV0hsUqrVxQIAACgWCOkAgHxrVz1MJg9sJYE+nrJ872kZ8MVyiU5MsbpYAAAATo+QDgC4LC2qhMq3g1pLiJ+XrDlwVu76fLmcjU+2ulgAAABOjZAOALhsjSuWkO8Gt5bQAG/ZcChK7vhsmUTGJlldLAAAAKdFSAcAXJH65ULkhwfaSOkgH9l2LMYE9ePRiVYXCwAAwCkR0gEAV6xWmSCZ8kAbKRviK7tOxErf8Uvl8NkEq4sFAADgdAjpAIACUa10oEx9sK1UKOkn+07FS59xS+XAqXiriwUAAOBUCOkAgAJTMdTfBPWqYQGmJb3P+KWy+2Ss1cUCAABwGoR0AECBKlfCz3R9rxkeKMeiE6Xv+GWy43iM1cUCAABwCoR0AECBCw/2NZPJ1S0bbGZ718nkNh+JsrpYAAAADo+QDgAoFKUCfeT7wa2lUYUQOR2XLP0+WybrDp61ulgAAAAOjZAOACg0Jfy95ZtBraV55ZISnZgqd32+XFbuO211sQAAABwWIR0AUKiCfb1k8sBW0qZaqMQmpcqAL1bIkl2RVhcLAADAIRHSAQCFLsDHU768t5W0rxkmCSlpcvfEFfLmn1skLinV6qIBAAA4FEI6AKBI+Hl7yOf3tJBeTcpJWrpNJizcK51Hz5eZm46JzWazungAAAAOgZAOACgyPp4e8uEdTeXLe1tKxVA/ORqVKA99s1ru/2qVHDwdb3XxAAAALEdIBwAUuWvrhMusoR3l0WtriJeHm/y77YR0eX++jJm7S5JT060uHgAAgGUI6QAAy7q/P92ttvz1RHszqVxiSrq8+/d26fHRQlm255TVxQMAALAEIR0AYKka4UHy/eA2MrpPYykV4C27TsTKHZ8tk2FT10lkbJLVxQMAAChShHQAgOXc3NzklmYV5N+nrpE7W1cSNzeRn9cclk6j5st3yw9IejoTywEAANdASAcAOIwQfy958+aG8vOQdlKvbLBEJaTIC9M3ym3jlsiWI9FWFw8AAKDQEdIBAA6naaWS8tujV8lLN9STAG8PWXPgrNz4ySJ5/Y8tEsva6gAAoBgjpAMAHJKnh7vcf3VVmfPUNdKzYVmztvoXi/ZK51Hz5a+NR1lbvRjR4Qw7jsdIGlUKAAAhHQDg2CJCfGXMnc1k0n0tpVKovxyLTpQh366RgZNWyoFTrK3u7KLiU+S+SSul5ydL5aNNHnLoTILVRQIAwFKEdACAU7imdrjMerKDPHZdxtrqc7efNGurf/LvTklKTbO6eLgMu07ESO9PF8v8HSfN9X2xbnLTp0tlxsajVhcNAADLENIBAE7D18tDnupaW2YO7SDtqpeSpNR0eW/WDunx4UJZvve01cVDPszZelx6j1kieyPjpHwJPxl3ZxOpEmiTmMRUefjbNWbCwMQUTr4AAFwPIR0A4HSqlw6Ubwe1lg/6NpGwQG/ZfTJO7pq4Sr7Z6S6nWFvdoelcAmPm7pJBk1eZSQBbVQ01kwR2qhMuj9dPkwfbVzVL8OnSe70+WWzGqgMA4EoI6QAAp11bvXfT8mZiubvbVDbBbmWku3T9cLF8u3w/a6s7oPjkVHn0+7Xy7t/bRef903rTky2lAn3M/R7uIk93rSmTB7YyJ1+2H4+Rmz5ZJD+sOMBEgQAAl0FIBwA4tRA/L3m9dwOZ9kBrqRBgk+jEVPm/6ZvklrFLZPORKKuLh3MOnYmX28YulT83HDVzCvzv5oam3rw0mZ+nfc3SMuOJ9tK+ZpgkpqTL8J83ymPfr5XoxBRLyg4AQFEipAMAioXGFUJkWMM0ebFHbQn08ZR1B8/KjR8vktd+Z211qy3bc0pu+mSxbDkabVrIvxvcRvq3rnTRx4QH+cpX97WS4d3riKe7m/yx4aj0/GihqVcAAIozQjoAoNjwcBO5p21lmfNUR7mhUVnRHu8TF++VTqPmmRnD6TJdtPR4f710n9z1+XI5HZcsDcoHy2+PXi0tq4Tm6fHu7m7yUMfqMvWhtlKhpJ8cPJ0gt41dIuPn72Y4AwCg2CKkAwCKnTLBvvJJ/2ZmbHPlUv5yPDrJzBh+75crZf+pOKuL5xKSU9PNDO0v/bpZUtNt0qtJOZn2YDspV8Iv38/VrFJJ+fPx9tKzYVnzXCP/2mbWVo9kkkAAQDFESAcAFFsdapWWv4d2kMc71RRvD3ezHnfX9xfIx3NYW70wnYxJkv4Tlsn3Kw6aCf2e717HzMTv5+1xRXMPfNK/qRnL7uOZUZfdP1woi3dFFmjZAQCwGiEdAFDs11Yf1qWWzBzaXq6uEWbWVh81e4cJeEsIeAVuw6GzZkb2VfvPSJCvp0y8t6U82LG6mY3/Sulz6Fh27TJfMzzQnAy464vl8u7f2yQ1Lb1Ayg8AgNUI6QAAl1CtdKB8fX8r+fAOXVvdR/acjJP+ny+XoT+sNWEPV+6XtYfl9nFL5WhUolQrHSC/PnKVXFs7vMBfp3ZEkAnq/VpVNEu5jZm7W/p+tszMIA8AgLMjpAMAXIa2xPZqomurd5QBbTPWVv9l3RG5btQ8+XrZfkljMrLLosdt5IytMnTKOtNT4bo64fLLI1eZEyOFRbvOj7ylkekCH+TjKav3n5EeHy6UmZuOFtprAgBQFAjpAACXo+ObX+vVwLT0NiwfIjGJqfLSL5vklk8Xy6bDrK2eH1HxKTJw0koZv2CPuf7ItdVlwoAWEuzrVSSvf0OjcmZN9cYVS0h0Yqo89M0aU5eJKcw5AABwToR0AIDLalShhGnxffWm+qY1dv2hKDOe+pXfNktMYorVxXN4u07ESO9PF5tJ3Hy93OXjfk3lmW51xMP9ysef50fFUH+Z9mBbebBDNXNde0X0HrPYlA8AAGdDSAcAuDQNlPe0q2K6wN/YuJxZW33Skn3SadR8+WPDEdZWz8Wcrcel95glsjcyTsqX8JOfhrQzx88q3p7u8nyPuvLVwFZSKsBbth2LkRs/XixTVx2kDgEAToWQDgCAiIQH+5qWYJ1crkopfzkRkySPfrdWBkxcIfsiWVvdTgPvmLm7ZNDkVRKblCqtqobKb49eJfXLhYgj6FirtPz1RHu5qkYpSUhJk2d/3CBP/LCOnhEAAKdBSAcAIIv2NUvLzKEdZGjnjLXVF+6MlK4fLJAXf9koO467dvfp+ORUefT7tfLu39vNrOp3t6ks3w5qLaUCfcTRTrh8PbC1PNOttukp8dv6I3LDx4vM8nAAADg6QjoAADmsrT60cy35+8kO0r5mmCSnpss3yw5I1/cXSL/PlpkZxF1tXe6Dp+Pl1rFL5c8NR8XLw03+d3NDeb13A/HycMz/Sri7u8kj19aQqQ+2Md3x95/S8i+RzxfukXRm8QcAODDH/MsKAIADqBoWIJMHtpLvBrWWbvXLiM6HtnTPKTODeId35ppu36dii/8a68v2nJJeYxbL1qPREhboLd8NbiP9W1cSZ9C8cqjMeLy9XF8/QlLSbPLGn1vl/q9WukS9AQCcEyEdAIBLrK3erkaYjL+7hSx87jp5+JrqEhrgLUeiEk2377Yj/5VhU9fJ+oNni+X486+X7pO7Pl8up+OSpUH5YPnt0aulZZVQcSYh/l4y9q5mpuVfJ5ibu/2kdP9woSzZHWl10QAAuAAhHQCAPNJu089eX0eWDL9ORt3eWBpVCJHktHT5ec1h09Ks289rDklSqvOv0a1d/F+YvlFe+nWzpKbbpFeTcjLtwXZSroSfOOvJFh1D/+sjV0mN8EAzMeCdny+X0bO2u9zQBQCAYyOkAwBwGWPWb21ewbQq6zrrNzctbyaZ09b0YVPXS7uR/8p7f2+XI2cTxBmdjEmS/hOWyfcrDoqbm8jz3evIB32biJ+3hzi7umW1N8BV0rdFRTP53Uf/7pJ+E5Y5bV0BAIofQjoAAFegScUS8n7fJrJ4+HXydNdaEhHsK6fikuWTubuk/TtzZcg3q2Xp7lNOs1a3zoB+0yeLZNX+MxLk6ykT720pD3asblqiiwt/b095+7ZG8uEdTSTQx1NW7jtjur/P2nzM6qIBAEBIBwCgIJQO8pFHr6spi567Vsbe2UzaVAuVtHSb/LXpmGmpvf6DhfLt8v0Sl5QqjuqXtYfl9nFL5WhUolQrHWC6hl9bO1yKq15Nysufj19thi1EJaTIA1+vlpd/3SSJKc4/XAEA4LwI6QAAFCBPD3fp3rCs/PBAW5k5tL2ZBd3Py0O2H4+R/5u+SdqMnCOv/b5F9kbGiaPQkwkjZ2yVoVPWSVJqulxXJ9x0469WOlCKu8qlAuTHh9rJ4PZVzfWvlu6XWz5dIrtPxlpdNACAiyKkAwBQSOpEBJv1xJe90EleuqGeVCnlLzGJqTJx8V659r15cs/EFTJ32wlL1+2Oik+RgZNWyvgFe8z1R66tLhMGtJBgXy9xFTrj+//1rCdf3tfSzNy/5Wi03PjxIvlp9SGriwYAcEGEdAAAClmIn5fcf3VV+fepa2TSfS1NS7UO8Z6/46TcN2mlXPPePPl84R4TmIvSrhMx0vvTxaYcvl7u8nG/pvJMtzrioQvCuyDt2v/XE+2lbbVSEp+cJk9NWy9PTlknsQ48RAEAUPwQ0gEAKCLu7m5yTe1wMxnb3KeukUFXV5VgX085cDpe3vhzq7Qe+Y88//MG2Xo0utDL8s+W49J7zBLT7V6XlvtpSDu5sXE5cXVlgn3lm0Gt5akutUTPVUxfe1hu+GihbDocZXXRAAAugpAOAIAFqoQFyIs31DNd4Ufe0lDqRARJYkq6WfZMZxrvM26p/LnhqKQU8BreOsv8mLm7ZPDXq0wLcauqoWZJsvrlQgr0dZyZ9iR4rFNNmfJgWykX4iv7TsXLzZ8ulomL9jrNLP0AAOflaXUBAABwZbocWL9WleSOlhXNUmBfLd0nMzcdkxX7TputTLCP3Nm6stzRqqKEB/le0WvFJ6fKM9M2yJ8bj5rrd7epLCNurCdeHpyzz0nLKqEy44n28uyPG2TWluPy2h9bZPGuSHn39sZm7DoAAIWBv8oAADgAXYdcW7XH9G8mi5+7Th6/roaEBXrL8egkGT17h1z11r/yxA9rZfX+M5fVmnvwdLzcOnapCeheHm5mQrvXezcgoF9CCX9vGX93c3mtV33x9nCXOdtOSI8PF8qyPaesLhoAoJjiLzMAAA4mIsRXhnWtLYuHXycf3tFEmlYqISlpNvl13RG5dewSufGTRTJt1cE8r+etgbLXmMVmrLsG/+8GtzFLwyHvJ1AGtK0i0x9pZ9aPPxadKP0nLJM3/9zCUm0AgAJHSAcAwEH5eHpIryblZfrDV5lx47c1r2CWC9t0OFqe+XGDtB05R976a5scOhOf4+O1xf3rpfvkrs+Xy+m4ZGlQPlh+e/Rq040b+afj9n9/9GpTD7pq3oSFe6XTqPnS86OFMm7+7lzrAQAApwrpY8aMkSpVqoivr6+0bt1aVqxYkeu+mzdvlltvvdXsr2e1P/jggyItKwAAVmlUoYS8d3tjWfZ8J3nu+jpmRvYz8SkmHHZ4Z64MnrxKFu2MzOwKn5yaLi9M3ygv/bpZUtNt0qtJOZn2YDspV8LP6rfi1AJ8PE09fHZ3c7mmdmnxdHeTzUeizcmSq9+eK7d8uli+XLxXTkQnWl1UAICTsnTiuClTpsiwYcNk3LhxJqBr6O7WrZts375dwsPDL9g/Pj5eqlWrJrfffrs8+eSTlpQZAAAr6YRlQ66pLg90qCZzth43E80t3nVKZm85brbqpQPMRHMzNh6VVfvPmPXYh19fx+yvJ7hRMLrWjzCb9lDQif5+X39Elu09JWsOnDWbTjLXpmops6xd9wYRUpKJ5gAAzhDSR48eLYMHD5b77rvPXNew/ueff8rEiRNl+PDhF+zfsmVLs6mc7gcAwJWWCbMHxV0nYmTy0v3y0+pDsvtknAmIKsjXUz7q11SurX3hiW8U3EkTHd+vm7ae68R8Gtg1qC/dc8psI37dJFfXDJMbG5WTLvXLSLCvl9XFBgA4MMtCenJysqxevVqef/75zNvc3d2lc+fOsnTp0gJ7naSkJLPZRUdHm58pKSlmc2T28jl6OXEh6s55UXfOy5XrrnJJX3mpR20Zel11+WXdEflh5SHx8nST929vJFXDApzimBSH+ivp5yF3tapgtkNnEmTGpmPy58ZjsuVojMzbftJs3tPdpWPNMLmhYYRcW7u0+Hl7iLMrDnXnqqg750XdOZ/81JWb7XLWcSkAR44ckfLly8uSJUukbdu2mbc/++yzMn/+fFm+fPlFH6/j0ocOHWq2i3nllVfk1VdfveD27777Tvz9/a/gHQAAAFza8QSRtZFusuaUuxxP+G/Igbe7TRqUtEmzMJvULWETT8tnCgIAFBYdut2/f3+JioqS4OBgx+3uXhS0pV7HvWdtSa9YsaJ07dr1kgfHEc62zJ49W7p06SJeXnSNcybUnfOi7pwXdefcinv96cA+bRfZfjzWtK7/sfGYaW1fc0rDe8bQhK71wqVnwwhpWzVUPJ1o/friXnfFGXXnvKg752Pv0Z0XloX0sLAw8fDwkOPHj2e7Xa9HREQU2Ov4+PiY7Xz6YXaWD7QzlRXZUXfOi7pzXtSdcyvu9dewYqjZnuteV9YfijLj1//YcESORyfJT2uOmK1UgLd0bxghNzUuLy0qlxR3d+eY8K+4111xRt05L+rOeeSnniwL6d7e3tK8eXOZM2eO9O7d29yWnp5urj/66KNWFQsAAKDQ6Uz7TSqWMNv/9agrK/edlt83HJEZG4/Jqbhk+WbZAbNFBPvKDY3KmlniG1UIYYZ+AHABlnZ3127o99xzj7Ro0UJatWpllmCLi4vLnO19wIABZtz6yJEjMyeb27JlS+blw4cPy7p16yQwMFBq1Khh5VsBAAC4LNpS3rpaKbO9cmN9WbL7lGlhn7n5mByLTpTPF+01W6VQf7mxcUZgr10miMAOAMWUpSG9b9++cvLkSRkxYoQcO3ZMmjRpIjNnzpQyZcqY+w8cOGBmfM862VzTpk0zr7/33ntm69ixo8ybN8+S9wAAAFBQdCx6h1qlzfbGzQ1kwY5IE9hnbzkuB07Hy5i5u81WMzzQhHVtZa9WOtDqYgMACpDlE8dp1/bcurefH7x1RneLJqMHAAAoUj6eHtKlXhmzxSenyr/bTpjAPnf7Sdl5IlZGz95htgblg80a7D0blZUKJVm5BgCcneUhHQAAABfn7+0pNzTSlvNyEp2YIrM3Hzdj2BfujJRNh6PNNvKvbdK8ckm5sVFZ6dGorIQH+VpdbADAZSCkAwAAOJFgXy+5tXkFs52OS5aZm46ZFvZle0/J6v1nzPbaH1ukTbVSpkv89fUjpGSAt9XFBgDkESEdAADASYUGeEv/1pXMdjw6UWZsPGoC+5oDZ80EdLq99MsmaV8zzLTCt68VRgs7ADg4QjoAAEAxUCbYV+67qqrZDp6Olz/PBfbNR6LNOHbdVJVS/tKiSqi0qhIqLaqUlKphAcwUDwAOhJAOAABQzFQM9ZeHOlY32+6TsfLH+qNmSbdtx6Jl36l4s/24+pDZNyzQR1pWKZkZ3OuWDTKzzAMArEFIBwAAKMaqlw6UJzrXNFtUQoqsOXBGVu49LSv3nZb1B6MkMjZJ/tp0zGwqwNtDmlUuKS3PtbQ3rVhS/Lw9rH4bAOAyCOkAAAAuIsTPS66tHW42lZiSJhsPR5nArsF91f4zEpOYamaN1015ebhJg/IhJrSb4F65JBPRAUAhIqQDAAC4KF8vj8zwLdeIpKXbZMfxmIzQvi+jxf1YdKKsPXDWbJ8t2GMeVzM8UFpW1ceVlKYVgq1+GwBQrBDSAQAAYHi4u0ndssFmG9C2ithsNjl0JuFcaM8I7rtOxMrOc9t3yw+Yx5Xw9pDZsRukdfUwE9xrhQeJuzuT0QHA5SCkAwAAIEc667tOQqfbLc0qmNtOxSaZbvGr9p2WFfvOyObDUXI2WeSPjcfMZu9Wr93izWR0VUua7vI+noxrB4C8IKQDAAAgz0oF+ki3+hFmU1FxCfLZT7PFo0wtWXMwykxMpxPUzdl2wmzKx9NdGlcskbnsW/PKJSXI18vidwIAjomQDgAAgMvm7+0ptUJs0uO66uLl5SUpaemy5Uh0Zhf5VfvOyKm4ZFmx97TZlPaE1y719vHw2kU+PNjX6rcCAA6BkA4AAIAC4+WR0Wqu26D21cy49j2RceeWfTtjgvuB0/Gy+Ui02SYt2WceV7mUf2Zg159VwwJMd3sAcDWEdAAAABQaDdq6Vrtud7SqZG47Hp2Y2cquretbj0XL/lPxZvtx9SGzT1igtzSuUEJqhGc8tnp4gNQoHSQh/nSTB1C8EdIBAABQpMoE+8oNjcqZTUUnpsia/Rmt7Cv3npF1h85KZGxytnHtdhreq5UO/C+8lw4wl8uF+DGjPIBigZAOAAAASwX7esk1tcPNppJS02TjoSjZeixGdp+Ild0nY83PI1GJJrxHxv43vt3O18tdqoVpi3ug1DjX8q4hXrvN63rwAOAsCOkAAABwKLpcmy7fpltWcUmpsudknAntu+zh/WSs7I2Mk8SUdNlyNNpsWemw9ool/TNb3DO6zmf8DA3wLuJ3BgCXRkgHAACAUwjw8ZSGFULMllVqWrocPJOQ2eq+K8vP6MRUM1GdbnO3n8z2OA3pGt6rZ+s+HyjlS/qJB13nAViEkA4AAACn5unhbrq169ZZymTerjPLa/d4e4t7RniPM2H+8NkEOR2XbDaddT4rXdddn8ve4p4R4ANMd3o/b7rOAyhchHQAAAAU25nlSwf5mK1NtVLZ7otP/q/rfEYLfMZlXS4uKTVdth2LMVv25xMpX8Ivs8U9Y8b5jO7zpQK8WTIOQIEgpAMAAMDl+Ht7SoPyIWbLKi3dJofOxJ8L73H/dZ0/GStn41Pk0JkEs83fkb3rfIifl2lt15nr9aRAWKBP5k+dkd5+mUnsAFwKIR0AAAA4R8eiVy4VYLbr6mS/71RsUmaLe9aJ6zS0RyWkyJoDZy/5/EG+nlJag7u28GcGee9soV5/lgr0NhPoAXA9hHQAAAAgD0oFanj2kVZVs886n5CcZmaY1+1kTMYycSdjkiQyNklOxiZJpLmcLMlp6RKTmGo27VZ/Kdo6n1OA/y/ca9j3llIBPuLt6V6I7xxAUSKkAwAAAFdAJ5OrVy7YbLnRSeyiE1JNaLcHeBPi7WH+XJC3X09Nt5nWed209f5SSvh7ZbTQnxfoTcjPEux17LxOtAfAcRHSAQAAgEKmk8qF+HuZTWeLvxgN9BrONbCfzCHAZw33eruOo9fx8rrtPBF7iXKIlPT3NqG9VICXJEW7y7q/tkvpYN/M8fMZP+lyD1iFkA4AAAA4WKAv4e9ttpplgi66b7oG9HOBPmuAzxruI89d1zH16TbJXHoug7usjtx/0TH09vCu3eq1e31GgNfWeW/z0x7og3w8meEeKACEdAAAAMBJubu7SWiAt9lqy8UDvba4n4lPzgjzMcly7GycLFy1XsIrVpfT8anm9lNxGffpz5Q0W+YYeh1vfyk6Lt600J9rjdeu9drVXn/au+Db79PWfJ2kD8CFCOkAAACAC9BQbO/KLhEiKSkh4nVknfToVku8vLxyHEMfaUJ7Rot8RoBPksi4jNb5U/rz3MR4cclpkpyaLofPJpjtUjSf64mFbK3z9svnfmZczwj5LF0HV0JIBwAAAJDrGPrqpS8+ht4+w31GS3xGgLdf1i739ttMyI9NNq352u3edMWPTZbtxy9dHu1Kbw/swX5eEujjabriB/l6nfuZsQX6ZLl+7nKgr6d4MVkenAghHQAAAMAVz3BfMdTfbJeSmpYup7Xb/blu9fbu9xmt9v/ddsqE+HPd7pNSzZaXbvc58fVyzxLovUzozzHYZwn+GScCvCT4XND38/JgzD2KBCEdAAAAQJHRJeDCg3zNdinnd7vXVvnYxFSJTkwxY+VjNbxnuRxtxtCnmH30toSUNPM8iSnpkpiSMZneZZfb3c2EdXt4z2itPy/Y+2YJ9uf2C/DxMAHf39vTnMzQy6xrj4shpAMAAAAoFt3uz5eSli5xJshnBHt7eI9JyricEeo14GcEfXM5h5MA2j0/NctSdyKXHnd/qcCvYV1Du7+3hxlzrz8zQnxGmPc/d/8Fl709xMtNZOtZNym974wE+/tkhn/7c/l4utPq78QI6QAAAACKJR2Lbl/O7nJpa358clpmYNdgnxn2Nfjn0IJvPwlgD/raoq/j9jXoK/1p78J/+Txk3NaVuU7Ml3ESwDMj/NtDfraTAedCvTkJoCcG3DP29/LIaP339pQAc1LA89x1DwnQ3gBeHmZVARQeQjoAAAAA5EJbpAN8NKh6SpngS3fRv1TLvgZ+Dewa3OOTUyXR/MzY7Jez3p+QnC4JKfrz3H16e1KqHIs8I15+AaYrf8bzpEtyWrp5HT0XoDPu61YYNNxnbBknAfTY2G8L0Nt8zgX6S1zPfIyPJ63/WRDSAQAAAKCIWvZD/HTLvuRdfqWkpMiMGTOkR4+rsy2fpycBNMQnZg30eTkpcK6lX++3768BPyE51fzUkwLxKWliy+gIkPl4kWQpKNo4H2AP8j7nwn/m9XMt+hrq9T7tBeCT/Xr7WmHi41k8luojpAMAAABAMTkJoFuw75WdBMhJerpNElPPBfwkDfGpmaE+Likj4GcG+yzXTcA/F+rNY/S+lIyfced6AJjnt8l/QwBi8j/B38ZXuhLSAQAAAACuQcehZ3Rv9xTJ/xx+uUpLt2V24Tdd9JPsod5+AuC/kB+f5QTA+ddNuYqJ4vNOAAAAAABOxUOXtvPJWLIOGVigDwAAAAAAB0FIBwAAAADAQRDSAQAAAABwEIR0AAAAAAAcBCEdAAAAAAAHQUgHAAAAAMBBENIBAAAAAHAQhHQAAAAAABwEIR0AAAAAAAdBSAcAAAAAwEEQ0gEAAAAAcBCEdAAAAAAAHAQhHQAAAAAAB0FIBwAAAADAQRDSAQAAAABwEIR0AAAAAAAcBCEdAAAAAAAHQUgHAAAAAMBBeIqLsdls5md0dLQ4upSUFImPjzdl9fLysro4yAfqznlRd86LunNu1J/zou6cF3XnvKg752PPn/Y8ejEuF9JjYmLMz4oVK1pdFAAAAACAi+XRkJCQi+7jZstLlC9G0tPT5ciRIxIUFCRubm7i6Gdb9GTCwYMHJTg42OriIB+oO+dF3Tkv6s65UX/Oi7pzXtSd86LunI/Gbg3o5cqVE3f3i486d7mWdD0gFSpUEGeiXzy+fM6JunNe1J3zou6cG/XnvKg750XdOS/qzrlcqgXdjonjAAAAAABwEIR0AAAAAAAcBCHdgfn4+MjLL79sfsK5UHfOi7pzXtSdc6P+nBd157yoO+dF3RVvLjdxHAAAAAAAjoqWdAAAAAAAHAQhHQAAAAAAB0FIBwAAAADAQRDSAQAAAABwEIR0C40ZM0aqVKkivr6+0rp1a1mxYsVF9582bZrUqVPH7N+wYUOZMWNGkZUV/xk5cqS0bNlSgoKCJDw8XHr37i3bt2+/6GMmTZokbm5u2TatRxStV1555YJ60O/UxfC9cwz6u/L8utPtkUceyXF/vnPWWrBggdx4441Srlw5c+x/+eWXbPfrnLUjRoyQsmXLip+fn3Tu3Fl27txZ4H83UbB1l5KSIs8995z5XRgQEGD2GTBggBw5cqTAf/ei4L9399577wX1cP3111/yefneWV93Of390+3dd9/N9Tn53jk3QrpFpkyZIsOGDTNLJ6xZs0YaN24s3bp1kxMnTuS4/5IlS6Rfv35y//33y9q1a00w1G3Tpk1FXnZXN3/+fBMMli1bJrNnzzb/aenatavExcVd9HHBwcFy9OjRzG3//v1FVmb8p379+tnqYdGiRbnuy/fOcaxcuTJbvel3T91+++25PobvnHX096H+XdP/3OfknXfekY8++kjGjRsny5cvN4FP/wYmJiYW2N9NFHzdxcfHm2P/0ksvmZ8///yzOUl90003FejvXhTO905pKM9aD99///1Fn5PvnWPUXdY6023ixIkmdN96660XfV6+d05Ml2BD0WvVqpXtkUceybyelpZmK1eunG3kyJE57t+nTx9bz549s93WunVr24MPPljoZcXFnThxQpcxtM2fPz/Xfb788ktbSEhIkZYLF3r55ZdtjRs3zvP+fO8c1xNPPGGrXr26LT09Pcf7+c45Dv39OH369MzrWmcRERG2d999N/O2s2fP2nx8fGzff/99gf3dRMHXXU5WrFhh9tu/f3+B/e5F4dTdPffcY+vVq1e+nofvnWN+77Qer7vuuovuw/fOudGSboHk5GRZvXq16d5n5+7ubq4vXbo0x8fo7Vn3V3omM7f9UXSioqLMz9DQ0IvuFxsbK5UrV5aKFStKr169ZPPmzUVUQmSlXWq1O1m1atXkzjvvlAMHDuS6L987x/0d+s0338jAgQNNS0Ju+M45pr1798qxY8eyfbdCQkJMN9rcvluX83cTRfc3UL+HJUqUKLDfvSg88+bNM0P1ateuLUOGDJFTp07lui/fO8d0/Phx+fPPP00vv0vhe+e8COkWiIyMlLS0NClTpky22/W6/sclJ3p7fvZH0UhPT5ehQ4fKVVddJQ0aNMh1P/1jqF2Tfv31VxMu9HHt2rWTQ4cOFWl5XZ2GAB2rPHPmTBk7dqwJC+3bt5eYmJgc9+d755h0rN7Zs2fN+Mrc8J1zXPbvT36+W5fzdxOFT4cn6Bh1HRakw0sK6ncvCod2dZ88ebLMmTNH3n77bTN8r3v37ua7lRO+d47pq6++MvMi3XLLLRfdj++dc/O0ugCAM9Ox6To++VJjfNq2bWs2Ow0LdevWlfHjx8vrr79eBCWF0v+M2DVq1Mj8AdOW1qlTp+bpjDQcwxdffGHqUlsHcsN3DihcOh9Lnz59zCSAGgAuht+9juGOO+7IvKyT/2ldVK9e3bSud+rUydKyIe/0BLS2il9qMlS+d86NlnQLhIWFiYeHh+mukpVej4iIyPExent+9kfhe/TRR+WPP/6QuXPnSoUKFfL1WC8vL2natKns2rWr0MqHS9PumbVq1cq1HvjeOR6d/O2ff/6RQYMG5etxfOcch/37k5/v1uX83UThB3T9PuokjhdrRb+c370oGtoFWr9budUD3zvHs3DhQjNZY37/Biq+d86FkG4Bb29vad68ueluZKddMfV61pafrPT2rPsr/cOY2/4oPNpqoAF9+vTp8u+//0rVqlXz/RzafWzjxo1m+SFYR8cs7969O9d64HvneL788ksznrJnz575ehzfOcehvzP1P/hZv1vR0dFmlvfcvluX83cThRvQdayrnjArVapUgf/uRdHQ4T86Jj23euB755g9ybROdCb4/OJ752SsnrnOVf3www9mJttJkybZtmzZYnvggQdsJUqUsB07dszcf/fdd9uGDx+euf/ixYttnp6etvfee8+2detWM2Ojl5eXbePGjRa+C9c0ZMgQM2v0vHnzbEePHs3c4uPjM/c5v/5effVV299//23bvXu3bfXq1bY77rjD5uvra9u8ebNF78I1PfXUU6be9u7da75TnTt3toWFhZkZ+hXfO8emswpXqlTJ9txzz11wH985xxITE2Nbu3at2fS/GqNHjzaX7TOAv/XWW+Zv3q+//mrbsGGDmam4atWqtoSEhMzn0JmLP/744zz/3UTh111ycrLtpptuslWoUMG2bt26bH8Dk5KScq27S/3uReHXnd739NNP25YuXWrq4Z9//rE1a9bMVrNmTVtiYmLmc/C9c8zfmSoqKsrm7+9vGzt2bI7PwfeueCGkW0i/SPofTm9vb7PExbJlyzLv69ixo1kqI6upU6faatWqZfavX7++7c8//7Sg1NBfnjltuuRTbvU3dOjQzLouU6aMrUePHrY1a9ZY9A5cV9++fW1ly5Y19VC+fHlzfdeuXZn3871zbBq69bu2ffv2C+7jO+dY5s6dm+PvSXsd6TJsL730kqkbDQCdOnW6oF4rV65sTozl9e8mCr/u9D/7uf0N1MflVneX+t2Lwq87bUjo2rWrrXTp0uZks9bR4MGDLwjbfO8c83emGj9+vM3Pz88sWZkTvnfFi5v+Y3VrPgAAAAAAYEw6AAAAAAAOg5AOAAAAAICDIKQDAAAAAOAgCOkAAAAAADgIQjoAAAAAAA6CkA4AAAAAgIMgpAMAAAAA4CAI6QAAAAAAOAhCOgDAZbm5uckvv/wiruTUqVMSHh4u+/bts7ooDuWaa66RoUOHFvnraj3o53DdunWF9hp33HGHjBo1qtCeHwBQsAjpAIAid++990rv3r2tLoYcPXpUunfv7lInCt58803p1auXVKlSRZzRpEmTzDHLuvn6+mbbx2azyYgRI6Rs2bLi5+cnnTt3lp07dxZ62ebNm2fKc/bsWXEkL774oqn3qKgoq4sCAMgDQjoAwGVFRESIj4+PuIr4+Hj54osv5P7777e6KJKSknLZjw0ODjYnWOzb/v37s93/zjvvyEcffSTjxo2T5cuXS0BAgHTr1k0SExPFFTVo0ECqV68u33zzjdVFAQDkASEdAOBw5s+fL61atTIBWltDhw8fLqmpqZn3x8TEyJ133mnCl97//vvvX9BdWcNbz549TUtq1apV5bvvvjOtxx988EGOrdj2bsc///yzXHvtteLv7y+NGzeWpUuXZivbhAkTpGLFiub+m2++WUaPHi0lSpTI9b0kJyfLo48+asqpLb6VK1eWkSNHmvvsrdn6PPraWVu3f/31V2nWrJl5TLVq1eTVV1/Ndgx0/7Fjx5qeAPoedZ8ff/zxosd1xowZ5pi2adMm2+2bNm0yzxMYGChlypSRu+++WyIjI819n332mZQrV07S09OzPUZb4wcOHJjv8t50002m3t544w2pUaOGvPfee9meV7t96767du3K9X3o/XqCxb5pmbO2omsda+uxlrFRo0YyefJkOXLkyCV7LGh5ta5CQkIkLCxMXnrpJfN8dl9//bW0aNFCgoKCzOv2799fTpw4kfn50c+NKlmypCmj9hhReuz0xIG+Xz3+lSpVMi3bWe3Zs+ein7tFixZJ+/btTV3r5+/xxx+XuLi4zPs//fRTqVmzpjn+ejxuu+22bI+/8cYb5Ycffrjo+wcAOAgbAABF7J577rH16tUrx/sOHTpk8/f3tz388MO2rVu32qZPn24LCwuzvfzyy5n7DBo0yFa5cmXbP//8Y9u4caPt5ptvtgUFBdmeeOKJzH06d+5sa9KkiW3ZsmW21atX2zp27Gjz8/Ozvf/++5n76J9BfX61d+9ec71OnTq2P/74w7Z9+3bbbbfdZl4nJSXF7LNo0SKbu7u77d133zX3jxkzxhYaGmoLCQnJ9b3qvhUrVrQtWLDAtm/fPtvChQtt3333nbnvxIkT5jW//PJL29GjR811pfsGBwfbJk2aZNu9e7dt1qxZtipVqtheeeWVbGUvVaqUbcKECaYsL774os3Dw8O2ZcuWXMvy+OOP266//vpst505c8ZWunRp2/PPP2+O95o1a2xdunSxXXvtteb+06dP27y9vc2xtjt16lS22/Ja3vDwcNvEiRPNPvv377e9+eabtnr16l1Qxg4dOuT6HvRY6fusVKmSrUKFCrabbrrJtmnTpsz79bn1tdauXZvtcfqc+ty50c9HYGCg+Qxt27bN9s0335jP4WeffZa5zxdffGGbMWOGeY2lS5fa2rZta+vevbu5LzU11fbTTz+Z19b60Po8e/asue/ZZ5+1lSxZ0hyfXbt2mc+A1lteP3f6mICAAPPZ3bFjh23x4sW2pk2b2u69915z/8qVK80x0c+Vfsa0Dj/88MNs7++vv/4ydZaYmJjrMQAAOAZCOgDAoUL6Cy+8YKtdu7YtPT098zYNwxqg0tLSbNHR0TYvLy/btGnTMu/XMKSByh7SNWxq8NHwYrdz505z26VC+ueff555/+bNm81t+nyqb9++tp49e2Yr75133nnRkP7YY4/ZrrvuumzvJ6usZbDr1KmT7X//+1+2277++mtb2bJlsz3uoYceyrZP69atbUOGDMm1LHrMBw4cmO22119/3da1a9dstx08eDAzbOb0uPHjx9vKlStn6iM/5R06dGi2fQ4fPmzC5fLly8315ORkc0JGw2xulixZYvvqq69MCJ83b57thhtuMCcItMxKA6y+1pEjR7I97vbbb7f16dPnoiG9bt262erpueeeM7flRj9f+loxMTHm+ty5c811PfFhp59XHx+fzFB+vrx87u6//37bAw88kO1xGvT1hFFCQoI5OaDHQF8rN+vXrzfPqSEeAODY6O4OAHAoW7dulbZt25ruwnZXXXWVxMbGyqFDh0y3YB3PrN3h7bR7cu3atTOvb9++XTw9PU33azvtaqzdkC9Fu0fbaRd1Ze/SrM+b9XXV+dfPp12etQu3lk+7KM+aNeuSZVi/fr289tprpvu5fRs8eLDpwq/jyu30OGWl1/X45SYhIeGCSdb0tebOnZvtterUqWPu2717t/mpQwt++uknSUpKMte//fZbM2O4u7t7vsqrXcWz0m70OiRh4sSJ5vrvv/9uXuP222/P9T3oexwwYIA0adJEOnbsaIYnlC5dWsaPHy9XSocBZP3c6WvphHNpaWnm+urVq023ce2url3e9fXVgQMHcn1OrQ99T506dbrsz50eX50wL+vx1TH22o1+79690qVLFzOMQocZ6FAFrZ+sx11pN3l1/u0AAMfjaXUBAABwJF5eXpmX7YHt/PHY+aEnCjRI/fXXX/LPP/9Inz59zGzjFxs/rickdEz3LbfccsF954fs/NBx1mfOnLngtTR4vv322xfsbw+Ler82hv/555/SsmVLWbhwoZkHIL/l1bHo5xs0aJAJlvp8X375pfTt29eMy85PfTVt2jRzDLuOFVfHjx/PLL/9ugb7y6XjvzUY66YhWE8MaDjX6zrvQG7s4Tgv7yO3z50e3wcffNCc5DmfnjDw9vaWNWvWmNnl9SSQzmz/yiuvyMqVKzPnSzh9+rT5qeUGADg2QjoAwKHUrVvXtNpqKLSHlcWLF5uWywoVKpjWcA00GkA0oChdWmrHjh3SoUMHc11brXUSsLVr10rz5s3NbRrizg+o+aXPq6+b1fnXc5uNXMOnbjqh1/XXX29CU2hoqHkv9pbarMFeW+219f9ili1bZlqVs17XwJobve/8Gb71tfR466R12vsgJxq0NYBrONXjqMchay+FvJY3Jz169DDhXSeVmzlzpixYsCBfj9djt3HjRvM8SicJ1KA+Z86czFAeHR1tZnkfMmTIRZ9L98lKj6dOxubh4SHbtm0za8y/9dZbZuI2tWrVqmz7a1i2l8lOH69BXcujJyQuhx7fLVu2XPT4at3pyR/dXn75ZRPO//3338wTJzo5oH5/9EQNAMCxEdIBAJbQYK3dwLMqVaqUPPzww2Z27scee8zMtK3hT0PHsGHDTPdqDev33HOPPPPMMybkhoeHm/v1Pnuo1+7aGlYeeOABE/40CD/11FMmLGXtzpxfWiY9EaAzumvrsoYgbSG/2HPqvtqiqwFZyzht2jQTIu0tnBqONcBpl36d+VtPQmhL6A033GBOQmio18dpl2cNWjorup0+l3Yhv/rqq02AXrFihVliLTfa6vv888+bkxX2rv+PPPKImbG+X79+8uyzz5pjqkFcZwL//PPPTUC1d3nXMm3evFnuuuuubM+b1/LmRJ9fhwRouTTQnt+F/3zarV67pWtg1fXI3333XbMEmz0Aa13oLP/6uvp8Gtp1lnbtWt+7d++LPre2jOvnTFuttWX6448/llGjRmVrsdbbHnroIfPeXn/99WyP1y7n+vp//PGHOWmgnzftmv7cc8+ZY6uP13o+efKkOY55XQpPH6/vWb8P+j71pIaG9tmzZ8snn3xiXk+HgehnU+tVZ/HXVvisQ0C090PXrl3z9HoAAItZPSgeAOCaE8fpn6DzN50gS+mEYC1btjSzUUdERJgJvOwzXSudIKt///5msji9f/To0bZWrVrZhg8fnrmPThymM2/rpF06U7bOfK2zi48bN+6iE8dlnRVcJwDT23RCMDud7bt8+fJmpvjevXvb3njjDVOG3Oj+Osu8zs6tk3vpJGs6+7bdb7/9ZqtRo4bN09PTlNNu5syZtnbt2pnX0cfp+8s607iWSyfU05nY9T3qbOpTpky55LHX58l6DJTOGK4z5JcoUcK8ns40rpO8ZZ1ETSeJ04ng9HV1dvPz5aW850+Qd/6M7O+8884ly6/l0pnd9bNRpkwZW48ePbIdT6Xlfumll8z9emz0mNsnwbvYxHG6ooBOxqfl19nYdRLDrMdAP0N6nPU5dWZ3rbvzPzOvvfaa+Ty4ubmZz7n92OnnROtXJz3U8tsn2svr527FihWmrnUCRf0sNWrUyMyOb59ETsuvZdbjr/dl/Szo5HI6uaHOSA8AcHxu+o/VJwoAALgSOl64fPnyptUzt9ZJnXROuynruPBLTeKVHzpBmnaF1pbKoqQtttOnT79k6/D5dFy59kLQlmD7xG9W02OndXLw4MFsa56jYGhvEv2s5GXSQgCA9ejuDgBwOjrWXIOxzqyu3ea1C7Tq1atX5j7aFV0n3GrYsKGZZVy7G2vXcvu49cv13nvvmdm0tcuxdnX/6quv5NNPPxVnobOp64zlhw8fzhxbbRWd9Vy7fuskZzqjOwG9cOhwD+2mDwBwDoR0AIBT0rCs49V1nK9ODqetsVknxdJl2l544QUzVlfHsbdr186M2846i/bl0HHf77zzjsTExJglrz766KPLnhDMKjpm2xF8//33pueDTvA2efJkq4tTbDnb5xMAXB3d3QEAAAAAcBCOMRgNAAAAAAAQ0gEAAAAAcBSEdAAAAAAAHAQhHQAAAAAAB0FIBwAAAADAQRDSAQAAAABwEIR0AAAAAAAcBCEdAAAAAABxDP8PugRrppakfT8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_model, user_labels, product_labels = train_matrix_factorization(\n",
    "    train_df,\n",
    "    latent_dim=1024,\n",
    "    epochs=2,\n",
    "    lr=0.001,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = project_dir / 'models'\n",
    "processed_data_path = project_dir / 'data' / 'processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0a09b-d0f6-44c1-817f-69bbcc71a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сохраняем обученную MF-модель\n",
    "# torch.save(mf_model.state_dict(), models_path / 'mf_model.pth')\n",
    "\n",
    "# # Сохраняем user_labels и product_labels\n",
    "# with open(processed_data_path / 'mf' / 'user_labels.pkl', 'wb') as f:\n",
    "#     pickle.dump(user_labels, f)\n",
    "\n",
    "# with open(processed_data_path / 'mf' / 'product_labels.pkl', 'wb') as f:\n",
    "#     pickle.dump(product_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c84e0c5-4feb-4629-9828-eb0722ec9209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFactorization(\n",
       "  (user_factors): Embedding(242532, 1024)\n",
       "  (item_factors): Embedding(269649, 1024)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем user_labels и product_labels\n",
    "with open(processed_data_path / 'mf' / 'user_labels.pkl', \"rb\") as f:\n",
    "    user_labels = pickle.load(f)\n",
    "\n",
    "with open(processed_data_path / 'mf' / 'product_labels.pkl', \"rb\") as f:\n",
    "    product_labels = pickle.load(f)\n",
    "\n",
    "# Воссоздаём архитектуру модели\n",
    "num_users = len(user_labels)\n",
    "num_items = len(product_labels)\n",
    "latent_dim = 1024  # Указываем тот же размер, что был при обучении\n",
    "\n",
    "mf_model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "# Загружаем веса модели\n",
    "mf_model.load_state_dict(torch.load(models_path / 'mf_model.pth'))\n",
    "\n",
    "# Переводим модель в режим предсказания (инференса)\n",
    "mf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "31659d1e-482a-4599-bfdb-970f4361de45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем список тестовых пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "len(user_ids[:len(user_ids) // 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c44d349a-ecb1-4827-b7dd-5545f7ee8e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e427364359f448fbb77556da814b50c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating MF recommendations:   0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Получаем список тестовых пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "# Делаем рекомендации\n",
    "user_recommendations_mf = recommend_mf_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 50],\n",
    "    model=mf_model,\n",
    "    user_labels=user_labels,\n",
    "    product_labels=product_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    batch_size=8,\n",
    "    filter_already_purchased=filter_already_purchased\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1022f56b-2eaa-4714-aff5-82579d3b718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mf = RecommendationDataset(user_recommendations=user_recommendations_mf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_mf, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ddac92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recs': tensor([13404705, 13404721, 12749132, 12883630,  2370888,  6869148]),\n",
       " 'true': tensor([13588693, 13581910])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_mf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9d278a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1cc94cdf-56f6-4ad1-8dfb-5e46cc0940ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf22aca91c5046b79c5d68bc29707291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f0108534664cf188ffb1a9f1735d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.000225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574796db70dc447d93eb940edc883401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10da9538e66c41fca3403ed5729b49d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k: 0.00011\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30839158-0bd9-4da4-9c35-97c3debca75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matrix Factorization</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>{'top_k_items': 6, 'latent_dim': 256, 'filter_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  k  Precision@k  Recall@k  MAP@k  NDCG@k  \\\n",
       "0  Matrix Factorization  6       0.0011     0.001  0.001  0.0011   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0  {'top_k_items': 6, 'latent_dim': 256, 'filter_...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Matrix Factorization', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, \n",
    "                  hyperparameters={'top_k_items': k, 'latent_dim': latent_dim, \n",
    "                                   'filter_already_purchased': filter_already_purchased})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8357f2-0f38-4aed-a674-1e92f389c39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "28997    False\n",
       "28998    False\n",
       "28999    False\n",
       "29000    False\n",
       "29001    False\n",
       "Name: anon_id_encrypred, Length: 29002, dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ambassadors[df_ambassadors['anon_id_encrypred'].isin(user_ids[:len(user_ids) // 1000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8be9f5-22af-4b1b-8f9a-0c22d0a2f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_to_true_items = train_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72d8a32d-c1bf-4d8b-9387-854b5353d052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>train_titles</th>\n",
       "      <th>train_brands</th>\n",
       "      <th>train_products</th>\n",
       "      <th>train_prices</th>\n",
       "      <th>train_links</th>\n",
       "      <th>test_titles</th>\n",
       "      <th>test_brands</th>\n",
       "      <th>test_products</th>\n",
       "      <th>test_prices</th>\n",
       "      <th>test_links</th>\n",
       "      <th>random_titles</th>\n",
       "      <th>random_brands</th>\n",
       "      <th>random_products</th>\n",
       "      <th>random_prices</th>\n",
       "      <th>random_links</th>\n",
       "      <th>top_k_titles</th>\n",
       "      <th>top_k_brands</th>\n",
       "      <th>top_k_products</th>\n",
       "      <th>top_k_prices</th>\n",
       "      <th>top_k_links</th>\n",
       "      <th>ubcf_titles</th>\n",
       "      <th>ubcf_brands</th>\n",
       "      <th>ubcf_products</th>\n",
       "      <th>ubcf_prices</th>\n",
       "      <th>ubcf_links</th>\n",
       "      <th>ibcf_titles</th>\n",
       "      <th>ibcf_brands</th>\n",
       "      <th>ibcf_products</th>\n",
       "      <th>ibcf_prices</th>\n",
       "      <th>ibcf_links</th>\n",
       "      <th>mf_titles</th>\n",
       "      <th>mf_brands</th>\n",
       "      <th>mf_products</th>\n",
       "      <th>mf_prices</th>\n",
       "      <th>mf_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wyyypqqtpqppptqt</td>\n",
       "      <td>[Хлопковое платье, Хлопковая рубашка, Хлопкова...</td>\n",
       "      <td>[HUGO, Paul &amp; Shark, BOSS, BOSS, BOSS, Dolce&amp;G...</td>\n",
       "      <td>[13601472, 13463459, 13439364, 13502218, 13642...</td>\n",
       "      <td>[16000.0, 16050.0, 5880.0, 3840.0, 1300.0, 211...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/11f4789a902750d1f...</td>\n",
       "      <td>[Шерстяной шарф, Хлопковая бейсболка, Галстук]</td>\n",
       "      <td>[BOSS, BOSS, BOSS]</td>\n",
       "      <td>[13610113, 13593083, 13491591]</td>\n",
       "      <td>[10500.0, 4700.0, 7995.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/2aa0a05e8e7...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Комплект из двух пар носков, Хлопковая бейсбо...</td>\n",
       "      <td>[BOSS, Versace Jeans Couture, BOSS, BOSS, Duno...</td>\n",
       "      <td>[13456544, 13505484, 13576366, 13439367, 13415...</td>\n",
       "      <td>[2850.0, 7640.0, 5300.0, 5880.0, 82800.0, 7760.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/7ef4612372897d7cc...</td>\n",
       "      <td>[Юбка, Сумка Love One Classic, Хлопковый пулов...</td>\n",
       "      <td>[Blumarine, Pinko, Iro, Tom Ford, Giorgio Arma...</td>\n",
       "      <td>[13592319, 13608237, 13630851, 10657051, 13587...</td>\n",
       "      <td>[33950.0, 49700.0, 45650.0, 163500.0, 49500.0,...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c5d279d80679441b5...</td>\n",
       "      <td>[Кожаные слипоны, Слитный купальник, Комбиниро...</td>\n",
       "      <td>[H`D`S`N Baracco, Scotch&amp;Soda, Flower Mountain...</td>\n",
       "      <td>[12435815, 13332086, 13468168, 7594187, 134790...</td>\n",
       "      <td>[29950.0, 7550.0, 29600.0, 9360.0, 14600.0, 53...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/f467e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wyyypqqtpqpppxwy</td>\n",
       "      <td>[Куртка, Шерстяная кепка, Набор из 2-х стакано...</td>\n",
       "      <td>[Deha, Gucci, Baccarat, Dolce&amp;Gabbana]</td>\n",
       "      <td>[13461536, 11247889, 13387866, 13430604]</td>\n",
       "      <td>[24100.0, 21650.0, 27500.0, 49950.0]</td>\n",
       "      <td>[None, None, None, None]</td>\n",
       "      <td>[Кардиган, Кольцо]</td>\n",
       "      <td>[Antonelli Firenze, Luv Aj]</td>\n",
       "      <td>[13324234, 13648375]</td>\n",
       "      <td>[52500.0, 8650.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/ae306cf3ac7...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Панама, Клипсы, Бра-топ, Пуховик, Утепленный ...</td>\n",
       "      <td>[Gucci, Dolce&amp;Gabbana, Dolce&amp;Gabbana, Bacon, s...</td>\n",
       "      <td>[8034648, 13022889, 13416444, 13440544, 131624...</td>\n",
       "      <td>[22950.0, 42450.0, 21500.0, 125000.0, 82550.0,...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/1797545d653...</td>\n",
       "      <td>[Шерстяная шапка, Платье, Шелковая блузка, Бар...</td>\n",
       "      <td>[Marni, Designer`s Cat, Designer`s Cat, Saint ...</td>\n",
       "      <td>[13436507, 12954264, 12968407, 8646903, 236264...</td>\n",
       "      <td>[16650.0, 20700.0, 13650.0, 299500.0, 3150.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/67c651d5a424682d1...</td>\n",
       "      <td>[Пододеяльник Links Embroidery, Хлопковые джог...</td>\n",
       "      <td>[Frette, Michael Kors, Tom Ford, Dolce&amp;Gabbana...</td>\n",
       "      <td>[13382692, 12115746, 2541923, 13628355, 115680...</td>\n",
       "      <td>[96500.0, 18200.0, 207000.0, 123000.0, 133500....</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wyyypqqtpqppqsyr</td>\n",
       "      <td>[Льняная футболка, Кожаный ремень, Кожаные дер...</td>\n",
       "      <td>[120% Lino, Corneliani, Alexander McQueen, Dan...</td>\n",
       "      <td>[12691330, 13309189, 11824167, 13293831, 13290...</td>\n",
       "      <td>[11950.0, 21050.0, 49950.0, 13400.0, 13400.0, ...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Кожаные пенни-лоферы, Кожаные дерби]</td>\n",
       "      <td>[Barrett, Moma]</td>\n",
       "      <td>[13405136, 13570133]</td>\n",
       "      <td>[74900.0, 47300.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/dd8eade74bf...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные кеды Recut Low, Джинсы Skyline Straig...</td>\n",
       "      <td>[Crime London, Paige, Santoni, Off-White, Scot...</td>\n",
       "      <td>[13569583, 13209210, 13370219, 13368486, 13243...</td>\n",
       "      <td>[22850.0, 31950.0, 59950.0, 63350.0, 4320.0, 1...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Брюки из хлопка и шелка, Кардиган из шерсти и...</td>\n",
       "      <td>[Marco Pescarolo, Luigi Borrelli, Luigi Borrel...</td>\n",
       "      <td>[13483916, 13451309, 12289393, 12803856, 12990...</td>\n",
       "      <td>[59950.0, 73500.0, 19550.0, 8500.0, 12850.0, 5...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/2e0a01883b2707d99...</td>\n",
       "      <td>[Кожаный ремень, Шорты из шерсти и хлопка, Хло...</td>\n",
       "      <td>[Antonelli Firenze, Zegna, Ermanno Scervino, M...</td>\n",
       "      <td>[13439394, 12540785, 4809713, 13456129, 130988...</td>\n",
       "      <td>[33350.0, 66700.0, 6395.0, 105000.0, 45700.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/55c4d1cccb6cf9b74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wyyypqqtpqppquwt</td>\n",
       "      <td>[Комбинированные кроссовки Buff Ly, Кожаные ке...</td>\n",
       "      <td>[Premiata, Premiata, Premiata, PT TORINO]</td>\n",
       "      <td>[13380688, 13178073, 12691555, 12926932]</td>\n",
       "      <td>[27850.0, 24050.0, 24050.0, 16600.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/16709080b9f...</td>\n",
       "      <td>[Кожаные туфли]</td>\n",
       "      <td>[BOSS]</td>\n",
       "      <td>[13488613]</td>\n",
       "      <td>[35450.0]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные кеды Belle, Комбинированные кроссовки...</td>\n",
       "      <td>[Premiata, Premiata, Premiata, Premiata, Premi...</td>\n",
       "      <td>[13380686, 13270483, 11330112, 13308941, 11251...</td>\n",
       "      <td>[27850.0, 24050.0, 29050.0, 27850.0, 27100.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/76ba7...</td>\n",
       "      <td>[Льняные шорты, Кожаные мокасины, Пуховик, Пух...</td>\n",
       "      <td>[120% Lino, Atlanta Mocassin, Hetrego, Hetrego...</td>\n",
       "      <td>[12501643, 2580019, 13003172, 12978994, 125427...</td>\n",
       "      <td>[11950.0, 3760.0, 59950.0, 52650.0, 4365.0, 21...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Хлопковая толстовка, Текстильные слипоны, Хло...</td>\n",
       "      <td>[Versace, Stella McCartney, Stone Island, Desi...</td>\n",
       "      <td>[12394897, 6566286, 13559833, 13455678, 254081...</td>\n",
       "      <td>[8995.0, 3770.0, 19950.0, 53400.0, 2095.0, 333...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wyyypqqtpqppqvqt</td>\n",
       "      <td>[Хлопковая футболка, Хлопковый лонгслив, Комби...</td>\n",
       "      <td>[Comme Des Fuckdown, Bluemarble, Premiata, Han...</td>\n",
       "      <td>[13221303, 13384003, 12855112, 13503368, 13311...</td>\n",
       "      <td>[7995.0, 26350.0, 29950.0, 27150.0, 16250.0, 1...</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "      <td>[Кеды из нубука, Джинсы, Хлопковый лонгслив, Д...</td>\n",
       "      <td>[H`D`S`N Baracco, Juun.J, Dries Van Noten, Juu...</td>\n",
       "      <td>[13476415, 13515397, 13422870, 13514165]</td>\n",
       "      <td>[42100.0, 57600.0, 36550.0, 59950.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/f8f27b8bee27c641a...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Джинсы, Рубашка, Хлопковая футболка, Хлопкова...</td>\n",
       "      <td>[Diesel, Ksubi, Carne Bollente, Comme Des Fuck...</td>\n",
       "      <td>[12849051, 13406123, 13262093, 13419595, 13287...</td>\n",
       "      <td>[17750.0, 25550.0, 7650.0, 12500.0, 7995.0, 13...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Шерстяной кардиган, Оправа, Хлопковая футболк...</td>\n",
       "      <td>[Dries Van Noten, Saint Laurent Paris, Paul &amp; ...</td>\n",
       "      <td>[13586226, 13253755, 13559727, 13119885, 12730...</td>\n",
       "      <td>[104000.0, 37950.0, 17750.0, 39080.0, 33050.0,...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/76b7a674b30b6748b...</td>\n",
       "      <td>[Хлопковые джоггеры, Льняной топ, Хлопковая фу...</td>\n",
       "      <td>[Armani, 120% Lino, Brunello Cucinelli, Eleven...</td>\n",
       "      <td>[13605665, 13319460, 13468231, 13267061, 13285...</td>\n",
       "      <td>[15100.0, 19900.0, 45250.0, 25350.0, 9735.0, 3...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/b49ab4275ed5d95c7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wyyypqqtpqppqxwq</td>\n",
       "      <td>[Замшевые ботинки, Джоггеры, Кожаные перчатки ...</td>\n",
       "      <td>[Santoni, Ralph Lauren Polo, Roeckl, Add, Hetr...</td>\n",
       "      <td>[13018881, 12607970, 12896261, 13174856, 13422...</td>\n",
       "      <td>[43400.0, 14950.0, 13550.0, 31650.0, 91950.0, ...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Сумка Camino small, Шелковый платок]</td>\n",
       "      <td>[Sans-Arcidet Collection, Lancel]</td>\n",
       "      <td>[13213668, 13511629]</td>\n",
       "      <td>[24700.0, 28150.0]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные шлепанцы, Текстильная косметичка, Зам...</td>\n",
       "      <td>[Melissa Odabash, MC2 Saint Barth, Santoni, Co...</td>\n",
       "      <td>[10960130, 13395719, 13014815, 13084364, 13365...</td>\n",
       "      <td>[10600.0, 3720.0, 39750.0, 10800.0, 47400.0, 2...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Солнцезащитные очки, Ваза Monofiori Frozen, П...</td>\n",
       "      <td>[Ray-Ban, Venini, Moorer, Brioni, Amina Muaddi...</td>\n",
       "      <td>[12027171, 13364136, 13379401, 10796503, 13538...</td>\n",
       "      <td>[24950.0, 35700.0, 239000.0, 12400.0, 137500.0...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/b0530748f28ac8fc9...</td>\n",
       "      <td>[Тарелка салатная Versailles Vert, Шелковые бр...</td>\n",
       "      <td>[Bernardaud, Tibi, MVST, Givenchy, Jil Sander,...</td>\n",
       "      <td>[13052719, 11399486, 13463033, 13558710, 12366...</td>\n",
       "      <td>[21250.0, 8370.0, 81850.0, 293000.0, 33650.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/04105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wyyypqqtpqpprtpx</td>\n",
       "      <td>[Хлопковая рубашка, Шерстяные брюки, Замшевые ...</td>\n",
       "      <td>[Giampaolo, Berwich, H`D`S`N Baracco, Giampaol...</td>\n",
       "      <td>[12841504, 13003200, 12138434, 12928642, 12060...</td>\n",
       "      <td>[15700.0, 26000.0, 45650.0, 14800.0, 32550.0, ...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Хлопковый свитшот, Кожаные дерби, Хлопковые ф...</td>\n",
       "      <td>[Off-White, Tod`s, MC2 Saint Barth]</td>\n",
       "      <td>[13520646, 11310166, 13444631]</td>\n",
       "      <td>[68250.0, 57750.0, 9815.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/ee92330fc9ced3b86...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные кеды Out of Office, Сумка Love Puff C...</td>\n",
       "      <td>[Off-White, Pinko, Moschino, Dsquared, Dolce&amp;G...</td>\n",
       "      <td>[13375377, 13413528, 13193191, 12539729, 12491...</td>\n",
       "      <td>[59950.0, 64550.0, 82100.0, 24750.0, 78850.0, ...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Хлопковая сорочка, Хлопковая рубашка, Хлопков...</td>\n",
       "      <td>[Corneliani, Van Laack, Jil Sander, Sonrisa, D...</td>\n",
       "      <td>[11903573, 12501398, 12651657, 12230335, 11339...</td>\n",
       "      <td>[12550.0, 13350.0, 20700.0, 13400.0, 18400.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Серьги, Боксеры, Хлопковая футболка, Сандалии...</td>\n",
       "      <td>[Versace, Zimmerli, Vetements, Giorgio Armani,...</td>\n",
       "      <td>[13378440, 13566382, 13094525, 12602503, 13385...</td>\n",
       "      <td>[19950.0, 9585.0, 49950.0, 7315.0, 55300.0, 72...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/e9f51e335f5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wyyypqqtpqppttpu</td>\n",
       "      <td>[Резиновые сабо Rubber Flash, Хлопковый лонгсл...</td>\n",
       "      <td>[Bottega Veneta, Jil Sander, Coccinelle, Cocci...</td>\n",
       "      <td>[12310342, 13481712, 13486229, 13480856, 98525...</td>\n",
       "      <td>[35200.0, 51300.0, 15500.0, 9500.0, 64150.0, 8...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Кольцо, Серьги]</td>\n",
       "      <td>[Dsquared, Jil Sander]</td>\n",
       "      <td>[13535888, 13647445]</td>\n",
       "      <td>[18750.0, 69950.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/8651a11b50850b90c...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Дорожный кофр с вешалкой, Кожаные кеды, Кашем...</td>\n",
       "      <td>[Bric`s, Hidnander, Inverni, Flower Mountain, ...</td>\n",
       "      <td>[13381312, 13366043, 12218239, 13054418, 13090...</td>\n",
       "      <td>[34300.0, 33250.0, 12700.0, 23250.0, 14300.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/b3906...</td>\n",
       "      <td>[Солнцезащитные очки, Хлопковый топ свободного...</td>\n",
       "      <td>[Chloe, Chloe, Bottega Veneta, Melissa Odabash...</td>\n",
       "      <td>[12772682, 2258839, 12007845, 2113603, 1358889...</td>\n",
       "      <td>[31950.0, 26100.0, 32750.0, 6200.0, 29400.0, 7...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Платье из хлопка и вискозы, Ободок, Джоггеры,...</td>\n",
       "      <td>[Bottega Veneta, Jennifer Ouellette, Barrow, B...</td>\n",
       "      <td>[12572864, 1595270, 12997565, 13581585, 132676...</td>\n",
       "      <td>[89400.0, 7760.0, 20800.0, 98750.0, 7725.0, 43...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c5cd78cea764d17e0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wyyypqqtpqppuput</td>\n",
       "      <td>[Текстильные кроссовки Buff, Комбинированные к...</td>\n",
       "      <td>[Premiata, Premiata, Moschino, Premiata]</td>\n",
       "      <td>[12725712, 10707668, 13144684, 2686391]</td>\n",
       "      <td>[24050.0, 24050.0, 6575.0, 24050.0]</td>\n",
       "      <td>[None, None, None, None]</td>\n",
       "      <td>[Комбинированные кроссовки Mick]</td>\n",
       "      <td>[Premiata]</td>\n",
       "      <td>[13405999]</td>\n",
       "      <td>[35850.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/3d4e9d762bac11ee3...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Комбинированные кроссовки Lander, Комбинирова...</td>\n",
       "      <td>[Premiata, Premiata, Premiata, Premiata, Premi...</td>\n",
       "      <td>[10767247, 13323894, 10958183, 13381353, 13268...</td>\n",
       "      <td>[29050.0, 25450.0, 29750.0, 29750.0, 24050.0, ...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/0e7fa951bee...</td>\n",
       "      <td>[Набор из четырех серег, Хлопковые боксеры, На...</td>\n",
       "      <td>[Jil Sander, Tom Ford, Marni, Chloe, Comme Des...</td>\n",
       "      <td>[11768772, 10604959, 10538414, 12653117, 13595...</td>\n",
       "      <td>[49900.0, 14650.0, 23150.0, 43950.0, 5710.0, 2...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Кожаный зажим для купюр, Комбинированные кеды...</td>\n",
       "      <td>[Bottega Veneta, Premiata, Ree Projects, Sarto...</td>\n",
       "      <td>[13608120, 13513908, 13428439, 13510137, 13404...</td>\n",
       "      <td>[89950.0, 31950.0, 64800.0, 74800.0, 12600.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/16c86edc9b6993c0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wyyypqqtpqppupvy</td>\n",
       "      <td>[Шерстяные брюки, Хлопковый пиджак, Хлопковая ...</td>\n",
       "      <td>[Isabel Benenato, Attachment, Comme Des Fuckdo...</td>\n",
       "      <td>[13511044, 13537136, 13419570, 13419541, 13368...</td>\n",
       "      <td>[85950.0, 44250.0, 12500.0, 12500.0, 21600.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/76fa2d2b8d54ddbac...</td>\n",
       "      <td>[Солнцезащитные очки, Комплект из двух пар нос...</td>\n",
       "      <td>[Gucci, BOSS, Dolce&amp;Gabbana]</td>\n",
       "      <td>[12101160, 13456004, 12783662]</td>\n",
       "      <td>[32600.0, 1995.0, 10400.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/80f32a57a685ae69c...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Хлопковая майка, Кожаные кеды Open Skate, Ком...</td>\n",
       "      <td>[Diesel, Valentino, Dolce&amp;Gabbana, Limitato, V...</td>\n",
       "      <td>[13402680, 13318408, 12568722, 13229899, 13373...</td>\n",
       "      <td>[5790.0, 98450.0, 59050.0, 13200.0, 7155.0, 69...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Оправа, Хлопковый пиджак, Плавки-шорты, Хлопк...</td>\n",
       "      <td>[Tom Ford, Harris Wharf London, Vilebrequin, B...</td>\n",
       "      <td>[12010666, 13624979, 13647340, 13494279, 13624...</td>\n",
       "      <td>[34700.0, 77800.0, 33250.0, 38050.0, 51650.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/25f6c563bebf96946...</td>\n",
       "      <td>[Хлопковая рубашка, Кожаные шлепанцы, Джинсы, ...</td>\n",
       "      <td>[Tom Ford, Premiata, Giorgio Armani, Roberto C...</td>\n",
       "      <td>[12135329, 13503791, 13532729, 13591731, 13411...</td>\n",
       "      <td>[69950.0, 48000.0, 19750.0, 49950.0, 79950.0, ...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/22d62a0214e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anon_id_encrypred                                       train_titles  \\\n",
       "0  wyyypqqtpqppptqt  [Хлопковое платье, Хлопковая рубашка, Хлопкова...   \n",
       "1  wyyypqqtpqpppxwy  [Куртка, Шерстяная кепка, Набор из 2-х стакано...   \n",
       "2  wyyypqqtpqppqsyr  [Льняная футболка, Кожаный ремень, Кожаные дер...   \n",
       "3  wyyypqqtpqppquwt  [Комбинированные кроссовки Buff Ly, Кожаные ке...   \n",
       "4  wyyypqqtpqppqvqt  [Хлопковая футболка, Хлопковый лонгслив, Комби...   \n",
       "5  wyyypqqtpqppqxwq  [Замшевые ботинки, Джоггеры, Кожаные перчатки ...   \n",
       "6  wyyypqqtpqpprtpx  [Хлопковая рубашка, Шерстяные брюки, Замшевые ...   \n",
       "7  wyyypqqtpqppttpu  [Резиновые сабо Rubber Flash, Хлопковый лонгсл...   \n",
       "8  wyyypqqtpqppuput  [Текстильные кроссовки Buff, Комбинированные к...   \n",
       "9  wyyypqqtpqppupvy  [Шерстяные брюки, Хлопковый пиджак, Хлопковая ...   \n",
       "\n",
       "                                        train_brands  \\\n",
       "0  [HUGO, Paul & Shark, BOSS, BOSS, BOSS, Dolce&G...   \n",
       "1             [Deha, Gucci, Baccarat, Dolce&Gabbana]   \n",
       "2  [120% Lino, Corneliani, Alexander McQueen, Dan...   \n",
       "3          [Premiata, Premiata, Premiata, PT TORINO]   \n",
       "4  [Comme Des Fuckdown, Bluemarble, Premiata, Han...   \n",
       "5  [Santoni, Ralph Lauren Polo, Roeckl, Add, Hetr...   \n",
       "6  [Giampaolo, Berwich, H`D`S`N Baracco, Giampaol...   \n",
       "7  [Bottega Veneta, Jil Sander, Coccinelle, Cocci...   \n",
       "8           [Premiata, Premiata, Moschino, Premiata]   \n",
       "9  [Isabel Benenato, Attachment, Comme Des Fuckdo...   \n",
       "\n",
       "                                      train_products  \\\n",
       "0  [13601472, 13463459, 13439364, 13502218, 13642...   \n",
       "1           [13461536, 11247889, 13387866, 13430604]   \n",
       "2  [12691330, 13309189, 11824167, 13293831, 13290...   \n",
       "3           [13380688, 13178073, 12691555, 12926932]   \n",
       "4  [13221303, 13384003, 12855112, 13503368, 13311...   \n",
       "5  [13018881, 12607970, 12896261, 13174856, 13422...   \n",
       "6  [12841504, 13003200, 12138434, 12928642, 12060...   \n",
       "7  [12310342, 13481712, 13486229, 13480856, 98525...   \n",
       "8            [12725712, 10707668, 13144684, 2686391]   \n",
       "9  [13511044, 13537136, 13419570, 13419541, 13368...   \n",
       "\n",
       "                                        train_prices  \\\n",
       "0  [16000.0, 16050.0, 5880.0, 3840.0, 1300.0, 211...   \n",
       "1               [24100.0, 21650.0, 27500.0, 49950.0]   \n",
       "2  [11950.0, 21050.0, 49950.0, 13400.0, 13400.0, ...   \n",
       "3               [27850.0, 24050.0, 24050.0, 16600.0]   \n",
       "4  [7995.0, 26350.0, 29950.0, 27150.0, 16250.0, 1...   \n",
       "5  [43400.0, 14950.0, 13550.0, 31650.0, 91950.0, ...   \n",
       "6  [15700.0, 26000.0, 45650.0, 14800.0, 32550.0, ...   \n",
       "7  [35200.0, 51300.0, 15500.0, 9500.0, 64150.0, 8...   \n",
       "8                [24050.0, 24050.0, 6575.0, 24050.0]   \n",
       "9  [85950.0, 44250.0, 12500.0, 12500.0, 21600.0, ...   \n",
       "\n",
       "                                         train_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/11f4789a902750d1f...   \n",
       "1                           [None, None, None, None]   \n",
       "2  [None, None, None, None, None, https://st-cdn....   \n",
       "3  [None, https://st-cdn.tsum.com/sig/16709080b9f...   \n",
       "4  [None, None, None, https://st-cdn.tsum.com/sig...   \n",
       "5  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "6  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "7  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "8                           [None, None, None, None]   \n",
       "9  [https://st-cdn.tsum.com/sig/76fa2d2b8d54ddbac...   \n",
       "\n",
       "                                         test_titles  \\\n",
       "0     [Шерстяной шарф, Хлопковая бейсболка, Галстук]   \n",
       "1                                 [Кардиган, Кольцо]   \n",
       "2              [Кожаные пенни-лоферы, Кожаные дерби]   \n",
       "3                                    [Кожаные туфли]   \n",
       "4  [Кеды из нубука, Джинсы, Хлопковый лонгслив, Д...   \n",
       "5              [Сумка Camino small, Шелковый платок]   \n",
       "6  [Хлопковый свитшот, Кожаные дерби, Хлопковые ф...   \n",
       "7                                   [Кольцо, Серьги]   \n",
       "8                   [Комбинированные кроссовки Mick]   \n",
       "9  [Солнцезащитные очки, Комплект из двух пар нос...   \n",
       "\n",
       "                                         test_brands  \\\n",
       "0                                 [BOSS, BOSS, BOSS]   \n",
       "1                        [Antonelli Firenze, Luv Aj]   \n",
       "2                                    [Barrett, Moma]   \n",
       "3                                             [BOSS]   \n",
       "4  [H`D`S`N Baracco, Juun.J, Dries Van Noten, Juu...   \n",
       "5                  [Sans-Arcidet Collection, Lancel]   \n",
       "6                [Off-White, Tod`s, MC2 Saint Barth]   \n",
       "7                             [Dsquared, Jil Sander]   \n",
       "8                                         [Premiata]   \n",
       "9                       [Gucci, BOSS, Dolce&Gabbana]   \n",
       "\n",
       "                              test_products  \\\n",
       "0            [13610113, 13593083, 13491591]   \n",
       "1                      [13324234, 13648375]   \n",
       "2                      [13405136, 13570133]   \n",
       "3                                [13488613]   \n",
       "4  [13476415, 13515397, 13422870, 13514165]   \n",
       "5                      [13213668, 13511629]   \n",
       "6            [13520646, 11310166, 13444631]   \n",
       "7                      [13535888, 13647445]   \n",
       "8                                [13405999]   \n",
       "9            [12101160, 13456004, 12783662]   \n",
       "\n",
       "                            test_prices  \\\n",
       "0             [10500.0, 4700.0, 7995.0]   \n",
       "1                     [52500.0, 8650.0]   \n",
       "2                    [74900.0, 47300.0]   \n",
       "3                             [35450.0]   \n",
       "4  [42100.0, 57600.0, 36550.0, 59950.0]   \n",
       "5                    [24700.0, 28150.0]   \n",
       "6            [68250.0, 57750.0, 9815.0]   \n",
       "7                    [18750.0, 69950.0]   \n",
       "8                             [35850.0]   \n",
       "9            [32600.0, 1995.0, 10400.0]   \n",
       "\n",
       "                                          test_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/2aa0a05e8e7...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/ae306cf3ac7...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/dd8eade74bf...   \n",
       "3                                             [None]   \n",
       "4  [https://st-cdn.tsum.com/sig/f8f27b8bee27c641a...   \n",
       "5                                       [None, None]   \n",
       "6  [https://st-cdn.tsum.com/sig/ee92330fc9ced3b86...   \n",
       "7  [https://st-cdn.tsum.com/sig/8651a11b50850b90c...   \n",
       "8  [https://st-cdn.tsum.com/sig/3d4e9d762bac11ee3...   \n",
       "9  [https://st-cdn.tsum.com/sig/80f32a57a685ae69c...   \n",
       "\n",
       "                                       random_titles  \\\n",
       "0  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "1  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "2  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "3  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "4  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "5  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "6  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "7  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "8  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "9  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "\n",
       "                                       random_brands  \\\n",
       "0  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "1  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "2  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "3  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "4  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "5  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "6  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "7  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "8  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "9  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "\n",
       "                                     random_products  \\\n",
       "0  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "1  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "2  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "3  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "4  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "5  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "6  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "7  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "8  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "9  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "\n",
       "                                       random_prices  \\\n",
       "0  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "1  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "2  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "3  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "4  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "5  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "6  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "7  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "8  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "9  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "\n",
       "                           random_links  \\\n",
       "0  [None, None, None, None, None, None]   \n",
       "1  [None, None, None, None, None, None]   \n",
       "2  [None, None, None, None, None, None]   \n",
       "3  [None, None, None, None, None, None]   \n",
       "4  [None, None, None, None, None, None]   \n",
       "5  [None, None, None, None, None, None]   \n",
       "6  [None, None, None, None, None, None]   \n",
       "7  [None, None, None, None, None, None]   \n",
       "8  [None, None, None, None, None, None]   \n",
       "9  [None, None, None, None, None, None]   \n",
       "\n",
       "                                        top_k_titles  \\\n",
       "0  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "1  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "2  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "3  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "4  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "5  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "6  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "7  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "8  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "9  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "\n",
       "                                        top_k_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "1  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "2  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "3  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "4  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "5  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "6  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "7  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "8  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "9  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "\n",
       "                                      top_k_products  \\\n",
       "0  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "1  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "2  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "3  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "4  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "5  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "6  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "7  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "8  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "9  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "\n",
       "                                        top_k_prices  \\\n",
       "0  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "1  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "2  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "3  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "4  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "5  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "6  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "7  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "8  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "9  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "\n",
       "                                         top_k_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "1  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "2  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "3  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "4  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "5  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "6  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "7  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "8  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "9  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "\n",
       "                                         ubcf_titles  \\\n",
       "0  [Комплект из двух пар носков, Хлопковая бейсбо...   \n",
       "1  [Панама, Клипсы, Бра-топ, Пуховик, Утепленный ...   \n",
       "2  [Кожаные кеды Recut Low, Джинсы Skyline Straig...   \n",
       "3  [Кожаные кеды Belle, Комбинированные кроссовки...   \n",
       "4  [Джинсы, Рубашка, Хлопковая футболка, Хлопкова...   \n",
       "5  [Кожаные шлепанцы, Текстильная косметичка, Зам...   \n",
       "6  [Кожаные кеды Out of Office, Сумка Love Puff C...   \n",
       "7  [Дорожный кофр с вешалкой, Кожаные кеды, Кашем...   \n",
       "8  [Комбинированные кроссовки Lander, Комбинирова...   \n",
       "9  [Хлопковая майка, Кожаные кеды Open Skate, Ком...   \n",
       "\n",
       "                                         ubcf_brands  \\\n",
       "0  [BOSS, Versace Jeans Couture, BOSS, BOSS, Duno...   \n",
       "1  [Gucci, Dolce&Gabbana, Dolce&Gabbana, Bacon, s...   \n",
       "2  [Crime London, Paige, Santoni, Off-White, Scot...   \n",
       "3  [Premiata, Premiata, Premiata, Premiata, Premi...   \n",
       "4  [Diesel, Ksubi, Carne Bollente, Comme Des Fuck...   \n",
       "5  [Melissa Odabash, MC2 Saint Barth, Santoni, Co...   \n",
       "6  [Off-White, Pinko, Moschino, Dsquared, Dolce&G...   \n",
       "7  [Bric`s, Hidnander, Inverni, Flower Mountain, ...   \n",
       "8  [Premiata, Premiata, Premiata, Premiata, Premi...   \n",
       "9  [Diesel, Valentino, Dolce&Gabbana, Limitato, V...   \n",
       "\n",
       "                                       ubcf_products  \\\n",
       "0  [13456544, 13505484, 13576366, 13439367, 13415...   \n",
       "1  [8034648, 13022889, 13416444, 13440544, 131624...   \n",
       "2  [13569583, 13209210, 13370219, 13368486, 13243...   \n",
       "3  [13380686, 13270483, 11330112, 13308941, 11251...   \n",
       "4  [12849051, 13406123, 13262093, 13419595, 13287...   \n",
       "5  [10960130, 13395719, 13014815, 13084364, 13365...   \n",
       "6  [13375377, 13413528, 13193191, 12539729, 12491...   \n",
       "7  [13381312, 13366043, 12218239, 13054418, 13090...   \n",
       "8  [10767247, 13323894, 10958183, 13381353, 13268...   \n",
       "9  [13402680, 13318408, 12568722, 13229899, 13373...   \n",
       "\n",
       "                                         ubcf_prices  \\\n",
       "0  [2850.0, 7640.0, 5300.0, 5880.0, 82800.0, 7760.0]   \n",
       "1  [22950.0, 42450.0, 21500.0, 125000.0, 82550.0,...   \n",
       "2  [22850.0, 31950.0, 59950.0, 63350.0, 4320.0, 1...   \n",
       "3  [27850.0, 24050.0, 29050.0, 27850.0, 27100.0, ...   \n",
       "4  [17750.0, 25550.0, 7650.0, 12500.0, 7995.0, 13...   \n",
       "5  [10600.0, 3720.0, 39750.0, 10800.0, 47400.0, 2...   \n",
       "6  [59950.0, 64550.0, 82100.0, 24750.0, 78850.0, ...   \n",
       "7  [34300.0, 33250.0, 12700.0, 23250.0, 14300.0, ...   \n",
       "8  [29050.0, 25450.0, 29750.0, 29750.0, 24050.0, ...   \n",
       "9  [5790.0, 98450.0, 59050.0, 13200.0, 7155.0, 69...   \n",
       "\n",
       "                                          ubcf_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/7ef4612372897d7cc...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/1797545d653...   \n",
       "2  [None, None, None, None, None, https://st-cdn....   \n",
       "3  [None, None, https://st-cdn.tsum.com/sig/76ba7...   \n",
       "4               [None, None, None, None, None, None]   \n",
       "5  [None, None, None, None, None, https://st-cdn....   \n",
       "6  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "7  [None, None, https://st-cdn.tsum.com/sig/b3906...   \n",
       "8  [None, https://st-cdn.tsum.com/sig/0e7fa951bee...   \n",
       "9               [None, None, None, None, None, None]   \n",
       "\n",
       "                                         ibcf_titles  \\\n",
       "0  [Юбка, Сумка Love One Classic, Хлопковый пулов...   \n",
       "1  [Шерстяная шапка, Платье, Шелковая блузка, Бар...   \n",
       "2  [Брюки из хлопка и шелка, Кардиган из шерсти и...   \n",
       "3  [Льняные шорты, Кожаные мокасины, Пуховик, Пух...   \n",
       "4  [Шерстяной кардиган, Оправа, Хлопковая футболк...   \n",
       "5  [Солнцезащитные очки, Ваза Monofiori Frozen, П...   \n",
       "6  [Хлопковая сорочка, Хлопковая рубашка, Хлопков...   \n",
       "7  [Солнцезащитные очки, Хлопковый топ свободного...   \n",
       "8  [Набор из четырех серег, Хлопковые боксеры, На...   \n",
       "9  [Оправа, Хлопковый пиджак, Плавки-шорты, Хлопк...   \n",
       "\n",
       "                                         ibcf_brands  \\\n",
       "0  [Blumarine, Pinko, Iro, Tom Ford, Giorgio Arma...   \n",
       "1  [Marni, Designer`s Cat, Designer`s Cat, Saint ...   \n",
       "2  [Marco Pescarolo, Luigi Borrelli, Luigi Borrel...   \n",
       "3  [120% Lino, Atlanta Mocassin, Hetrego, Hetrego...   \n",
       "4  [Dries Van Noten, Saint Laurent Paris, Paul & ...   \n",
       "5  [Ray-Ban, Venini, Moorer, Brioni, Amina Muaddi...   \n",
       "6  [Corneliani, Van Laack, Jil Sander, Sonrisa, D...   \n",
       "7  [Chloe, Chloe, Bottega Veneta, Melissa Odabash...   \n",
       "8  [Jil Sander, Tom Ford, Marni, Chloe, Comme Des...   \n",
       "9  [Tom Ford, Harris Wharf London, Vilebrequin, B...   \n",
       "\n",
       "                                       ibcf_products  \\\n",
       "0  [13592319, 13608237, 13630851, 10657051, 13587...   \n",
       "1  [13436507, 12954264, 12968407, 8646903, 236264...   \n",
       "2  [13483916, 13451309, 12289393, 12803856, 12990...   \n",
       "3  [12501643, 2580019, 13003172, 12978994, 125427...   \n",
       "4  [13586226, 13253755, 13559727, 13119885, 12730...   \n",
       "5  [12027171, 13364136, 13379401, 10796503, 13538...   \n",
       "6  [11903573, 12501398, 12651657, 12230335, 11339...   \n",
       "7  [12772682, 2258839, 12007845, 2113603, 1358889...   \n",
       "8  [11768772, 10604959, 10538414, 12653117, 13595...   \n",
       "9  [12010666, 13624979, 13647340, 13494279, 13624...   \n",
       "\n",
       "                                         ibcf_prices  \\\n",
       "0  [33950.0, 49700.0, 45650.0, 163500.0, 49500.0,...   \n",
       "1  [16650.0, 20700.0, 13650.0, 299500.0, 3150.0, ...   \n",
       "2  [59950.0, 73500.0, 19550.0, 8500.0, 12850.0, 5...   \n",
       "3  [11950.0, 3760.0, 59950.0, 52650.0, 4365.0, 21...   \n",
       "4  [104000.0, 37950.0, 17750.0, 39080.0, 33050.0,...   \n",
       "5  [24950.0, 35700.0, 239000.0, 12400.0, 137500.0...   \n",
       "6  [12550.0, 13350.0, 20700.0, 13400.0, 18400.0, ...   \n",
       "7  [31950.0, 26100.0, 32750.0, 6200.0, 29400.0, 7...   \n",
       "8  [49900.0, 14650.0, 23150.0, 43950.0, 5710.0, 2...   \n",
       "9  [34700.0, 77800.0, 33250.0, 38050.0, 51650.0, ...   \n",
       "\n",
       "                                          ibcf_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c5d279d80679441b5...   \n",
       "1  [https://st-cdn.tsum.com/sig/67c651d5a424682d1...   \n",
       "2  [https://st-cdn.tsum.com/sig/2e0a01883b2707d99...   \n",
       "3               [None, None, None, None, None, None]   \n",
       "4  [https://st-cdn.tsum.com/sig/76b7a674b30b6748b...   \n",
       "5  [https://st-cdn.tsum.com/sig/b0530748f28ac8fc9...   \n",
       "6               [None, None, None, None, None, None]   \n",
       "7               [None, None, None, None, None, None]   \n",
       "8  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "9  [https://st-cdn.tsum.com/sig/25f6c563bebf96946...   \n",
       "\n",
       "                                           mf_titles  \\\n",
       "0  [Кожаные слипоны, Слитный купальник, Комбиниро...   \n",
       "1  [Пододеяльник Links Embroidery, Хлопковые джог...   \n",
       "2  [Кожаный ремень, Шорты из шерсти и хлопка, Хло...   \n",
       "3  [Хлопковая толстовка, Текстильные слипоны, Хло...   \n",
       "4  [Хлопковые джоггеры, Льняной топ, Хлопковая фу...   \n",
       "5  [Тарелка салатная Versailles Vert, Шелковые бр...   \n",
       "6  [Серьги, Боксеры, Хлопковая футболка, Сандалии...   \n",
       "7  [Платье из хлопка и вискозы, Ободок, Джоггеры,...   \n",
       "8  [Кожаный зажим для купюр, Комбинированные кеды...   \n",
       "9  [Хлопковая рубашка, Кожаные шлепанцы, Джинсы, ...   \n",
       "\n",
       "                                           mf_brands  \\\n",
       "0  [H`D`S`N Baracco, Scotch&Soda, Flower Mountain...   \n",
       "1  [Frette, Michael Kors, Tom Ford, Dolce&Gabbana...   \n",
       "2  [Antonelli Firenze, Zegna, Ermanno Scervino, M...   \n",
       "3  [Versace, Stella McCartney, Stone Island, Desi...   \n",
       "4  [Armani, 120% Lino, Brunello Cucinelli, Eleven...   \n",
       "5  [Bernardaud, Tibi, MVST, Givenchy, Jil Sander,...   \n",
       "6  [Versace, Zimmerli, Vetements, Giorgio Armani,...   \n",
       "7  [Bottega Veneta, Jennifer Ouellette, Barrow, B...   \n",
       "8  [Bottega Veneta, Premiata, Ree Projects, Sarto...   \n",
       "9  [Tom Ford, Premiata, Giorgio Armani, Roberto C...   \n",
       "\n",
       "                                         mf_products  \\\n",
       "0  [12435815, 13332086, 13468168, 7594187, 134790...   \n",
       "1  [13382692, 12115746, 2541923, 13628355, 115680...   \n",
       "2  [13439394, 12540785, 4809713, 13456129, 130988...   \n",
       "3  [12394897, 6566286, 13559833, 13455678, 254081...   \n",
       "4  [13605665, 13319460, 13468231, 13267061, 13285...   \n",
       "5  [13052719, 11399486, 13463033, 13558710, 12366...   \n",
       "6  [13378440, 13566382, 13094525, 12602503, 13385...   \n",
       "7  [12572864, 1595270, 12997565, 13581585, 132676...   \n",
       "8  [13608120, 13513908, 13428439, 13510137, 13404...   \n",
       "9  [12135329, 13503791, 13532729, 13591731, 13411...   \n",
       "\n",
       "                                           mf_prices  \\\n",
       "0  [29950.0, 7550.0, 29600.0, 9360.0, 14600.0, 53...   \n",
       "1  [96500.0, 18200.0, 207000.0, 123000.0, 133500....   \n",
       "2  [33350.0, 66700.0, 6395.0, 105000.0, 45700.0, ...   \n",
       "3  [8995.0, 3770.0, 19950.0, 53400.0, 2095.0, 333...   \n",
       "4  [15100.0, 19900.0, 45250.0, 25350.0, 9735.0, 3...   \n",
       "5  [21250.0, 8370.0, 81850.0, 293000.0, 33650.0, ...   \n",
       "6  [19950.0, 9585.0, 49950.0, 7315.0, 55300.0, 72...   \n",
       "7  [89400.0, 7760.0, 20800.0, 98750.0, 7725.0, 43...   \n",
       "8  [89950.0, 31950.0, 64800.0, 74800.0, 12600.0, ...   \n",
       "9  [69950.0, 48000.0, 19750.0, 49950.0, 79950.0, ...   \n",
       "\n",
       "                                            mf_links  \n",
       "0  [None, None, https://st-cdn.tsum.com/sig/f467e...  \n",
       "1  [None, None, None, https://st-cdn.tsum.com/sig...  \n",
       "2  [https://st-cdn.tsum.com/sig/55c4d1cccb6cf9b74...  \n",
       "3               [None, None, None, None, None, None]  \n",
       "4  [https://st-cdn.tsum.com/sig/b49ab4275ed5d95c7...  \n",
       "5  [None, None, https://st-cdn.tsum.com/sig/04105...  \n",
       "6  [None, https://st-cdn.tsum.com/sig/e9f51e335f5...  \n",
       "7  [https://st-cdn.tsum.com/sig/c5cd78cea764d17e0...  \n",
       "8  [https://st-cdn.tsum.com/sig/16c86edc9b6993c0d...  \n",
       "9  [None, https://st-cdn.tsum.com/sig/22d62a0214e...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>train_titles</th>\n",
       "      <th>train_brands</th>\n",
       "      <th>train_products</th>\n",
       "      <th>train_prices</th>\n",
       "      <th>train_links</th>\n",
       "      <th>test_titles</th>\n",
       "      <th>test_brands</th>\n",
       "      <th>test_products</th>\n",
       "      <th>test_prices</th>\n",
       "      <th>test_links</th>\n",
       "      <th>random_titles</th>\n",
       "      <th>random_brands</th>\n",
       "      <th>random_products</th>\n",
       "      <th>random_prices</th>\n",
       "      <th>random_links</th>\n",
       "      <th>top_k_titles</th>\n",
       "      <th>top_k_brands</th>\n",
       "      <th>top_k_products</th>\n",
       "      <th>top_k_prices</th>\n",
       "      <th>top_k_links</th>\n",
       "      <th>ubcf_titles</th>\n",
       "      <th>ubcf_brands</th>\n",
       "      <th>ubcf_products</th>\n",
       "      <th>ubcf_prices</th>\n",
       "      <th>ubcf_links</th>\n",
       "      <th>ibcf_titles</th>\n",
       "      <th>ibcf_brands</th>\n",
       "      <th>ibcf_products</th>\n",
       "      <th>ibcf_prices</th>\n",
       "      <th>ibcf_links</th>\n",
       "      <th>mf_titles</th>\n",
       "      <th>mf_brands</th>\n",
       "      <th>mf_products</th>\n",
       "      <th>mf_prices</th>\n",
       "      <th>mf_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wyyypqqtpqpprpws</td>\n",
       "      <td>[Хлопковая футболка, Хлопковая футболка, Хлопк...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Dolce&amp;Gabbana, ...</td>\n",
       "      <td>[12803705, 12312995, 12311565, 10178895]</td>\n",
       "      <td>[59950.0, 29950.0, 55900.0, 27950.0]</td>\n",
       "      <td>[None, None, None, None]</td>\n",
       "      <td>[Серьги, Сумка Chain Hobo]</td>\n",
       "      <td>[Anton Heunis, J.W. Anderson]</td>\n",
       "      <td>[13549798, 13465383]</td>\n",
       "      <td>[13300.0, 123000.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/912c78393e9...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Джинсы, Шелковая футболка, Замшевый бомбер, С...</td>\n",
       "      <td>[Kiton, Dolce&amp;Gabbana, BOSS, Michael Kors, Off...</td>\n",
       "      <td>[11464250, 10897290, 13461154, 13089856, 13452...</td>\n",
       "      <td>[65400.0, 32250.0, 79100.0, 28880.0, 88950.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/9bb1f...</td>\n",
       "      <td>[Шерстяная водолазка, Свитер из шерсти и кашем...</td>\n",
       "      <td>[Giorgio Armani, Giorgio Armani, Angulus, Palm...</td>\n",
       "      <td>[10396914, 11184534, 11730821, 13583284, 13456...</td>\n",
       "      <td>[78750.0, 44950.0, 8975.0, 23900.0, 18250.0, 1...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/8be13a669d8...</td>\n",
       "      <td>[Солнцезащитные очки, Серьги, Кеды, Хлопковые ...</td>\n",
       "      <td>[Gucci, Anton Heunis, Missouri, Dolce&amp;Gabbana,...</td>\n",
       "      <td>[13469357, 13615028, 12139483, 11314658, 13641...</td>\n",
       "      <td>[32500.0, 12500.0, 11750.0, 51650.0, 54950.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/e7eee111a9e46de68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wyyypqqtpqppupwq</td>\n",
       "      <td>[Текстильные кеды VL7N, Джинсы, Хлопковая футб...</td>\n",
       "      <td>[Valentino, Kiton, Giorgio Armani, Zilli, Bott...</td>\n",
       "      <td>[12498177, 13370502, 13252105, 13294097, 11725...</td>\n",
       "      <td>[55100.0, 124500.0, 49700.0, 47300.0, 116000.0...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/82b10436ab5...</td>\n",
       "      <td>[Хлопковая футболка, Хлопковая футболка, Хлопк...</td>\n",
       "      <td>[Giorgio Armani, Giorgio Armani, Zilli, Brunel...</td>\n",
       "      <td>[13252105, 13289913, 13294061, 13365689, 13211...</td>\n",
       "      <td>[49700.0, 49700.0, 63650.0, 99150.0, 68550.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/50d175b34c6713e0f...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Комбинированные кроссовки, Джинсы, Хлопковая ...</td>\n",
       "      <td>[Brioni, Dolce&amp;Gabbana, Valentino, Valentino, ...</td>\n",
       "      <td>[10350256, 11209952, 11203779, 13377023, 13239...</td>\n",
       "      <td>[84250.0, 59950.0, 35950.0, 49300.0, 96800.0, ...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/d381f04931c...</td>\n",
       "      <td>[Джинсы, Свитер из хлопка и льна, Юбка из хлоп...</td>\n",
       "      <td>[Brioni, Одежда Бутики\\, Versace, Versace, Tom...</td>\n",
       "      <td>[10363695, 12452122, 12640620, 12513552, 11840...</td>\n",
       "      <td>[54200.0, 107500.0, 159000.0, 119500.0, 459500...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/8d424...</td>\n",
       "      <td>[Сумка Crush, Плавки-шорты, Шерстяные брюки, Ш...</td>\n",
       "      <td>[Balenciaga, Givenchy, Marni, Kiton, N21, Prem...</td>\n",
       "      <td>[13561257, 13541634, 13438531, 11030978, 13504...</td>\n",
       "      <td>[312500.0, 17200.0, 84550.0, 89450.0, 33550.0,...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wyyypqqtpqppuxuv</td>\n",
       "      <td>[Замшевые лоферы, Джинсы, Хлопковые брюки, Шер...</td>\n",
       "      <td>[Kiton, Zilli, Kiton, Dolce&amp;Gabbana, Santoni, ...</td>\n",
       "      <td>[11023234, 13493383, 13517706, 12941581, 13394...</td>\n",
       "      <td>[110500.0, 136500.0, 115000.0, 78950.0, 81850....</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/0bc429b2a58b9dc02...</td>\n",
       "      <td>[Кожаные ботинки, Хлопковые шорты, Хлопковые б...</td>\n",
       "      <td>[Zilli, Kiton, Kiton, Kiton, Zilli, Santoni, Z...</td>\n",
       "      <td>[13454273, 13486790, 12811052, 13530969, 13534...</td>\n",
       "      <td>[168500.0, 94250.0, 23700.0, 115000.0, 121000....</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/caa3e55d563033697...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Хлопковое поло , Джинсы Margot Ultra Skinny, ...</td>\n",
       "      <td>[Kiton, Paige, Corneliani, MC2 Saint Barth, Di...</td>\n",
       "      <td>[13155564, 3577377, 13123846, 13395655, 133666...</td>\n",
       "      <td>[96950.0, 21500.0, 12250.0, 6825.0, 4320.0, 88...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/5e81d120b8f...</td>\n",
       "      <td>[Кашемировый шарф, Шарф из кашемира и шелка, К...</td>\n",
       "      <td>[Zilli, Zilli, Marco Pescarolo, Zilli, Le Sill...</td>\n",
       "      <td>[13434316, 13450569, 12845136, 11717148, 13482...</td>\n",
       "      <td>[89950.0, 108000.0, 62500.0, 120500.0, 56250.0...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/3eedb01f465...</td>\n",
       "      <td>[Хлопковое худи, Хлопковые джоггеры, Кашемиров...</td>\n",
       "      <td>[Givenchy, Eleventy, Burberry, MVST, Andrea Ca...</td>\n",
       "      <td>[12636065, 12770451, 11397700, 13316149, 13485...</td>\n",
       "      <td>[66250.0, 31100.0, 124500.0, 88600.0, 151000.0...</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wyyypqqtpqppxpqs</td>\n",
       "      <td>[Шлепанцы Rockstud, Пуховик Fustet, Текстильна...</td>\n",
       "      <td>[Valentino, Moncler, BOSS, Diesel]</td>\n",
       "      <td>[6904120, 12282338, 13429499, 13482312]</td>\n",
       "      <td>[35000.0, 145500.0, 13800.0, 29950.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/bdf25ad80ba3d2cc9...</td>\n",
       "      <td>[Двусторонний ремень VLogo Signature]</td>\n",
       "      <td>[Valentino]</td>\n",
       "      <td>[13639524]</td>\n",
       "      <td>[64650.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/7fb7cc9f6900a5714...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Текстильный ремень, Текстильные кеды S-Hanami...</td>\n",
       "      <td>[Off-White, Diesel, Premiata, Dolce&amp;Gabbana, B...</td>\n",
       "      <td>[11563264, 13511706, 13516764, 13089314, 11678...</td>\n",
       "      <td>[19550.0, 23450.0, 30750.0, 93350.0, 32850.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/2c19c...</td>\n",
       "      <td>[Сумка Magie small, Замшевые сапоги, Хлопковые...</td>\n",
       "      <td>[Coccinelle, Saint Laurent Paris, Dolce&amp;Gabban...</td>\n",
       "      <td>[12814454, 12286345, 13058077, 8896971, 124572...</td>\n",
       "      <td>[38400.0, 120500.0, 10400.0, 29050.0, 47450.0,...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Замшевые казаки West, Шерстяные брюки, Хлопко...</td>\n",
       "      <td>[Saint Laurent Paris, LVIR, Golden Goose Delux...</td>\n",
       "      <td>[11286803, 13553414, 13191763, 10897232, 10760...</td>\n",
       "      <td>[59950.0, 47900.0, 26350.0, 152500.0, 12750.0,...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/95cf11f3fa3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wyyypqqtpqppxqvy</td>\n",
       "      <td>[Шелковое платье, Рамка для фотографии Russian...</td>\n",
       "      <td>[Valentino, Faberge, Valentino, Dolce&amp;Gabbana,...</td>\n",
       "      <td>[11390368, 6641312, 12542017, 12651332, 124945...</td>\n",
       "      <td>[149500.0, 117000.0, 388000.0, 84150.0, 190500...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/30921...</td>\n",
       "      <td>[Кашемировый топ, Хлопковый лонгслив, Джинсы]</td>\n",
       "      <td>[Alexander McQueen, Jil Sander, Dolce&amp;Gabbana]</td>\n",
       "      <td>[12208096, 13427074, 12783431]</td>\n",
       "      <td>[72200.0, 76050.0, 37150.0]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кашемировая шапка с помпоном из меха лисы, Ко...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Gianvito Rossi, Balenciaga, Do...</td>\n",
       "      <td>[6723674, 13487297, 13631512, 13536356, 134200...</td>\n",
       "      <td>[77650.0, 194000.0, 132000.0, 122500.0, 111500...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/3159ea83e96...</td>\n",
       "      <td>[Ободок для волос, Юбка-макси, Юбка-миди, Шелк...</td>\n",
       "      <td>[Maison Michel Paris, Jacquemus, Ralph Lauren,...</td>\n",
       "      <td>[13461253, 11034997, 10538647, 11057389, 11519...</td>\n",
       "      <td>[12450.0, 42750.0, 68400.0, 89950.0, 139500.0,...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Статуэтка Bloom, Комплект из трех пар носков,...</td>\n",
       "      <td>[Baccarat, Diesel, Hinnominate, Corneliani, Ra...</td>\n",
       "      <td>[12702459, 13401489, 13480915, 13401816, 12621...</td>\n",
       "      <td>[17250.0, 2895.0, 6825.0, 69950.0, 2890.0, 299...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/13d43868670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wyyypqqtpqppyryt</td>\n",
       "      <td>[Поясная сумка, Сумка, Текстильные эспадрильи,...</td>\n",
       "      <td>[Brunello Cucinelli, Brunello Cucinelli, Casta...</td>\n",
       "      <td>[13408032, 13407245, 13549071, 13566545, 13543...</td>\n",
       "      <td>[178000.0, 158500.0, 11800.0, 18750.0, 11800.0...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/ac9bbee23fcb1cfc2...</td>\n",
       "      <td>[Текстильный рюкзак, Кожаные ботинки]</td>\n",
       "      <td>[Premiata, W.Gibbs]</td>\n",
       "      <td>[13432100, 13582149]</td>\n",
       "      <td>[51850.0, 63050.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/7c60c3fbc4f4a0c4d...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Замшевые сабо, Текстильные эспадрильи Woody, ...</td>\n",
       "      <td>[Manebi, Chloe, Manebi, Dolce&amp;Gabbana, MC2 Sai...</td>\n",
       "      <td>[13476813, 12041496, 13497712, 11723914, 13566...</td>\n",
       "      <td>[18200.0, 49950.0, 12300.0, 34950.0, 14400.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/33e956d80f95f2ee7...</td>\n",
       "      <td>[Хлопковое поло, Льняные брюки, Сумка Hammock,...</td>\n",
       "      <td>[Fioroni, 120% Lino, Loewe, Corneliani, Gucci,...</td>\n",
       "      <td>[12521535, 13480277, 11905496, 13519468, 12432...</td>\n",
       "      <td>[21200.0, 36250.0, 297000.0, 62300.0, 47520.0,...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/bc807df0a8e...</td>\n",
       "      <td>[Приталенное платье с цветочной отделкой, Хлоп...</td>\n",
       "      <td>[Monnalisa, Dolce&amp;Gabbana, Moorer, Forte_Forte...</td>\n",
       "      <td>[1825872, 12467016, 13257204, 11027886, 135388...</td>\n",
       "      <td>[15950.0, 16550.0, 55350.0, 27450.0, 99350.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/897b2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wyyypqqtpqppysxu</td>\n",
       "      <td>[Кожаные туфли, Сумка Hydole small, Шлепанцы, ...</td>\n",
       "      <td>[Maison Margiela, Coccinelle, Dolce&amp;Gabbana, J...</td>\n",
       "      <td>[13149184, 13247394, 13392902, 13473901, 13213...</td>\n",
       "      <td>[76500.0, 34350.0, 38800.0, 64350.0, 23800.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/5e7c6...</td>\n",
       "      <td>[Текстильные туфли Elisa 45, Комбинированные т...</td>\n",
       "      <td>[Jimmy Choo, Jimmy Choo, Dolce&amp;Gabbana]</td>\n",
       "      <td>[13620058, 13603660, 13617959]</td>\n",
       "      <td>[83800.0, 85050.0, 206500.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/8ca313b309c793878...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Замшевые полусапоги, Хлопковое худи, Хлопково...</td>\n",
       "      <td>[INUIKII, Acne Studios, Acne Studios, Paul &amp; S...</td>\n",
       "      <td>[12366838, 12730978, 12126778, 12813232, 12813...</td>\n",
       "      <td>[28550.0, 42550.0, 35300.0, 18850.0, 13200.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Шелковая блузка, Солнцезащитные очки, Топ, Су...</td>\n",
       "      <td>[Elie Saab, Saint Laurent Paris, Armarium, Sal...</td>\n",
       "      <td>[13455565, 13267170, 13503633, 13447574, 11417...</td>\n",
       "      <td>[188000.0, 41200.0, 49950.0, 299500.0, 9275.0,...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/b521f...</td>\n",
       "      <td>[Джинсы, Топ из смеси кашемира и шелка, Кашеми...</td>\n",
       "      <td>[Brunello Cucinelli, Dolce&amp;Gabbana, Nina Ricci...</td>\n",
       "      <td>[13406735, 8488773, 13364732, 13460848, 131535...</td>\n",
       "      <td>[47000.0, 56250.0, 82850.0, 92500.0, 47050.0, ...</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wyyypqqtpqppywrr</td>\n",
       "      <td>[Рюкзак Rhea mini, Текстильные полусапоги Kai,...</td>\n",
       "      <td>[Michael Kors, Jimmy Choo, Off-White, Goen.J, ...</td>\n",
       "      <td>[13061090, 12434532, 11996365, 13316056, 12444...</td>\n",
       "      <td>[33650.0, 109000.0, 52350.0, 48300.0, 56600.0,...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Складной зонт, Кожаные кеды Oversized]</td>\n",
       "      <td>[Moschino, Alexander McQueen]</td>\n",
       "      <td>[12586606, 10658655]</td>\n",
       "      <td>[10900.0, 51600.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/8cfae71ecd2...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Хлопковое платье, Хлопковая футболка, Пуховик...</td>\n",
       "      <td>[D.Exterior, Diesel, Add, Gucci, Casadei, Doro...</td>\n",
       "      <td>[13239525, 13636211, 13407510, 11211427, 12497...</td>\n",
       "      <td>[33600.0, 4805.0, 89800.0, 39950.0, 22300.0, 8...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/73b8f...</td>\n",
       "      <td>[Кашемировая шапка, Кожаные шорты, Хлопковые б...</td>\n",
       "      <td>[Fedeli, Saint Laurent Paris, Barrow, Michael ...</td>\n",
       "      <td>[12993530, 12370079, 13608390, 13507587, 13411...</td>\n",
       "      <td>[19750.0, 179500.0, 26500.0, 26550.0, 121000.0...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/ae032ee0de5...</td>\n",
       "      <td>[Хлопковый лонгслив, Замшевые мокасины, Хлопко...</td>\n",
       "      <td>[Lorena Antoniazzi, Tod`s, Brunello Cucinelli,...</td>\n",
       "      <td>[12821767, 12499173, 13103988, 13291998, 13548...</td>\n",
       "      <td>[16900.0, 49700.0, 166500.0, 19900.0, 66550.0,...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wyyypqqtpqprprpr</td>\n",
       "      <td>[Шерстяные брюки, Замшевые лоферы, Набор из 2-...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Pantanetti, Baccarat, Yves Sal...</td>\n",
       "      <td>[13444742, 13478410, 2095754, 13613074, 134017...</td>\n",
       "      <td>[111500.0, 48350.0, 49950.0, 1555000.0, 108000...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/e19cb381f02dcf343...</td>\n",
       "      <td>[Оправа, Шуба из овчины, Кожаные дерби, Вельве...</td>\n",
       "      <td>[Gucci, MVST, Doucal`s, D.Exterior, Giuseppe Z...</td>\n",
       "      <td>[13473507, 13603976, 13603532, 13580592, 13383...</td>\n",
       "      <td>[43900.0, 433500.0, 59950.0, 39950.0, 93750.0,...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/8a1bf...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Ваза Louxor, Тарелка Swing big, Тарелка Mille...</td>\n",
       "      <td>[Baccarat, Baccarat, Baccarat, Baccarat, Bacca...</td>\n",
       "      <td>[10617780, 11007691, 6639975, 4212067, 6639786...</td>\n",
       "      <td>[45150.0, 19800.0, 35250.0, 67050.0, 12050.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Двусторонняя дубленка с капюшоном, Дубленка с...</td>\n",
       "      <td>[Loro Piana, Yves Salomon, Paul &amp; Shark, Elie ...</td>\n",
       "      <td>[6629097, 6946064, 13645522, 13490949, 1338782...</td>\n",
       "      <td>[486500.0, 157500.0, 23400.0, 175500.0, 39950....</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Шелковый джемпер, Джинсовая куртка, Хлопковая...</td>\n",
       "      <td>[Gran Sasso, MM6 Maison Margiela, Il Trenino, ...</td>\n",
       "      <td>[10979182, 13517539, 13265485, 12439652, 13247...</td>\n",
       "      <td>[22700.0, 32750.0, 4945.0, 95700.0, 17050.0, 2...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/906b9713041d2d129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wyyypqqtpqprpury</td>\n",
       "      <td>[Кожаная обложка для паспорта, Джинсы, Комбини...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Gimo`...</td>\n",
       "      <td>[2557056, 11209952, 13257125, 13501925, 131772...</td>\n",
       "      <td>[23800.0, 59950.0, 29750.0, 123000.0, 35250.0,...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/1b15c816298ce33e4...</td>\n",
       "      <td>[Хлопковые легинсы, Хлопковый бра-топ, Хлопков...</td>\n",
       "      <td>[Stella McCartney, Stella McCartney, Rick Owens]</td>\n",
       "      <td>[13367627, 13457307, 13535378]</td>\n",
       "      <td>[18500.0, 16050.0, 58850.0]</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/a7938...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаная обложка для паспорта, Хлопковая футбо...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[2568464, 13396985, 13300206, 2799094, 1315532...</td>\n",
       "      <td>[19900.0, 65300.0, 27850.0, 19900.0, 29700.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/fa5f8abdf8f6e3d51...</td>\n",
       "      <td>[Хлопковый кардиган на молнии с капюшоном, Кож...</td>\n",
       "      <td>[Loro Piana, Dolce&amp;Gabbana, Add, Valentino, Da...</td>\n",
       "      <td>[2709247, 11247450, 13431189, 11930336, 103677...</td>\n",
       "      <td>[26250.0, 37250.0, 51200.0, 76550.0, 10600.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Плавки-шорты, Хлопковые боксеры, Хлопковый ло...</td>\n",
       "      <td>[MC2 Saint Barth, Moschino, Attachment, Forte ...</td>\n",
       "      <td>[13409247, 13548545, 13173884, 13574062, 13553...</td>\n",
       "      <td>[17950.0, 6485.0, 28800.0, 29500.0, 79950.0, 3...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/498abe5bd6c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anon_id_encrypred                                       train_titles  \\\n",
       "0  wyyypqqtpqpprpws  [Хлопковая футболка, Хлопковая футболка, Хлопк...   \n",
       "1  wyyypqqtpqppupwq  [Текстильные кеды VL7N, Джинсы, Хлопковая футб...   \n",
       "2  wyyypqqtpqppuxuv  [Замшевые лоферы, Джинсы, Хлопковые брюки, Шер...   \n",
       "3  wyyypqqtpqppxpqs  [Шлепанцы Rockstud, Пуховик Fustet, Текстильна...   \n",
       "4  wyyypqqtpqppxqvy  [Шелковое платье, Рамка для фотографии Russian...   \n",
       "5  wyyypqqtpqppyryt  [Поясная сумка, Сумка, Текстильные эспадрильи,...   \n",
       "6  wyyypqqtpqppysxu  [Кожаные туфли, Сумка Hydole small, Шлепанцы, ...   \n",
       "7  wyyypqqtpqppywrr  [Рюкзак Rhea mini, Текстильные полусапоги Kai,...   \n",
       "8  wyyypqqtpqprprpr  [Шерстяные брюки, Замшевые лоферы, Набор из 2-...   \n",
       "9  wyyypqqtpqprpury  [Кожаная обложка для паспорта, Джинсы, Комбини...   \n",
       "\n",
       "                                        train_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Dolce&Gabbana, ...   \n",
       "1  [Valentino, Kiton, Giorgio Armani, Zilli, Bott...   \n",
       "2  [Kiton, Zilli, Kiton, Dolce&Gabbana, Santoni, ...   \n",
       "3                 [Valentino, Moncler, BOSS, Diesel]   \n",
       "4  [Valentino, Faberge, Valentino, Dolce&Gabbana,...   \n",
       "5  [Brunello Cucinelli, Brunello Cucinelli, Casta...   \n",
       "6  [Maison Margiela, Coccinelle, Dolce&Gabbana, J...   \n",
       "7  [Michael Kors, Jimmy Choo, Off-White, Goen.J, ...   \n",
       "8  [Dolce&Gabbana, Pantanetti, Baccarat, Yves Sal...   \n",
       "9  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Gimo`...   \n",
       "\n",
       "                                      train_products  \\\n",
       "0           [12803705, 12312995, 12311565, 10178895]   \n",
       "1  [12498177, 13370502, 13252105, 13294097, 11725...   \n",
       "2  [11023234, 13493383, 13517706, 12941581, 13394...   \n",
       "3            [6904120, 12282338, 13429499, 13482312]   \n",
       "4  [11390368, 6641312, 12542017, 12651332, 124945...   \n",
       "5  [13408032, 13407245, 13549071, 13566545, 13543...   \n",
       "6  [13149184, 13247394, 13392902, 13473901, 13213...   \n",
       "7  [13061090, 12434532, 11996365, 13316056, 12444...   \n",
       "8  [13444742, 13478410, 2095754, 13613074, 134017...   \n",
       "9  [2557056, 11209952, 13257125, 13501925, 131772...   \n",
       "\n",
       "                                        train_prices  \\\n",
       "0               [59950.0, 29950.0, 55900.0, 27950.0]   \n",
       "1  [55100.0, 124500.0, 49700.0, 47300.0, 116000.0...   \n",
       "2  [110500.0, 136500.0, 115000.0, 78950.0, 81850....   \n",
       "3              [35000.0, 145500.0, 13800.0, 29950.0]   \n",
       "4  [149500.0, 117000.0, 388000.0, 84150.0, 190500...   \n",
       "5  [178000.0, 158500.0, 11800.0, 18750.0, 11800.0...   \n",
       "6  [76500.0, 34350.0, 38800.0, 64350.0, 23800.0, ...   \n",
       "7  [33650.0, 109000.0, 52350.0, 48300.0, 56600.0,...   \n",
       "8  [111500.0, 48350.0, 49950.0, 1555000.0, 108000...   \n",
       "9  [23800.0, 59950.0, 29750.0, 123000.0, 35250.0,...   \n",
       "\n",
       "                                         train_links  \\\n",
       "0                           [None, None, None, None]   \n",
       "1  [None, https://st-cdn.tsum.com/sig/82b10436ab5...   \n",
       "2  [https://st-cdn.tsum.com/sig/0bc429b2a58b9dc02...   \n",
       "3  [https://st-cdn.tsum.com/sig/bdf25ad80ba3d2cc9...   \n",
       "4  [None, None, https://st-cdn.tsum.com/sig/30921...   \n",
       "5  [https://st-cdn.tsum.com/sig/ac9bbee23fcb1cfc2...   \n",
       "6  [None, None, https://st-cdn.tsum.com/sig/5e7c6...   \n",
       "7  [None, None, None, None, None, https://st-cdn....   \n",
       "8  [https://st-cdn.tsum.com/sig/e19cb381f02dcf343...   \n",
       "9  [https://st-cdn.tsum.com/sig/1b15c816298ce33e4...   \n",
       "\n",
       "                                         test_titles  \\\n",
       "0                         [Серьги, Сумка Chain Hobo]   \n",
       "1  [Хлопковая футболка, Хлопковая футболка, Хлопк...   \n",
       "2  [Кожаные ботинки, Хлопковые шорты, Хлопковые б...   \n",
       "3              [Двусторонний ремень VLogo Signature]   \n",
       "4      [Кашемировый топ, Хлопковый лонгслив, Джинсы]   \n",
       "5              [Текстильный рюкзак, Кожаные ботинки]   \n",
       "6  [Текстильные туфли Elisa 45, Комбинированные т...   \n",
       "7            [Складной зонт, Кожаные кеды Oversized]   \n",
       "8  [Оправа, Шуба из овчины, Кожаные дерби, Вельве...   \n",
       "9  [Хлопковые легинсы, Хлопковый бра-топ, Хлопков...   \n",
       "\n",
       "                                         test_brands  \\\n",
       "0                      [Anton Heunis, J.W. Anderson]   \n",
       "1  [Giorgio Armani, Giorgio Armani, Zilli, Brunel...   \n",
       "2  [Zilli, Kiton, Kiton, Kiton, Zilli, Santoni, Z...   \n",
       "3                                        [Valentino]   \n",
       "4     [Alexander McQueen, Jil Sander, Dolce&Gabbana]   \n",
       "5                                [Premiata, W.Gibbs]   \n",
       "6            [Jimmy Choo, Jimmy Choo, Dolce&Gabbana]   \n",
       "7                      [Moschino, Alexander McQueen]   \n",
       "8  [Gucci, MVST, Doucal`s, D.Exterior, Giuseppe Z...   \n",
       "9   [Stella McCartney, Stella McCartney, Rick Owens]   \n",
       "\n",
       "                                       test_products  \\\n",
       "0                               [13549798, 13465383]   \n",
       "1  [13252105, 13289913, 13294061, 13365689, 13211...   \n",
       "2  [13454273, 13486790, 12811052, 13530969, 13534...   \n",
       "3                                         [13639524]   \n",
       "4                     [12208096, 13427074, 12783431]   \n",
       "5                               [13432100, 13582149]   \n",
       "6                     [13620058, 13603660, 13617959]   \n",
       "7                               [12586606, 10658655]   \n",
       "8  [13473507, 13603976, 13603532, 13580592, 13383...   \n",
       "9                     [13367627, 13457307, 13535378]   \n",
       "\n",
       "                                         test_prices  \\\n",
       "0                                [13300.0, 123000.0]   \n",
       "1  [49700.0, 49700.0, 63650.0, 99150.0, 68550.0, ...   \n",
       "2  [168500.0, 94250.0, 23700.0, 115000.0, 121000....   \n",
       "3                                          [64650.0]   \n",
       "4                        [72200.0, 76050.0, 37150.0]   \n",
       "5                                 [51850.0, 63050.0]   \n",
       "6                       [83800.0, 85050.0, 206500.0]   \n",
       "7                                 [10900.0, 51600.0]   \n",
       "8  [43900.0, 433500.0, 59950.0, 39950.0, 93750.0,...   \n",
       "9                        [18500.0, 16050.0, 58850.0]   \n",
       "\n",
       "                                          test_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/912c78393e9...   \n",
       "1  [https://st-cdn.tsum.com/sig/50d175b34c6713e0f...   \n",
       "2  [https://st-cdn.tsum.com/sig/caa3e55d563033697...   \n",
       "3  [https://st-cdn.tsum.com/sig/7fb7cc9f6900a5714...   \n",
       "4                                 [None, None, None]   \n",
       "5  [https://st-cdn.tsum.com/sig/7c60c3fbc4f4a0c4d...   \n",
       "6  [https://st-cdn.tsum.com/sig/8ca313b309c793878...   \n",
       "7  [None, https://st-cdn.tsum.com/sig/8cfae71ecd2...   \n",
       "8  [None, None, https://st-cdn.tsum.com/sig/8a1bf...   \n",
       "9  [None, None, https://st-cdn.tsum.com/sig/a7938...   \n",
       "\n",
       "                                       random_titles  \\\n",
       "0  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "1  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "2  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "3  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "4  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "5  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "6  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "7  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "8  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "9  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "\n",
       "                                       random_brands  \\\n",
       "0  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "1  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "2  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "3  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "4  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "5  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "6  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "7  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "8  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "9  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "\n",
       "                                     random_products  \\\n",
       "0  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "1  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "2  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "3  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "4  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "5  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "6  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "7  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "8  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "9  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "\n",
       "                                       random_prices  \\\n",
       "0  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "1  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "2  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "3  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "4  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "5  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "6  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "7  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "8  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "9  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "\n",
       "                           random_links  \\\n",
       "0  [None, None, None, None, None, None]   \n",
       "1  [None, None, None, None, None, None]   \n",
       "2  [None, None, None, None, None, None]   \n",
       "3  [None, None, None, None, None, None]   \n",
       "4  [None, None, None, None, None, None]   \n",
       "5  [None, None, None, None, None, None]   \n",
       "6  [None, None, None, None, None, None]   \n",
       "7  [None, None, None, None, None, None]   \n",
       "8  [None, None, None, None, None, None]   \n",
       "9  [None, None, None, None, None, None]   \n",
       "\n",
       "                                        top_k_titles  \\\n",
       "0  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "1  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "2  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "3  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "4  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "5  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "6  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "7  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "8  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "9  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "\n",
       "                                        top_k_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "1  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "2  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "3  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "4  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "5  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "6  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "7  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "8  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "9  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "\n",
       "                                      top_k_products  \\\n",
       "0  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "1  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "2  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "3  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "4  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "5  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "6  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "7  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "8  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "9  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "\n",
       "                                        top_k_prices  \\\n",
       "0  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "1  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "2  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "3  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "4  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "5  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "6  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "7  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "8  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "9  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "\n",
       "                                         top_k_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "1  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "2  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "3  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "4  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "5  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "6  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "7  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "8  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "9  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "\n",
       "                                         ubcf_titles  \\\n",
       "0  [Джинсы, Шелковая футболка, Замшевый бомбер, С...   \n",
       "1  [Комбинированные кроссовки, Джинсы, Хлопковая ...   \n",
       "2  [Хлопковое поло , Джинсы Margot Ultra Skinny, ...   \n",
       "3  [Текстильный ремень, Текстильные кеды S-Hanami...   \n",
       "4  [Кашемировая шапка с помпоном из меха лисы, Ко...   \n",
       "5  [Замшевые сабо, Текстильные эспадрильи Woody, ...   \n",
       "6  [Замшевые полусапоги, Хлопковое худи, Хлопково...   \n",
       "7  [Хлопковое платье, Хлопковая футболка, Пуховик...   \n",
       "8  [Ваза Louxor, Тарелка Swing big, Тарелка Mille...   \n",
       "9  [Кожаная обложка для паспорта, Хлопковая футбо...   \n",
       "\n",
       "                                         ubcf_brands  \\\n",
       "0  [Kiton, Dolce&Gabbana, BOSS, Michael Kors, Off...   \n",
       "1  [Brioni, Dolce&Gabbana, Valentino, Valentino, ...   \n",
       "2  [Kiton, Paige, Corneliani, MC2 Saint Barth, Di...   \n",
       "3  [Off-White, Diesel, Premiata, Dolce&Gabbana, B...   \n",
       "4  [Dolce&Gabbana, Gianvito Rossi, Balenciaga, Do...   \n",
       "5  [Manebi, Chloe, Manebi, Dolce&Gabbana, MC2 Sai...   \n",
       "6  [INUIKII, Acne Studios, Acne Studios, Paul & S...   \n",
       "7  [D.Exterior, Diesel, Add, Gucci, Casadei, Doro...   \n",
       "8  [Baccarat, Baccarat, Baccarat, Baccarat, Bacca...   \n",
       "9  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "\n",
       "                                       ubcf_products  \\\n",
       "0  [11464250, 10897290, 13461154, 13089856, 13452...   \n",
       "1  [10350256, 11209952, 11203779, 13377023, 13239...   \n",
       "2  [13155564, 3577377, 13123846, 13395655, 133666...   \n",
       "3  [11563264, 13511706, 13516764, 13089314, 11678...   \n",
       "4  [6723674, 13487297, 13631512, 13536356, 134200...   \n",
       "5  [13476813, 12041496, 13497712, 11723914, 13566...   \n",
       "6  [12366838, 12730978, 12126778, 12813232, 12813...   \n",
       "7  [13239525, 13636211, 13407510, 11211427, 12497...   \n",
       "8  [10617780, 11007691, 6639975, 4212067, 6639786...   \n",
       "9  [2568464, 13396985, 13300206, 2799094, 1315532...   \n",
       "\n",
       "                                         ubcf_prices  \\\n",
       "0  [65400.0, 32250.0, 79100.0, 28880.0, 88950.0, ...   \n",
       "1  [84250.0, 59950.0, 35950.0, 49300.0, 96800.0, ...   \n",
       "2  [96950.0, 21500.0, 12250.0, 6825.0, 4320.0, 88...   \n",
       "3  [19550.0, 23450.0, 30750.0, 93350.0, 32850.0, ...   \n",
       "4  [77650.0, 194000.0, 132000.0, 122500.0, 111500...   \n",
       "5  [18200.0, 49950.0, 12300.0, 34950.0, 14400.0, ...   \n",
       "6  [28550.0, 42550.0, 35300.0, 18850.0, 13200.0, ...   \n",
       "7  [33600.0, 4805.0, 89800.0, 39950.0, 22300.0, 8...   \n",
       "8  [45150.0, 19800.0, 35250.0, 67050.0, 12050.0, ...   \n",
       "9  [19900.0, 65300.0, 27850.0, 19900.0, 29700.0, ...   \n",
       "\n",
       "                                          ubcf_links  \\\n",
       "0  [None, None, https://st-cdn.tsum.com/sig/9bb1f...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/d381f04931c...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/5e81d120b8f...   \n",
       "3  [None, None, https://st-cdn.tsum.com/sig/2c19c...   \n",
       "4  [None, https://st-cdn.tsum.com/sig/3159ea83e96...   \n",
       "5  [https://st-cdn.tsum.com/sig/33e956d80f95f2ee7...   \n",
       "6               [None, None, None, None, None, None]   \n",
       "7  [None, None, https://st-cdn.tsum.com/sig/73b8f...   \n",
       "8               [None, None, None, None, None, None]   \n",
       "9  [https://st-cdn.tsum.com/sig/fa5f8abdf8f6e3d51...   \n",
       "\n",
       "                                         ibcf_titles  \\\n",
       "0  [Шерстяная водолазка, Свитер из шерсти и кашем...   \n",
       "1  [Джинсы, Свитер из хлопка и льна, Юбка из хлоп...   \n",
       "2  [Кашемировый шарф, Шарф из кашемира и шелка, К...   \n",
       "3  [Сумка Magie small, Замшевые сапоги, Хлопковые...   \n",
       "4  [Ободок для волос, Юбка-макси, Юбка-миди, Шелк...   \n",
       "5  [Хлопковое поло, Льняные брюки, Сумка Hammock,...   \n",
       "6  [Шелковая блузка, Солнцезащитные очки, Топ, Су...   \n",
       "7  [Кашемировая шапка, Кожаные шорты, Хлопковые б...   \n",
       "8  [Двусторонняя дубленка с капюшоном, Дубленка с...   \n",
       "9  [Хлопковый кардиган на молнии с капюшоном, Кож...   \n",
       "\n",
       "                                         ibcf_brands  \\\n",
       "0  [Giorgio Armani, Giorgio Armani, Angulus, Palm...   \n",
       "1  [Brioni, Одежда Бутики\\, Versace, Versace, Tom...   \n",
       "2  [Zilli, Zilli, Marco Pescarolo, Zilli, Le Sill...   \n",
       "3  [Coccinelle, Saint Laurent Paris, Dolce&Gabban...   \n",
       "4  [Maison Michel Paris, Jacquemus, Ralph Lauren,...   \n",
       "5  [Fioroni, 120% Lino, Loewe, Corneliani, Gucci,...   \n",
       "6  [Elie Saab, Saint Laurent Paris, Armarium, Sal...   \n",
       "7  [Fedeli, Saint Laurent Paris, Barrow, Michael ...   \n",
       "8  [Loro Piana, Yves Salomon, Paul & Shark, Elie ...   \n",
       "9  [Loro Piana, Dolce&Gabbana, Add, Valentino, Da...   \n",
       "\n",
       "                                       ibcf_products  \\\n",
       "0  [10396914, 11184534, 11730821, 13583284, 13456...   \n",
       "1  [10363695, 12452122, 12640620, 12513552, 11840...   \n",
       "2  [13434316, 13450569, 12845136, 11717148, 13482...   \n",
       "3  [12814454, 12286345, 13058077, 8896971, 124572...   \n",
       "4  [13461253, 11034997, 10538647, 11057389, 11519...   \n",
       "5  [12521535, 13480277, 11905496, 13519468, 12432...   \n",
       "6  [13455565, 13267170, 13503633, 13447574, 11417...   \n",
       "7  [12993530, 12370079, 13608390, 13507587, 13411...   \n",
       "8  [6629097, 6946064, 13645522, 13490949, 1338782...   \n",
       "9  [2709247, 11247450, 13431189, 11930336, 103677...   \n",
       "\n",
       "                                         ibcf_prices  \\\n",
       "0  [78750.0, 44950.0, 8975.0, 23900.0, 18250.0, 1...   \n",
       "1  [54200.0, 107500.0, 159000.0, 119500.0, 459500...   \n",
       "2  [89950.0, 108000.0, 62500.0, 120500.0, 56250.0...   \n",
       "3  [38400.0, 120500.0, 10400.0, 29050.0, 47450.0,...   \n",
       "4  [12450.0, 42750.0, 68400.0, 89950.0, 139500.0,...   \n",
       "5  [21200.0, 36250.0, 297000.0, 62300.0, 47520.0,...   \n",
       "6  [188000.0, 41200.0, 49950.0, 299500.0, 9275.0,...   \n",
       "7  [19750.0, 179500.0, 26500.0, 26550.0, 121000.0...   \n",
       "8  [486500.0, 157500.0, 23400.0, 175500.0, 39950....   \n",
       "9  [26250.0, 37250.0, 51200.0, 76550.0, 10600.0, ...   \n",
       "\n",
       "                                          ibcf_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/8be13a669d8...   \n",
       "1  [None, None, https://st-cdn.tsum.com/sig/8d424...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/3eedb01f465...   \n",
       "3  [None, None, None, None, None, https://st-cdn....   \n",
       "4  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "5  [None, https://st-cdn.tsum.com/sig/bc807df0a8e...   \n",
       "6  [None, None, https://st-cdn.tsum.com/sig/b521f...   \n",
       "7  [None, https://st-cdn.tsum.com/sig/ae032ee0de5...   \n",
       "8  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "9               [None, None, None, None, None, None]   \n",
       "\n",
       "                                           mf_titles  \\\n",
       "0  [Солнцезащитные очки, Серьги, Кеды, Хлопковые ...   \n",
       "1  [Сумка Crush, Плавки-шорты, Шерстяные брюки, Ш...   \n",
       "2  [Хлопковое худи, Хлопковые джоггеры, Кашемиров...   \n",
       "3  [Замшевые казаки West, Шерстяные брюки, Хлопко...   \n",
       "4  [Статуэтка Bloom, Комплект из трех пар носков,...   \n",
       "5  [Приталенное платье с цветочной отделкой, Хлоп...   \n",
       "6  [Джинсы, Топ из смеси кашемира и шелка, Кашеми...   \n",
       "7  [Хлопковый лонгслив, Замшевые мокасины, Хлопко...   \n",
       "8  [Шелковый джемпер, Джинсовая куртка, Хлопковая...   \n",
       "9  [Плавки-шорты, Хлопковые боксеры, Хлопковый ло...   \n",
       "\n",
       "                                           mf_brands  \\\n",
       "0  [Gucci, Anton Heunis, Missouri, Dolce&Gabbana,...   \n",
       "1  [Balenciaga, Givenchy, Marni, Kiton, N21, Prem...   \n",
       "2  [Givenchy, Eleventy, Burberry, MVST, Andrea Ca...   \n",
       "3  [Saint Laurent Paris, LVIR, Golden Goose Delux...   \n",
       "4  [Baccarat, Diesel, Hinnominate, Corneliani, Ra...   \n",
       "5  [Monnalisa, Dolce&Gabbana, Moorer, Forte_Forte...   \n",
       "6  [Brunello Cucinelli, Dolce&Gabbana, Nina Ricci...   \n",
       "7  [Lorena Antoniazzi, Tod`s, Brunello Cucinelli,...   \n",
       "8  [Gran Sasso, MM6 Maison Margiela, Il Trenino, ...   \n",
       "9  [MC2 Saint Barth, Moschino, Attachment, Forte ...   \n",
       "\n",
       "                                         mf_products  \\\n",
       "0  [13469357, 13615028, 12139483, 11314658, 13641...   \n",
       "1  [13561257, 13541634, 13438531, 11030978, 13504...   \n",
       "2  [12636065, 12770451, 11397700, 13316149, 13485...   \n",
       "3  [11286803, 13553414, 13191763, 10897232, 10760...   \n",
       "4  [12702459, 13401489, 13480915, 13401816, 12621...   \n",
       "5  [1825872, 12467016, 13257204, 11027886, 135388...   \n",
       "6  [13406735, 8488773, 13364732, 13460848, 131535...   \n",
       "7  [12821767, 12499173, 13103988, 13291998, 13548...   \n",
       "8  [10979182, 13517539, 13265485, 12439652, 13247...   \n",
       "9  [13409247, 13548545, 13173884, 13574062, 13553...   \n",
       "\n",
       "                                           mf_prices  \\\n",
       "0  [32500.0, 12500.0, 11750.0, 51650.0, 54950.0, ...   \n",
       "1  [312500.0, 17200.0, 84550.0, 89450.0, 33550.0,...   \n",
       "2  [66250.0, 31100.0, 124500.0, 88600.0, 151000.0...   \n",
       "3  [59950.0, 47900.0, 26350.0, 152500.0, 12750.0,...   \n",
       "4  [17250.0, 2895.0, 6825.0, 69950.0, 2890.0, 299...   \n",
       "5  [15950.0, 16550.0, 55350.0, 27450.0, 99350.0, ...   \n",
       "6  [47000.0, 56250.0, 82850.0, 92500.0, 47050.0, ...   \n",
       "7  [16900.0, 49700.0, 166500.0, 19900.0, 66550.0,...   \n",
       "8  [22700.0, 32750.0, 4945.0, 95700.0, 17050.0, 2...   \n",
       "9  [17950.0, 6485.0, 28800.0, 29500.0, 79950.0, 3...   \n",
       "\n",
       "                                            mf_links  \n",
       "0  [https://st-cdn.tsum.com/sig/e7eee111a9e46de68...  \n",
       "1  [None, None, None, None, https://st-cdn.tsum.c...  \n",
       "2  [None, None, None, https://st-cdn.tsum.com/sig...  \n",
       "3  [None, https://st-cdn.tsum.com/sig/95cf11f3fa3...  \n",
       "4  [None, https://st-cdn.tsum.com/sig/13d43868670...  \n",
       "5  [None, None, https://st-cdn.tsum.com/sig/897b2...  \n",
       "6  [None, None, None, https://st-cdn.tsum.com/sig...  \n",
       "7  [None, None, None, None, https://st-cdn.tsum.c...  \n",
       "8  [https://st-cdn.tsum.com/sig/906b9713041d2d129...  \n",
       "9  [None, https://st-cdn.tsum.com/sig/498abe5bd6c...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_final_dataframe(df_group,  # df_ambassadors или df_rich\n",
    "                          train_dict, test_dict,\n",
    "                          rec_random, rec_topk, rec_ubcf, rec_ibcf, rec_mf,\n",
    "                          n=10):\n",
    "    \"\"\"\n",
    "    Формируем DataFrame по n пользователям из df_group, упорядочивая столбцы \n",
    "    в логике: ID, затем для каждой группы (train/test/random/etc):\n",
    "      titles, brands, products, prices, links\n",
    "    \"\"\"\n",
    "    all_keys = set(train_dict.keys()) | set(test_dict.keys()) \\\n",
    "               | set(rec_random.keys()) | set(rec_topk.keys()) \\\n",
    "               | set(rec_ubcf.keys())  | set(rec_ibcf.keys()) \\\n",
    "               | set(rec_mf.keys())\n",
    "    \n",
    "    # Выберем всех пользователей, кто есть и в df_group, и в all_keys\n",
    "    df_ids = df_group['anon_id_encrypred'].unique()\n",
    "    valid_ids = [uid for uid in df_ids if uid in all_keys]\n",
    "    \n",
    "    # Если таких больше n, берем первые n\n",
    "    if len(valid_ids) > n:\n",
    "        valid_ids = valid_ids[:n]\n",
    "    \n",
    "    rows = []\n",
    "    for uid in valid_ids:\n",
    "        # train\n",
    "        train_items = list(train_dict.get(uid, []))\n",
    "        train_links, train_prices, train_brands, train_titles = [], [], [], []\n",
    "        for pid in train_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            train_links.append(link)\n",
    "            train_prices.append(price)\n",
    "            train_brands.append(br)\n",
    "            train_titles.append(tl)\n",
    "        \n",
    "        # test\n",
    "        test_items = list(test_dict.get(uid, []))\n",
    "        test_links, test_prices, test_brands, test_titles = [], [], [], []\n",
    "        for pid in test_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            test_links.append(link)\n",
    "            test_prices.append(price)\n",
    "            test_brands.append(br)\n",
    "            test_titles.append(tl)\n",
    "        \n",
    "        # random\n",
    "        random_items = list(rec_random.get(uid, []))\n",
    "        random_links, random_prices, random_brands, random_titles = [], [], [], []\n",
    "        for pid in random_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            random_links.append(link)\n",
    "            random_prices.append(price)\n",
    "            random_brands.append(br)\n",
    "            random_titles.append(tl)\n",
    "        \n",
    "        # top_k\n",
    "        topk_items = list(rec_topk.get(uid, []))\n",
    "        topk_links, topk_prices, topk_brands, topk_titles = [], [], [], []\n",
    "        for pid in topk_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            topk_links.append(link)\n",
    "            topk_prices.append(price)\n",
    "            topk_brands.append(br)\n",
    "            topk_titles.append(tl)\n",
    "        \n",
    "        # ubcf\n",
    "        ubcf_items = list(rec_ubcf.get(uid, []))\n",
    "        ubcf_links, ubcf_prices, ubcf_brands, ubcf_titles = [], [], [], []\n",
    "        for pid in ubcf_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            ubcf_links.append(link)\n",
    "            ubcf_prices.append(price)\n",
    "            ubcf_brands.append(br)\n",
    "            ubcf_titles.append(tl)\n",
    "        \n",
    "        # ibcf\n",
    "        ibcf_items = list(rec_ibcf.get(uid, []))\n",
    "        ibcf_links, ibcf_prices, ibcf_brands, ibcf_titles = [], [], [], []\n",
    "        for pid in ibcf_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            ibcf_links.append(link)\n",
    "            ibcf_prices.append(price)\n",
    "            ibcf_brands.append(br)\n",
    "            ibcf_titles.append(tl)\n",
    "        \n",
    "        # mf\n",
    "        mf_items = list(rec_mf.get(uid, []))\n",
    "        mf_links, mf_prices, mf_brands, mf_titles = [], [], [], []\n",
    "        for pid in mf_items:\n",
    "            link, price, br, tl = get_product_info(pid)\n",
    "            mf_links.append(link)\n",
    "            mf_prices.append(price)\n",
    "            mf_brands.append(br)\n",
    "            mf_titles.append(tl)\n",
    "        \n",
    "        rows.append({\n",
    "            'anon_id_encrypred': uid,\n",
    "            # train\n",
    "            'train_titles': train_titles,\n",
    "            'train_brands': train_brands,\n",
    "            'train_products': train_items,\n",
    "            'train_prices': train_prices,\n",
    "            'train_links': train_links,\n",
    "            # test\n",
    "            'test_titles': test_titles,\n",
    "            'test_brands': test_brands,\n",
    "            'test_products': test_items,\n",
    "            'test_prices': test_prices,\n",
    "            'test_links': test_links,\n",
    "            # random\n",
    "            'random_titles': random_titles,\n",
    "            'random_brands': random_brands,\n",
    "            'random_products': random_items,\n",
    "            'random_prices': random_prices,\n",
    "            'random_links': random_links,\n",
    "            # top_k\n",
    "            'top_k_titles': topk_titles,\n",
    "            'top_k_brands': topk_brands,\n",
    "            'top_k_products': topk_items,\n",
    "            'top_k_prices': topk_prices,\n",
    "            'top_k_links': topk_links,\n",
    "            # ubcf\n",
    "            'ubcf_titles': ubcf_titles,\n",
    "            'ubcf_brands': ubcf_brands,\n",
    "            'ubcf_products': ubcf_items,\n",
    "            'ubcf_prices': ubcf_prices,\n",
    "            'ubcf_links': ubcf_links,\n",
    "            # ibcf\n",
    "            'ibcf_titles': ibcf_titles,\n",
    "            'ibcf_brands': ibcf_brands,\n",
    "            'ibcf_products': ibcf_items,\n",
    "            'ibcf_prices': ibcf_prices,\n",
    "            'ibcf_links': ibcf_links,\n",
    "            # mf\n",
    "            'mf_titles': mf_titles,\n",
    "            'mf_brands': mf_brands,\n",
    "            'mf_products': mf_items,\n",
    "            'mf_prices': mf_prices,\n",
    "            'mf_links': mf_links,\n",
    "        })\n",
    "    \n",
    "    df_res = pd.DataFrame(rows)\n",
    "    \n",
    "    # Явно указываем нужный порядок столбцов:\n",
    "    desired_columns = [\n",
    "        'anon_id_encrypred',\n",
    "        # TRAIN\n",
    "        'train_titles', 'train_brands', 'train_products', 'train_prices', 'train_links',\n",
    "        # TEST\n",
    "        'test_titles', 'test_brands', 'test_products', 'test_prices', 'test_links',\n",
    "        # RANDOM\n",
    "        'random_titles', 'random_brands', 'random_products', 'random_prices', 'random_links',\n",
    "        # TOP-K\n",
    "        'top_k_titles', 'top_k_brands', 'top_k_products', 'top_k_prices', 'top_k_links',\n",
    "        # UBCF\n",
    "        'ubcf_titles', 'ubcf_brands', 'ubcf_products', 'ubcf_prices', 'ubcf_links',\n",
    "        # IBCF\n",
    "        'ibcf_titles', 'ibcf_brands', 'ibcf_products', 'ibcf_prices', 'ibcf_links',\n",
    "        # MF\n",
    "        'mf_titles', 'mf_brands', 'mf_products', 'mf_prices', 'mf_links',\n",
    "    ]\n",
    "    # Переставляем колонки (на случай, если DataFrame имеет те же, но в другом порядке)\n",
    "    df_res = df_res[desired_columns]\n",
    "    return df_res\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. Пример использования\n",
    "# ---------------------------------------------------------------\n",
    "# 3.1 Собираем 10 строк для df_ambassadors\n",
    "df_amb_10 = build_final_dataframe(\n",
    "    df_group=df_ambassadors,\n",
    "    train_dict=train_user_to_true_items,\n",
    "    test_dict=test_user_to_true_items,\n",
    "    rec_random=user_recommendations_random,\n",
    "    rec_topk=user_recommendations_top_k,\n",
    "    rec_ubcf=user_recommendations_ubcf,\n",
    "    rec_ibcf=user_recommendations_ibcf,\n",
    "    rec_mf=user_recommendations_mf,\n",
    "    n=10\n",
    ")\n",
    "\n",
    "# 3.2 Собираем 10 строк для df_rich\n",
    "df_rich_10 = build_final_dataframe(\n",
    "    df_group=df_rich,\n",
    "    train_dict=train_user_to_true_items,\n",
    "    test_dict=test_user_to_true_items,\n",
    "    rec_random=user_recommendations_random,\n",
    "    rec_topk=user_recommendations_top_k,\n",
    "    rec_ubcf=user_recommendations_ubcf,\n",
    "    rec_ibcf=user_recommendations_ibcf,\n",
    "    rec_mf=user_recommendations_mf,\n",
    "    n=10\n",
    ")\n",
    "\n",
    "# Проверим результат\n",
    "display(df_amb_10, df_rich_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c22734e3-a2ed-4690-a66d-e02d49905c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>total_receipts</th>\n",
       "      <th>avg_receipt_len</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>favourite_month_ratio</th>\n",
       "      <th>holiday_ratio</th>\n",
       "      <th>avg_receipt_value</th>\n",
       "      <th>avg_discount</th>\n",
       "      <th>premium_ratio</th>\n",
       "      <th>brand_entropy</th>\n",
       "      <th>category_entropy</th>\n",
       "      <th>collection_freshness</th>\n",
       "      <th>favourite_brand_ratio</th>\n",
       "      <th>train_titles</th>\n",
       "      <th>train_brands</th>\n",
       "      <th>train_products</th>\n",
       "      <th>train_prices</th>\n",
       "      <th>train_links</th>\n",
       "      <th>test_titles</th>\n",
       "      <th>test_brands</th>\n",
       "      <th>test_products</th>\n",
       "      <th>test_prices</th>\n",
       "      <th>test_links</th>\n",
       "      <th>random_titles</th>\n",
       "      <th>random_brands</th>\n",
       "      <th>random_products</th>\n",
       "      <th>random_prices</th>\n",
       "      <th>random_links</th>\n",
       "      <th>top_k_titles</th>\n",
       "      <th>top_k_brands</th>\n",
       "      <th>top_k_products</th>\n",
       "      <th>top_k_prices</th>\n",
       "      <th>top_k_links</th>\n",
       "      <th>ubcf_titles</th>\n",
       "      <th>ubcf_brands</th>\n",
       "      <th>ubcf_products</th>\n",
       "      <th>ubcf_prices</th>\n",
       "      <th>ubcf_links</th>\n",
       "      <th>ibcf_titles</th>\n",
       "      <th>ibcf_brands</th>\n",
       "      <th>ibcf_products</th>\n",
       "      <th>ibcf_prices</th>\n",
       "      <th>ibcf_links</th>\n",
       "      <th>mf_titles</th>\n",
       "      <th>mf_brands</th>\n",
       "      <th>mf_products</th>\n",
       "      <th>mf_prices</th>\n",
       "      <th>mf_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wyyypqqtpqppptqt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>12986.739167</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.357978</td>\n",
       "      <td>2.253858</td>\n",
       "      <td>91.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[Хлопковое платье, Хлопковая рубашка, Хлопкова...</td>\n",
       "      <td>[HUGO, Paul &amp; Shark, BOSS, BOSS, BOSS, Dolce&amp;G...</td>\n",
       "      <td>[13601472, 13463459, 13439364, 13502218, 13642...</td>\n",
       "      <td>[16000.0, 16050.0, 5880.0, 3840.0, 1300.0, 211...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/11f4789a902750d1f...</td>\n",
       "      <td>[Шерстяной шарф, Хлопковая бейсболка, Галстук]</td>\n",
       "      <td>[BOSS, BOSS, BOSS]</td>\n",
       "      <td>[13610113, 13593083, 13491591]</td>\n",
       "      <td>[10500.0, 4700.0, 7995.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/2aa0a05e8e7...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Комплект из двух пар носков, Хлопковая бейсбо...</td>\n",
       "      <td>[BOSS, Versace Jeans Couture, BOSS, BOSS, Duno...</td>\n",
       "      <td>[13456544, 13505484, 13576366, 13439367, 13415...</td>\n",
       "      <td>[2850.0, 7640.0, 5300.0, 5880.0, 82800.0, 7760.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/7ef4612372897d7cc...</td>\n",
       "      <td>[Юбка, Сумка Love One Classic, Хлопковый пулов...</td>\n",
       "      <td>[Blumarine, Pinko, Iro, Tom Ford, Giorgio Arma...</td>\n",
       "      <td>[13592319, 13608237, 13630851, 10657051, 13587...</td>\n",
       "      <td>[33950.0, 49700.0, 45650.0, 163500.0, 49500.0,...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c5d279d80679441b5...</td>\n",
       "      <td>[Кожаные слипоны, Слитный купальник, Комбиниро...</td>\n",
       "      <td>[H`D`S`N Baracco, Scotch&amp;Soda, Flower Mountain...</td>\n",
       "      <td>[12435815, 13332086, 13468168, 7594187, 134790...</td>\n",
       "      <td>[29950.0, 7550.0, 29600.0, 9360.0, 14600.0, 53...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/f467e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wyyypqqtpqpppxwy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>19891.528000</td>\n",
       "      <td>0.265073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>[Куртка, Шерстяная кепка, Набор из 2-х стакано...</td>\n",
       "      <td>[Deha, Gucci, Baccarat, Dolce&amp;Gabbana]</td>\n",
       "      <td>[13461536, 11247889, 13387866, 13430604]</td>\n",
       "      <td>[24100.0, 21650.0, 27500.0, 49950.0]</td>\n",
       "      <td>[None, None, None, None]</td>\n",
       "      <td>[Кардиган, Кольцо]</td>\n",
       "      <td>[Antonelli Firenze, Luv Aj]</td>\n",
       "      <td>[13324234, 13648375]</td>\n",
       "      <td>[52500.0, 8650.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/ae306cf3ac7...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Панама, Клипсы, Бра-топ, Пуховик, Утепленный ...</td>\n",
       "      <td>[Gucci, Dolce&amp;Gabbana, Dolce&amp;Gabbana, Bacon, s...</td>\n",
       "      <td>[8034648, 13022889, 13416444, 13440544, 131624...</td>\n",
       "      <td>[22950.0, 42450.0, 21500.0, 125000.0, 82550.0,...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/1797545d653...</td>\n",
       "      <td>[Шерстяная шапка, Платье, Шелковая блузка, Бар...</td>\n",
       "      <td>[Marni, Designer`s Cat, Designer`s Cat, Saint ...</td>\n",
       "      <td>[13436507, 12954264, 12968407, 8646903, 236264...</td>\n",
       "      <td>[16650.0, 20700.0, 13650.0, 299500.0, 3150.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/67c651d5a424682d1...</td>\n",
       "      <td>[Пододеяльник Links Embroidery, Хлопковые джог...</td>\n",
       "      <td>[Frette, Michael Kors, Tom Ford, Dolce&amp;Gabbana...</td>\n",
       "      <td>[13382692, 12115746, 2541923, 13628355, 115680...</td>\n",
       "      <td>[96500.0, 18200.0, 207000.0, 123000.0, 133500....</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wyyypqqtpqppqsyr</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>23382.478636</td>\n",
       "      <td>0.058763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.991346</td>\n",
       "      <td>1.395397</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[Льняная футболка, Кожаный ремень, Кожаные дер...</td>\n",
       "      <td>[120% Lino, Corneliani, Alexander McQueen, Dan...</td>\n",
       "      <td>[12691330, 13309189, 11824167, 13293831, 13290...</td>\n",
       "      <td>[11950.0, 21050.0, 49950.0, 13400.0, 13400.0, ...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Кожаные пенни-лоферы, Кожаные дерби]</td>\n",
       "      <td>[Barrett, Moma]</td>\n",
       "      <td>[13405136, 13570133]</td>\n",
       "      <td>[74900.0, 47300.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/dd8eade74bf...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные кеды Recut Low, Джинсы Skyline Straig...</td>\n",
       "      <td>[Crime London, Paige, Santoni, Off-White, Scot...</td>\n",
       "      <td>[13569583, 13209210, 13370219, 13368486, 13243...</td>\n",
       "      <td>[22850.0, 31950.0, 59950.0, 63350.0, 4320.0, 1...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Брюки из хлопка и шелка, Кардиган из шерсти и...</td>\n",
       "      <td>[Marco Pescarolo, Luigi Borrelli, Luigi Borrel...</td>\n",
       "      <td>[13483916, 13451309, 12289393, 12803856, 12990...</td>\n",
       "      <td>[59950.0, 73500.0, 19550.0, 8500.0, 12850.0, 5...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/2e0a01883b2707d99...</td>\n",
       "      <td>[Кожаный ремень, Шорты из шерсти и хлопка, Хло...</td>\n",
       "      <td>[Antonelli Firenze, Zegna, Ermanno Scervino, M...</td>\n",
       "      <td>[13439394, 12540785, 4809713, 13456129, 130988...</td>\n",
       "      <td>[33350.0, 66700.0, 6395.0, 105000.0, 45700.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/55c4d1cccb6cf9b74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wyyypqqtpqppquwt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>22941.400000</td>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950271</td>\n",
       "      <td>1.332179</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[Комбинированные кроссовки Buff Ly, Кожаные ке...</td>\n",
       "      <td>[Premiata, Premiata, Premiata, PT TORINO]</td>\n",
       "      <td>[13380688, 13178073, 12691555, 12926932]</td>\n",
       "      <td>[27850.0, 24050.0, 24050.0, 16600.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/16709080b9f...</td>\n",
       "      <td>[Кожаные туфли]</td>\n",
       "      <td>[BOSS]</td>\n",
       "      <td>[13488613]</td>\n",
       "      <td>[35450.0]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кожаные кеды Belle, Комбинированные кроссовки...</td>\n",
       "      <td>[Premiata, Premiata, Premiata, Premiata, Premi...</td>\n",
       "      <td>[13380686, 13270483, 11330112, 13308941, 11251...</td>\n",
       "      <td>[27850.0, 24050.0, 29050.0, 27850.0, 27100.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/76ba7...</td>\n",
       "      <td>[Льняные шорты, Кожаные мокасины, Пуховик, Пух...</td>\n",
       "      <td>[120% Lino, Atlanta Mocassin, Hetrego, Hetrego...</td>\n",
       "      <td>[12501643, 2580019, 13003172, 12978994, 125427...</td>\n",
       "      <td>[11950.0, 3760.0, 59950.0, 52650.0, 4365.0, 21...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Хлопковая толстовка, Текстильные слипоны, Хло...</td>\n",
       "      <td>[Versace, Stella McCartney, Stone Island, Desi...</td>\n",
       "      <td>[12394897, 6566286, 13559833, 13455678, 254081...</td>\n",
       "      <td>[8995.0, 3770.0, 19950.0, 53400.0, 2095.0, 333...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wyyypqqtpqppqvqt</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>24528.265238</td>\n",
       "      <td>0.051039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.725550</td>\n",
       "      <td>2.156088</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>[Хлопковая футболка, Хлопковый лонгслив, Комби...</td>\n",
       "      <td>[Comme Des Fuckdown, Bluemarble, Premiata, Han...</td>\n",
       "      <td>[13221303, 13384003, 12855112, 13503368, 13311...</td>\n",
       "      <td>[7995.0, 26350.0, 29950.0, 27150.0, 16250.0, 1...</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "      <td>[Кеды из нубука, Джинсы, Хлопковый лонгслив, Д...</td>\n",
       "      <td>[H`D`S`N Baracco, Juun.J, Dries Van Noten, Juu...</td>\n",
       "      <td>[13476415, 13515397, 13422870, 13514165]</td>\n",
       "      <td>[42100.0, 57600.0, 36550.0, 59950.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/f8f27b8bee27c641a...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Джинсы, Рубашка, Хлопковая футболка, Хлопкова...</td>\n",
       "      <td>[Diesel, Ksubi, Carne Bollente, Comme Des Fuck...</td>\n",
       "      <td>[12849051, 13406123, 13262093, 13419595, 13287...</td>\n",
       "      <td>[17750.0, 25550.0, 7650.0, 12500.0, 7995.0, 13...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Шерстяной кардиган, Оправа, Хлопковая футболк...</td>\n",
       "      <td>[Dries Van Noten, Saint Laurent Paris, Paul &amp; ...</td>\n",
       "      <td>[13586226, 13253755, 13559727, 13119885, 12730...</td>\n",
       "      <td>[104000.0, 37950.0, 17750.0, 39080.0, 33050.0,...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/76b7a674b30b6748b...</td>\n",
       "      <td>[Хлопковые джоггеры, Льняной топ, Хлопковая фу...</td>\n",
       "      <td>[Armani, 120% Lino, Brunello Cucinelli, Eleven...</td>\n",
       "      <td>[13605665, 13319460, 13468231, 13267061, 13285...</td>\n",
       "      <td>[15100.0, 19900.0, 45250.0, 25350.0, 9735.0, 3...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/b49ab4275ed5d95c7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anon_id_encrypred  total_receipts  avg_receipt_len  purchase_frequency  \\\n",
       "0  wyyypqqtpqppptqt             8.0         1.500000                30.0   \n",
       "1  wyyypqqtpqpppxwy             5.0         1.200000                83.0   \n",
       "2  wyyypqqtpqppqsyr            11.0         1.363636                 7.5   \n",
       "3  wyyypqqtpqppquwt             5.0         1.000000                62.0   \n",
       "4  wyyypqqtpqppqvqt             7.0         2.714286               109.0   \n",
       "\n",
       "   favourite_month_ratio  holiday_ratio  avg_receipt_value  avg_discount  \\\n",
       "0               0.375000       0.625000       12986.739167      0.075913   \n",
       "1               0.400000       0.600000       19891.528000      0.265073   \n",
       "2               0.454545       0.090909       23382.478636      0.058763   \n",
       "3               0.200000       0.400000       22941.400000      0.062630   \n",
       "4               0.428571       0.285714       24528.265238      0.051039   \n",
       "\n",
       "   premium_ratio  brand_entropy  category_entropy  collection_freshness  \\\n",
       "0            0.0       1.357978          2.253858                  91.5   \n",
       "1            0.0       1.791759          1.791759                  22.0   \n",
       "2            0.0       1.991346          1.395397                 365.0   \n",
       "3            0.0       0.950271          1.332179                 120.0   \n",
       "4            0.0       2.725550          2.156088                 169.0   \n",
       "\n",
       "   favourite_brand_ratio                                       train_titles  \\\n",
       "0               0.500000  [Хлопковое платье, Хлопковая рубашка, Хлопкова...   \n",
       "1               0.166667  [Куртка, Шерстяная кепка, Набор из 2-х стакано...   \n",
       "2               0.200000  [Льняная футболка, Кожаный ремень, Кожаные дер...   \n",
       "3               0.600000  [Комбинированные кроссовки Buff Ly, Кожаные ке...   \n",
       "4               0.105263  [Хлопковая футболка, Хлопковый лонгслив, Комби...   \n",
       "\n",
       "                                        train_brands  \\\n",
       "0  [HUGO, Paul & Shark, BOSS, BOSS, BOSS, Dolce&G...   \n",
       "1             [Deha, Gucci, Baccarat, Dolce&Gabbana]   \n",
       "2  [120% Lino, Corneliani, Alexander McQueen, Dan...   \n",
       "3          [Premiata, Premiata, Premiata, PT TORINO]   \n",
       "4  [Comme Des Fuckdown, Bluemarble, Premiata, Han...   \n",
       "\n",
       "                                      train_products  \\\n",
       "0  [13601472, 13463459, 13439364, 13502218, 13642...   \n",
       "1           [13461536, 11247889, 13387866, 13430604]   \n",
       "2  [12691330, 13309189, 11824167, 13293831, 13290...   \n",
       "3           [13380688, 13178073, 12691555, 12926932]   \n",
       "4  [13221303, 13384003, 12855112, 13503368, 13311...   \n",
       "\n",
       "                                        train_prices  \\\n",
       "0  [16000.0, 16050.0, 5880.0, 3840.0, 1300.0, 211...   \n",
       "1               [24100.0, 21650.0, 27500.0, 49950.0]   \n",
       "2  [11950.0, 21050.0, 49950.0, 13400.0, 13400.0, ...   \n",
       "3               [27850.0, 24050.0, 24050.0, 16600.0]   \n",
       "4  [7995.0, 26350.0, 29950.0, 27150.0, 16250.0, 1...   \n",
       "\n",
       "                                         train_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/11f4789a902750d1f...   \n",
       "1                           [None, None, None, None]   \n",
       "2  [None, None, None, None, None, https://st-cdn....   \n",
       "3  [None, https://st-cdn.tsum.com/sig/16709080b9f...   \n",
       "4  [None, None, None, https://st-cdn.tsum.com/sig...   \n",
       "\n",
       "                                         test_titles  \\\n",
       "0     [Шерстяной шарф, Хлопковая бейсболка, Галстук]   \n",
       "1                                 [Кардиган, Кольцо]   \n",
       "2              [Кожаные пенни-лоферы, Кожаные дерби]   \n",
       "3                                    [Кожаные туфли]   \n",
       "4  [Кеды из нубука, Джинсы, Хлопковый лонгслив, Д...   \n",
       "\n",
       "                                         test_brands  \\\n",
       "0                                 [BOSS, BOSS, BOSS]   \n",
       "1                        [Antonelli Firenze, Luv Aj]   \n",
       "2                                    [Barrett, Moma]   \n",
       "3                                             [BOSS]   \n",
       "4  [H`D`S`N Baracco, Juun.J, Dries Van Noten, Juu...   \n",
       "\n",
       "                              test_products  \\\n",
       "0            [13610113, 13593083, 13491591]   \n",
       "1                      [13324234, 13648375]   \n",
       "2                      [13405136, 13570133]   \n",
       "3                                [13488613]   \n",
       "4  [13476415, 13515397, 13422870, 13514165]   \n",
       "\n",
       "                            test_prices  \\\n",
       "0             [10500.0, 4700.0, 7995.0]   \n",
       "1                     [52500.0, 8650.0]   \n",
       "2                    [74900.0, 47300.0]   \n",
       "3                             [35450.0]   \n",
       "4  [42100.0, 57600.0, 36550.0, 59950.0]   \n",
       "\n",
       "                                          test_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/2aa0a05e8e7...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/ae306cf3ac7...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/dd8eade74bf...   \n",
       "3                                             [None]   \n",
       "4  [https://st-cdn.tsum.com/sig/f8f27b8bee27c641a...   \n",
       "\n",
       "                                       random_titles  \\\n",
       "0  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "1  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "2  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "3  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "4  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "\n",
       "                                       random_brands  \\\n",
       "0  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "1  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "2  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "3  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "4  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "\n",
       "                                     random_products  \\\n",
       "0  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "1  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "2  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "3  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "4  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "\n",
       "                                       random_prices  \\\n",
       "0  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "1  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "2  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "3  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "4  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "\n",
       "                           random_links  \\\n",
       "0  [None, None, None, None, None, None]   \n",
       "1  [None, None, None, None, None, None]   \n",
       "2  [None, None, None, None, None, None]   \n",
       "3  [None, None, None, None, None, None]   \n",
       "4  [None, None, None, None, None, None]   \n",
       "\n",
       "                                        top_k_titles  \\\n",
       "0  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "1  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "2  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "3  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "4  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "\n",
       "                                        top_k_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "1  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "2  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "3  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "4  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "\n",
       "                                      top_k_products  \\\n",
       "0  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "1  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "2  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "3  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "4  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "\n",
       "                                        top_k_prices  \\\n",
       "0  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "1  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "2  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "3  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "4  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "\n",
       "                                         top_k_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "1  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "2  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "3  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "4  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "\n",
       "                                         ubcf_titles  \\\n",
       "0  [Комплект из двух пар носков, Хлопковая бейсбо...   \n",
       "1  [Панама, Клипсы, Бра-топ, Пуховик, Утепленный ...   \n",
       "2  [Кожаные кеды Recut Low, Джинсы Skyline Straig...   \n",
       "3  [Кожаные кеды Belle, Комбинированные кроссовки...   \n",
       "4  [Джинсы, Рубашка, Хлопковая футболка, Хлопкова...   \n",
       "\n",
       "                                         ubcf_brands  \\\n",
       "0  [BOSS, Versace Jeans Couture, BOSS, BOSS, Duno...   \n",
       "1  [Gucci, Dolce&Gabbana, Dolce&Gabbana, Bacon, s...   \n",
       "2  [Crime London, Paige, Santoni, Off-White, Scot...   \n",
       "3  [Premiata, Premiata, Premiata, Premiata, Premi...   \n",
       "4  [Diesel, Ksubi, Carne Bollente, Comme Des Fuck...   \n",
       "\n",
       "                                       ubcf_products  \\\n",
       "0  [13456544, 13505484, 13576366, 13439367, 13415...   \n",
       "1  [8034648, 13022889, 13416444, 13440544, 131624...   \n",
       "2  [13569583, 13209210, 13370219, 13368486, 13243...   \n",
       "3  [13380686, 13270483, 11330112, 13308941, 11251...   \n",
       "4  [12849051, 13406123, 13262093, 13419595, 13287...   \n",
       "\n",
       "                                         ubcf_prices  \\\n",
       "0  [2850.0, 7640.0, 5300.0, 5880.0, 82800.0, 7760.0]   \n",
       "1  [22950.0, 42450.0, 21500.0, 125000.0, 82550.0,...   \n",
       "2  [22850.0, 31950.0, 59950.0, 63350.0, 4320.0, 1...   \n",
       "3  [27850.0, 24050.0, 29050.0, 27850.0, 27100.0, ...   \n",
       "4  [17750.0, 25550.0, 7650.0, 12500.0, 7995.0, 13...   \n",
       "\n",
       "                                          ubcf_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/7ef4612372897d7cc...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/1797545d653...   \n",
       "2  [None, None, None, None, None, https://st-cdn....   \n",
       "3  [None, None, https://st-cdn.tsum.com/sig/76ba7...   \n",
       "4               [None, None, None, None, None, None]   \n",
       "\n",
       "                                         ibcf_titles  \\\n",
       "0  [Юбка, Сумка Love One Classic, Хлопковый пулов...   \n",
       "1  [Шерстяная шапка, Платье, Шелковая блузка, Бар...   \n",
       "2  [Брюки из хлопка и шелка, Кардиган из шерсти и...   \n",
       "3  [Льняные шорты, Кожаные мокасины, Пуховик, Пух...   \n",
       "4  [Шерстяной кардиган, Оправа, Хлопковая футболк...   \n",
       "\n",
       "                                         ibcf_brands  \\\n",
       "0  [Blumarine, Pinko, Iro, Tom Ford, Giorgio Arma...   \n",
       "1  [Marni, Designer`s Cat, Designer`s Cat, Saint ...   \n",
       "2  [Marco Pescarolo, Luigi Borrelli, Luigi Borrel...   \n",
       "3  [120% Lino, Atlanta Mocassin, Hetrego, Hetrego...   \n",
       "4  [Dries Van Noten, Saint Laurent Paris, Paul & ...   \n",
       "\n",
       "                                       ibcf_products  \\\n",
       "0  [13592319, 13608237, 13630851, 10657051, 13587...   \n",
       "1  [13436507, 12954264, 12968407, 8646903, 236264...   \n",
       "2  [13483916, 13451309, 12289393, 12803856, 12990...   \n",
       "3  [12501643, 2580019, 13003172, 12978994, 125427...   \n",
       "4  [13586226, 13253755, 13559727, 13119885, 12730...   \n",
       "\n",
       "                                         ibcf_prices  \\\n",
       "0  [33950.0, 49700.0, 45650.0, 163500.0, 49500.0,...   \n",
       "1  [16650.0, 20700.0, 13650.0, 299500.0, 3150.0, ...   \n",
       "2  [59950.0, 73500.0, 19550.0, 8500.0, 12850.0, 5...   \n",
       "3  [11950.0, 3760.0, 59950.0, 52650.0, 4365.0, 21...   \n",
       "4  [104000.0, 37950.0, 17750.0, 39080.0, 33050.0,...   \n",
       "\n",
       "                                          ibcf_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c5d279d80679441b5...   \n",
       "1  [https://st-cdn.tsum.com/sig/67c651d5a424682d1...   \n",
       "2  [https://st-cdn.tsum.com/sig/2e0a01883b2707d99...   \n",
       "3               [None, None, None, None, None, None]   \n",
       "4  [https://st-cdn.tsum.com/sig/76b7a674b30b6748b...   \n",
       "\n",
       "                                           mf_titles  \\\n",
       "0  [Кожаные слипоны, Слитный купальник, Комбиниро...   \n",
       "1  [Пододеяльник Links Embroidery, Хлопковые джог...   \n",
       "2  [Кожаный ремень, Шорты из шерсти и хлопка, Хло...   \n",
       "3  [Хлопковая толстовка, Текстильные слипоны, Хло...   \n",
       "4  [Хлопковые джоггеры, Льняной топ, Хлопковая фу...   \n",
       "\n",
       "                                           mf_brands  \\\n",
       "0  [H`D`S`N Baracco, Scotch&Soda, Flower Mountain...   \n",
       "1  [Frette, Michael Kors, Tom Ford, Dolce&Gabbana...   \n",
       "2  [Antonelli Firenze, Zegna, Ermanno Scervino, M...   \n",
       "3  [Versace, Stella McCartney, Stone Island, Desi...   \n",
       "4  [Armani, 120% Lino, Brunello Cucinelli, Eleven...   \n",
       "\n",
       "                                         mf_products  \\\n",
       "0  [12435815, 13332086, 13468168, 7594187, 134790...   \n",
       "1  [13382692, 12115746, 2541923, 13628355, 115680...   \n",
       "2  [13439394, 12540785, 4809713, 13456129, 130988...   \n",
       "3  [12394897, 6566286, 13559833, 13455678, 254081...   \n",
       "4  [13605665, 13319460, 13468231, 13267061, 13285...   \n",
       "\n",
       "                                           mf_prices  \\\n",
       "0  [29950.0, 7550.0, 29600.0, 9360.0, 14600.0, 53...   \n",
       "1  [96500.0, 18200.0, 207000.0, 123000.0, 133500....   \n",
       "2  [33350.0, 66700.0, 6395.0, 105000.0, 45700.0, ...   \n",
       "3  [8995.0, 3770.0, 19950.0, 53400.0, 2095.0, 333...   \n",
       "4  [15100.0, 19900.0, 45250.0, 25350.0, 9735.0, 3...   \n",
       "\n",
       "                                            mf_links  \n",
       "0  [None, None, https://st-cdn.tsum.com/sig/f467e...  \n",
       "1  [None, None, None, https://st-cdn.tsum.com/sig...  \n",
       "2  [https://st-cdn.tsum.com/sig/55c4d1cccb6cf9b74...  \n",
       "3               [None, None, None, None, None, None]  \n",
       "4  [https://st-cdn.tsum.com/sig/b49ab4275ed5d95c7...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>total_receipts</th>\n",
       "      <th>avg_receipt_len</th>\n",
       "      <th>purchase_frequency</th>\n",
       "      <th>favourite_month_ratio</th>\n",
       "      <th>holiday_ratio</th>\n",
       "      <th>avg_receipt_value</th>\n",
       "      <th>avg_discount</th>\n",
       "      <th>premium_ratio</th>\n",
       "      <th>brand_entropy</th>\n",
       "      <th>category_entropy</th>\n",
       "      <th>collection_freshness</th>\n",
       "      <th>favourite_brand_ratio</th>\n",
       "      <th>train_titles</th>\n",
       "      <th>train_brands</th>\n",
       "      <th>train_products</th>\n",
       "      <th>train_prices</th>\n",
       "      <th>train_links</th>\n",
       "      <th>test_titles</th>\n",
       "      <th>test_brands</th>\n",
       "      <th>test_products</th>\n",
       "      <th>test_prices</th>\n",
       "      <th>test_links</th>\n",
       "      <th>random_titles</th>\n",
       "      <th>random_brands</th>\n",
       "      <th>random_products</th>\n",
       "      <th>random_prices</th>\n",
       "      <th>random_links</th>\n",
       "      <th>top_k_titles</th>\n",
       "      <th>top_k_brands</th>\n",
       "      <th>top_k_products</th>\n",
       "      <th>top_k_prices</th>\n",
       "      <th>top_k_links</th>\n",
       "      <th>ubcf_titles</th>\n",
       "      <th>ubcf_brands</th>\n",
       "      <th>ubcf_products</th>\n",
       "      <th>ubcf_prices</th>\n",
       "      <th>ubcf_links</th>\n",
       "      <th>ibcf_titles</th>\n",
       "      <th>ibcf_brands</th>\n",
       "      <th>ibcf_products</th>\n",
       "      <th>ibcf_prices</th>\n",
       "      <th>ibcf_links</th>\n",
       "      <th>mf_titles</th>\n",
       "      <th>mf_brands</th>\n",
       "      <th>mf_products</th>\n",
       "      <th>mf_prices</th>\n",
       "      <th>mf_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wyyypqqtpqpprpws</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>177.5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>42149.544000</td>\n",
       "      <td>0.217372</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.242453</td>\n",
       "      <td>1.560710</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[Хлопковая футболка, Хлопковая футболка, Хлопк...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Dolce&amp;Gabbana, ...</td>\n",
       "      <td>[12803705, 12312995, 12311565, 10178895]</td>\n",
       "      <td>[59950.0, 29950.0, 55900.0, 27950.0]</td>\n",
       "      <td>[None, None, None, None]</td>\n",
       "      <td>[Серьги, Сумка Chain Hobo]</td>\n",
       "      <td>[Anton Heunis, J.W. Anderson]</td>\n",
       "      <td>[13549798, 13465383]</td>\n",
       "      <td>[13300.0, 123000.0]</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/912c78393e9...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Джинсы, Шелковая футболка, Замшевый бомбер, С...</td>\n",
       "      <td>[Kiton, Dolce&amp;Gabbana, BOSS, Michael Kors, Off...</td>\n",
       "      <td>[11464250, 10897290, 13461154, 13089856, 13452...</td>\n",
       "      <td>[65400.0, 32250.0, 79100.0, 28880.0, 88950.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/9bb1f...</td>\n",
       "      <td>[Шерстяная водолазка, Свитер из шерсти и кашем...</td>\n",
       "      <td>[Giorgio Armani, Giorgio Armani, Angulus, Palm...</td>\n",
       "      <td>[10396914, 11184534, 11730821, 13583284, 13456...</td>\n",
       "      <td>[78750.0, 44950.0, 8975.0, 23900.0, 18250.0, 1...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/8be13a669d8...</td>\n",
       "      <td>[Солнцезащитные очки, Серьги, Кеды, Хлопковые ...</td>\n",
       "      <td>[Gucci, Anton Heunis, Missouri, Dolce&amp;Gabbana,...</td>\n",
       "      <td>[13469357, 13615028, 12139483, 11314658, 13641...</td>\n",
       "      <td>[32500.0, 12500.0, 11750.0, 51650.0, 54950.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/e7eee111a9e46de68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wyyypqqtpqppupwq</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>67846.828231</td>\n",
       "      <td>0.089116</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>1.924485</td>\n",
       "      <td>1.627668</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>[Текстильные кеды VL7N, Джинсы, Хлопковая футб...</td>\n",
       "      <td>[Valentino, Kiton, Giorgio Armani, Zilli, Bott...</td>\n",
       "      <td>[12498177, 13370502, 13252105, 13294097, 11725...</td>\n",
       "      <td>[55100.0, 124500.0, 49700.0, 47300.0, 116000.0...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/82b10436ab5...</td>\n",
       "      <td>[Хлопковая футболка, Хлопковая футболка, Хлопк...</td>\n",
       "      <td>[Giorgio Armani, Giorgio Armani, Zilli, Brunel...</td>\n",
       "      <td>[13252105, 13289913, 13294061, 13365689, 13211...</td>\n",
       "      <td>[49700.0, 49700.0, 63650.0, 99150.0, 68550.0, ...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/50d175b34c6713e0f...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Комбинированные кроссовки, Джинсы, Хлопковая ...</td>\n",
       "      <td>[Brioni, Dolce&amp;Gabbana, Valentino, Valentino, ...</td>\n",
       "      <td>[10350256, 11209952, 11203779, 13377023, 13239...</td>\n",
       "      <td>[84250.0, 59950.0, 35950.0, 49300.0, 96800.0, ...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/d381f04931c...</td>\n",
       "      <td>[Джинсы, Свитер из хлопка и льна, Юбка из хлоп...</td>\n",
       "      <td>[Brioni, Одежда Бутики\\, Versace, Versace, Tom...</td>\n",
       "      <td>[10363695, 12452122, 12640620, 12513552, 11840...</td>\n",
       "      <td>[54200.0, 107500.0, 159000.0, 119500.0, 459500...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/8d424...</td>\n",
       "      <td>[Сумка Crush, Плавки-шорты, Шерстяные брюки, Ш...</td>\n",
       "      <td>[Balenciaga, Givenchy, Marni, Kiton, N21, Prem...</td>\n",
       "      <td>[13561257, 13541634, 13438531, 11030978, 13504...</td>\n",
       "      <td>[312500.0, 17200.0, 84550.0, 89450.0, 33550.0,...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wyyypqqtpqppuxuv</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>83744.180942</td>\n",
       "      <td>0.094725</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.339814</td>\n",
       "      <td>2.629916</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>[Замшевые лоферы, Джинсы, Хлопковые брюки, Шер...</td>\n",
       "      <td>[Kiton, Zilli, Kiton, Dolce&amp;Gabbana, Santoni, ...</td>\n",
       "      <td>[11023234, 13493383, 13517706, 12941581, 13394...</td>\n",
       "      <td>[110500.0, 136500.0, 115000.0, 78950.0, 81850....</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/0bc429b2a58b9dc02...</td>\n",
       "      <td>[Кожаные ботинки, Хлопковые шорты, Хлопковые б...</td>\n",
       "      <td>[Zilli, Kiton, Kiton, Kiton, Zilli, Santoni, Z...</td>\n",
       "      <td>[13454273, 13486790, 12811052, 13530969, 13534...</td>\n",
       "      <td>[168500.0, 94250.0, 23700.0, 115000.0, 121000....</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/caa3e55d563033697...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Хлопковое поло , Джинсы Margot Ultra Skinny, ...</td>\n",
       "      <td>[Kiton, Paige, Corneliani, MC2 Saint Barth, Di...</td>\n",
       "      <td>[13155564, 3577377, 13123846, 13395655, 133666...</td>\n",
       "      <td>[96950.0, 21500.0, 12250.0, 6825.0, 4320.0, 88...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/5e81d120b8f...</td>\n",
       "      <td>[Кашемировый шарф, Шарф из кашемира и шелка, К...</td>\n",
       "      <td>[Zilli, Zilli, Marco Pescarolo, Zilli, Le Sill...</td>\n",
       "      <td>[13434316, 13450569, 12845136, 11717148, 13482...</td>\n",
       "      <td>[89950.0, 108000.0, 62500.0, 120500.0, 56250.0...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/3eedb01f465...</td>\n",
       "      <td>[Хлопковое худи, Хлопковые джоггеры, Кашемиров...</td>\n",
       "      <td>[Givenchy, Eleventy, Burberry, MVST, Andrea Ca...</td>\n",
       "      <td>[12636065, 12770451, 11397700, 13316149, 13485...</td>\n",
       "      <td>[66250.0, 31100.0, 124500.0, 88600.0, 151000.0...</td>\n",
       "      <td>[None, None, None, https://st-cdn.tsum.com/sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wyyypqqtpqppxpqs</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>55165.912000</td>\n",
       "      <td>0.140435</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.332179</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[Шлепанцы Rockstud, Пуховик Fustet, Текстильна...</td>\n",
       "      <td>[Valentino, Moncler, BOSS, Diesel]</td>\n",
       "      <td>[6904120, 12282338, 13429499, 13482312]</td>\n",
       "      <td>[35000.0, 145500.0, 13800.0, 29950.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/bdf25ad80ba3d2cc9...</td>\n",
       "      <td>[Двусторонний ремень VLogo Signature]</td>\n",
       "      <td>[Valentino]</td>\n",
       "      <td>[13639524]</td>\n",
       "      <td>[64650.0]</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/7fb7cc9f6900a5714...</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Текстильный ремень, Текстильные кеды S-Hanami...</td>\n",
       "      <td>[Off-White, Diesel, Premiata, Dolce&amp;Gabbana, B...</td>\n",
       "      <td>[11563264, 13511706, 13516764, 13089314, 11678...</td>\n",
       "      <td>[19550.0, 23450.0, 30750.0, 93350.0, 32850.0, ...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/2c19c...</td>\n",
       "      <td>[Сумка Magie small, Замшевые сапоги, Хлопковые...</td>\n",
       "      <td>[Coccinelle, Saint Laurent Paris, Dolce&amp;Gabban...</td>\n",
       "      <td>[12814454, 12286345, 13058077, 8896971, 124572...</td>\n",
       "      <td>[38400.0, 120500.0, 10400.0, 29050.0, 47450.0,...</td>\n",
       "      <td>[None, None, None, None, None, https://st-cdn....</td>\n",
       "      <td>[Замшевые казаки West, Шерстяные брюки, Хлопко...</td>\n",
       "      <td>[Saint Laurent Paris, LVIR, Golden Goose Delux...</td>\n",
       "      <td>[11286803, 13553414, 13191763, 10897232, 10760...</td>\n",
       "      <td>[59950.0, 47900.0, 26350.0, 152500.0, 12750.0,...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/95cf11f3fa3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wyyypqqtpqppxqvy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>103794.073750</td>\n",
       "      <td>0.102364</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.569153</td>\n",
       "      <td>2.441015</td>\n",
       "      <td>751.5</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[Шелковое платье, Рамка для фотографии Russian...</td>\n",
       "      <td>[Valentino, Faberge, Valentino, Dolce&amp;Gabbana,...</td>\n",
       "      <td>[11390368, 6641312, 12542017, 12651332, 124945...</td>\n",
       "      <td>[149500.0, 117000.0, 388000.0, 84150.0, 190500...</td>\n",
       "      <td>[None, None, https://st-cdn.tsum.com/sig/30921...</td>\n",
       "      <td>[Кашемировый топ, Хлопковый лонгслив, Джинсы]</td>\n",
       "      <td>[Alexander McQueen, Jil Sander, Dolce&amp;Gabbana]</td>\n",
       "      <td>[12208096, 13427074, 12783431]</td>\n",
       "      <td>[72200.0, 76050.0, 37150.0]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>[Шелковый топ, Двусторонний ремень VLogo Signa...</td>\n",
       "      <td>[Proenza Schouler, Valentino, Versace Jeans Co...</td>\n",
       "      <td>[11102461, 12687611, 12993560, 13416324, 12062...</td>\n",
       "      <td>[15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...</td>\n",
       "      <td>[None, None, None, None, None, None]</td>\n",
       "      <td>[Комплект из двух боксеров, Комплект из двух б...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Dolce&amp;Gabbana, Premiata, Dolce...</td>\n",
       "      <td>[13404705, 13404721, 2370888, 12749132, 128836...</td>\n",
       "      <td>[7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...</td>\n",
       "      <td>[https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...</td>\n",
       "      <td>[Кашемировая шапка с помпоном из меха лисы, Ко...</td>\n",
       "      <td>[Dolce&amp;Gabbana, Gianvito Rossi, Balenciaga, Do...</td>\n",
       "      <td>[6723674, 13487297, 13631512, 13536356, 134200...</td>\n",
       "      <td>[77650.0, 194000.0, 132000.0, 122500.0, 111500...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/3159ea83e96...</td>\n",
       "      <td>[Ободок для волос, Юбка-макси, Юбка-миди, Шелк...</td>\n",
       "      <td>[Maison Michel Paris, Jacquemus, Ralph Lauren,...</td>\n",
       "      <td>[13461253, 11034997, 10538647, 11057389, 11519...</td>\n",
       "      <td>[12450.0, 42750.0, 68400.0, 89950.0, 139500.0,...</td>\n",
       "      <td>[None, None, None, None, https://st-cdn.tsum.c...</td>\n",
       "      <td>[Статуэтка Bloom, Комплект из трех пар носков,...</td>\n",
       "      <td>[Baccarat, Diesel, Hinnominate, Corneliani, Ra...</td>\n",
       "      <td>[12702459, 13401489, 13480915, 13401816, 12621...</td>\n",
       "      <td>[17250.0, 2895.0, 6825.0, 69950.0, 2890.0, 299...</td>\n",
       "      <td>[None, https://st-cdn.tsum.com/sig/13d43868670...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anon_id_encrypred  total_receipts  avg_receipt_len  purchase_frequency  \\\n",
       "0  wyyypqqtpqpprpws             5.0         1.200000               177.5   \n",
       "1  wyyypqqtpqppupwq             7.0         4.142857                 5.5   \n",
       "2  wyyypqqtpqppuxuv            23.0         1.521739                16.0   \n",
       "3  wyyypqqtpqppxpqs             5.0         1.000000               114.5   \n",
       "4  wyyypqqtpqppxqvy             8.0         1.750000                28.0   \n",
       "\n",
       "   favourite_month_ratio  holiday_ratio  avg_receipt_value  avg_discount  \\\n",
       "0               0.400000        0.80000       42149.544000      0.217372   \n",
       "1               0.571429        0.00000       67846.828231      0.089116   \n",
       "2               0.173913        0.26087       83744.180942      0.094725   \n",
       "3               0.400000        0.60000       55165.912000      0.140435   \n",
       "4               0.375000        0.87500      103794.073750      0.102364   \n",
       "\n",
       "   premium_ratio  brand_entropy  category_entropy  collection_freshness  \\\n",
       "0       0.166667       1.242453          1.560710                 384.0   \n",
       "1       0.206897       1.924485          1.627668                 111.0   \n",
       "2       0.400000       1.339814          2.629916                 206.0   \n",
       "3       0.200000       1.332179          1.609438                 221.0   \n",
       "4       0.428571       1.569153          2.441015                 751.5   \n",
       "\n",
       "   favourite_brand_ratio                                       train_titles  \\\n",
       "0               0.500000  [Хлопковая футболка, Хлопковая футболка, Хлопк...   \n",
       "1               0.275862  [Текстильные кеды VL7N, Джинсы, Хлопковая футб...   \n",
       "2               0.542857  [Замшевые лоферы, Джинсы, Хлопковые брюки, Шер...   \n",
       "3               0.400000  [Шлепанцы Rockstud, Пуховик Fustet, Текстильна...   \n",
       "4               0.357143  [Шелковое платье, Рамка для фотографии Russian...   \n",
       "\n",
       "                                        train_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Dolce&Gabbana, ...   \n",
       "1  [Valentino, Kiton, Giorgio Armani, Zilli, Bott...   \n",
       "2  [Kiton, Zilli, Kiton, Dolce&Gabbana, Santoni, ...   \n",
       "3                 [Valentino, Moncler, BOSS, Diesel]   \n",
       "4  [Valentino, Faberge, Valentino, Dolce&Gabbana,...   \n",
       "\n",
       "                                      train_products  \\\n",
       "0           [12803705, 12312995, 12311565, 10178895]   \n",
       "1  [12498177, 13370502, 13252105, 13294097, 11725...   \n",
       "2  [11023234, 13493383, 13517706, 12941581, 13394...   \n",
       "3            [6904120, 12282338, 13429499, 13482312]   \n",
       "4  [11390368, 6641312, 12542017, 12651332, 124945...   \n",
       "\n",
       "                                        train_prices  \\\n",
       "0               [59950.0, 29950.0, 55900.0, 27950.0]   \n",
       "1  [55100.0, 124500.0, 49700.0, 47300.0, 116000.0...   \n",
       "2  [110500.0, 136500.0, 115000.0, 78950.0, 81850....   \n",
       "3              [35000.0, 145500.0, 13800.0, 29950.0]   \n",
       "4  [149500.0, 117000.0, 388000.0, 84150.0, 190500...   \n",
       "\n",
       "                                         train_links  \\\n",
       "0                           [None, None, None, None]   \n",
       "1  [None, https://st-cdn.tsum.com/sig/82b10436ab5...   \n",
       "2  [https://st-cdn.tsum.com/sig/0bc429b2a58b9dc02...   \n",
       "3  [https://st-cdn.tsum.com/sig/bdf25ad80ba3d2cc9...   \n",
       "4  [None, None, https://st-cdn.tsum.com/sig/30921...   \n",
       "\n",
       "                                         test_titles  \\\n",
       "0                         [Серьги, Сумка Chain Hobo]   \n",
       "1  [Хлопковая футболка, Хлопковая футболка, Хлопк...   \n",
       "2  [Кожаные ботинки, Хлопковые шорты, Хлопковые б...   \n",
       "3              [Двусторонний ремень VLogo Signature]   \n",
       "4      [Кашемировый топ, Хлопковый лонгслив, Джинсы]   \n",
       "\n",
       "                                         test_brands  \\\n",
       "0                      [Anton Heunis, J.W. Anderson]   \n",
       "1  [Giorgio Armani, Giorgio Armani, Zilli, Brunel...   \n",
       "2  [Zilli, Kiton, Kiton, Kiton, Zilli, Santoni, Z...   \n",
       "3                                        [Valentino]   \n",
       "4     [Alexander McQueen, Jil Sander, Dolce&Gabbana]   \n",
       "\n",
       "                                       test_products  \\\n",
       "0                               [13549798, 13465383]   \n",
       "1  [13252105, 13289913, 13294061, 13365689, 13211...   \n",
       "2  [13454273, 13486790, 12811052, 13530969, 13534...   \n",
       "3                                         [13639524]   \n",
       "4                     [12208096, 13427074, 12783431]   \n",
       "\n",
       "                                         test_prices  \\\n",
       "0                                [13300.0, 123000.0]   \n",
       "1  [49700.0, 49700.0, 63650.0, 99150.0, 68550.0, ...   \n",
       "2  [168500.0, 94250.0, 23700.0, 115000.0, 121000....   \n",
       "3                                          [64650.0]   \n",
       "4                        [72200.0, 76050.0, 37150.0]   \n",
       "\n",
       "                                          test_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/912c78393e9...   \n",
       "1  [https://st-cdn.tsum.com/sig/50d175b34c6713e0f...   \n",
       "2  [https://st-cdn.tsum.com/sig/caa3e55d563033697...   \n",
       "3  [https://st-cdn.tsum.com/sig/7fb7cc9f6900a5714...   \n",
       "4                                 [None, None, None]   \n",
       "\n",
       "                                       random_titles  \\\n",
       "0  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "1  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "2  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "3  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "4  [Шелковый топ, Двусторонний ремень VLogo Signa...   \n",
       "\n",
       "                                       random_brands  \\\n",
       "0  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "1  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "2  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "3  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "4  [Proenza Schouler, Valentino, Versace Jeans Co...   \n",
       "\n",
       "                                     random_products  \\\n",
       "0  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "1  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "2  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "3  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "4  [11102461, 12687611, 12993560, 13416324, 12062...   \n",
       "\n",
       "                                       random_prices  \\\n",
       "0  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "1  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "2  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "3  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "4  [15300.0, 49950.0, 33750.0, 28050.0, 38850.0, ...   \n",
       "\n",
       "                           random_links  \\\n",
       "0  [None, None, None, None, None, None]   \n",
       "1  [None, None, None, None, None, None]   \n",
       "2  [None, None, None, None, None, None]   \n",
       "3  [None, None, None, None, None, None]   \n",
       "4  [None, None, None, None, None, None]   \n",
       "\n",
       "                                        top_k_titles  \\\n",
       "0  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "1  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "2  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "3  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "4  [Комплект из двух боксеров, Комплект из двух б...   \n",
       "\n",
       "                                        top_k_brands  \\\n",
       "0  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "1  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "2  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "3  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "4  [Dolce&Gabbana, Dolce&Gabbana, Premiata, Dolce...   \n",
       "\n",
       "                                      top_k_products  \\\n",
       "0  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "1  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "2  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "3  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "4  [13404705, 13404721, 2370888, 12749132, 128836...   \n",
       "\n",
       "                                        top_k_prices  \\\n",
       "0  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "1  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "2  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "3  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "4  [7760.0, 7760.0, 29050.0, 71700.0, 84500.0, 55...   \n",
       "\n",
       "                                         top_k_links  \\\n",
       "0  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "1  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "2  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "3  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "4  [https://st-cdn.tsum.com/sig/c8fb07c6efaaa5178...   \n",
       "\n",
       "                                         ubcf_titles  \\\n",
       "0  [Джинсы, Шелковая футболка, Замшевый бомбер, С...   \n",
       "1  [Комбинированные кроссовки, Джинсы, Хлопковая ...   \n",
       "2  [Хлопковое поло , Джинсы Margot Ultra Skinny, ...   \n",
       "3  [Текстильный ремень, Текстильные кеды S-Hanami...   \n",
       "4  [Кашемировая шапка с помпоном из меха лисы, Ко...   \n",
       "\n",
       "                                         ubcf_brands  \\\n",
       "0  [Kiton, Dolce&Gabbana, BOSS, Michael Kors, Off...   \n",
       "1  [Brioni, Dolce&Gabbana, Valentino, Valentino, ...   \n",
       "2  [Kiton, Paige, Corneliani, MC2 Saint Barth, Di...   \n",
       "3  [Off-White, Diesel, Premiata, Dolce&Gabbana, B...   \n",
       "4  [Dolce&Gabbana, Gianvito Rossi, Balenciaga, Do...   \n",
       "\n",
       "                                       ubcf_products  \\\n",
       "0  [11464250, 10897290, 13461154, 13089856, 13452...   \n",
       "1  [10350256, 11209952, 11203779, 13377023, 13239...   \n",
       "2  [13155564, 3577377, 13123846, 13395655, 133666...   \n",
       "3  [11563264, 13511706, 13516764, 13089314, 11678...   \n",
       "4  [6723674, 13487297, 13631512, 13536356, 134200...   \n",
       "\n",
       "                                         ubcf_prices  \\\n",
       "0  [65400.0, 32250.0, 79100.0, 28880.0, 88950.0, ...   \n",
       "1  [84250.0, 59950.0, 35950.0, 49300.0, 96800.0, ...   \n",
       "2  [96950.0, 21500.0, 12250.0, 6825.0, 4320.0, 88...   \n",
       "3  [19550.0, 23450.0, 30750.0, 93350.0, 32850.0, ...   \n",
       "4  [77650.0, 194000.0, 132000.0, 122500.0, 111500...   \n",
       "\n",
       "                                          ubcf_links  \\\n",
       "0  [None, None, https://st-cdn.tsum.com/sig/9bb1f...   \n",
       "1  [None, https://st-cdn.tsum.com/sig/d381f04931c...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/5e81d120b8f...   \n",
       "3  [None, None, https://st-cdn.tsum.com/sig/2c19c...   \n",
       "4  [None, https://st-cdn.tsum.com/sig/3159ea83e96...   \n",
       "\n",
       "                                         ibcf_titles  \\\n",
       "0  [Шерстяная водолазка, Свитер из шерсти и кашем...   \n",
       "1  [Джинсы, Свитер из хлопка и льна, Юбка из хлоп...   \n",
       "2  [Кашемировый шарф, Шарф из кашемира и шелка, К...   \n",
       "3  [Сумка Magie small, Замшевые сапоги, Хлопковые...   \n",
       "4  [Ободок для волос, Юбка-макси, Юбка-миди, Шелк...   \n",
       "\n",
       "                                         ibcf_brands  \\\n",
       "0  [Giorgio Armani, Giorgio Armani, Angulus, Palm...   \n",
       "1  [Brioni, Одежда Бутики\\, Versace, Versace, Tom...   \n",
       "2  [Zilli, Zilli, Marco Pescarolo, Zilli, Le Sill...   \n",
       "3  [Coccinelle, Saint Laurent Paris, Dolce&Gabban...   \n",
       "4  [Maison Michel Paris, Jacquemus, Ralph Lauren,...   \n",
       "\n",
       "                                       ibcf_products  \\\n",
       "0  [10396914, 11184534, 11730821, 13583284, 13456...   \n",
       "1  [10363695, 12452122, 12640620, 12513552, 11840...   \n",
       "2  [13434316, 13450569, 12845136, 11717148, 13482...   \n",
       "3  [12814454, 12286345, 13058077, 8896971, 124572...   \n",
       "4  [13461253, 11034997, 10538647, 11057389, 11519...   \n",
       "\n",
       "                                         ibcf_prices  \\\n",
       "0  [78750.0, 44950.0, 8975.0, 23900.0, 18250.0, 1...   \n",
       "1  [54200.0, 107500.0, 159000.0, 119500.0, 459500...   \n",
       "2  [89950.0, 108000.0, 62500.0, 120500.0, 56250.0...   \n",
       "3  [38400.0, 120500.0, 10400.0, 29050.0, 47450.0,...   \n",
       "4  [12450.0, 42750.0, 68400.0, 89950.0, 139500.0,...   \n",
       "\n",
       "                                          ibcf_links  \\\n",
       "0  [None, https://st-cdn.tsum.com/sig/8be13a669d8...   \n",
       "1  [None, None, https://st-cdn.tsum.com/sig/8d424...   \n",
       "2  [None, https://st-cdn.tsum.com/sig/3eedb01f465...   \n",
       "3  [None, None, None, None, None, https://st-cdn....   \n",
       "4  [None, None, None, None, https://st-cdn.tsum.c...   \n",
       "\n",
       "                                           mf_titles  \\\n",
       "0  [Солнцезащитные очки, Серьги, Кеды, Хлопковые ...   \n",
       "1  [Сумка Crush, Плавки-шорты, Шерстяные брюки, Ш...   \n",
       "2  [Хлопковое худи, Хлопковые джоггеры, Кашемиров...   \n",
       "3  [Замшевые казаки West, Шерстяные брюки, Хлопко...   \n",
       "4  [Статуэтка Bloom, Комплект из трех пар носков,...   \n",
       "\n",
       "                                           mf_brands  \\\n",
       "0  [Gucci, Anton Heunis, Missouri, Dolce&Gabbana,...   \n",
       "1  [Balenciaga, Givenchy, Marni, Kiton, N21, Prem...   \n",
       "2  [Givenchy, Eleventy, Burberry, MVST, Andrea Ca...   \n",
       "3  [Saint Laurent Paris, LVIR, Golden Goose Delux...   \n",
       "4  [Baccarat, Diesel, Hinnominate, Corneliani, Ra...   \n",
       "\n",
       "                                         mf_products  \\\n",
       "0  [13469357, 13615028, 12139483, 11314658, 13641...   \n",
       "1  [13561257, 13541634, 13438531, 11030978, 13504...   \n",
       "2  [12636065, 12770451, 11397700, 13316149, 13485...   \n",
       "3  [11286803, 13553414, 13191763, 10897232, 10760...   \n",
       "4  [12702459, 13401489, 13480915, 13401816, 12621...   \n",
       "\n",
       "                                           mf_prices  \\\n",
       "0  [32500.0, 12500.0, 11750.0, 51650.0, 54950.0, ...   \n",
       "1  [312500.0, 17200.0, 84550.0, 89450.0, 33550.0,...   \n",
       "2  [66250.0, 31100.0, 124500.0, 88600.0, 151000.0...   \n",
       "3  [59950.0, 47900.0, 26350.0, 152500.0, 12750.0,...   \n",
       "4  [17250.0, 2895.0, 6825.0, 69950.0, 2890.0, 299...   \n",
       "\n",
       "                                            mf_links  \n",
       "0  [https://st-cdn.tsum.com/sig/e7eee111a9e46de68...  \n",
       "1  [None, None, None, None, https://st-cdn.tsum.c...  \n",
       "2  [None, None, None, https://st-cdn.tsum.com/sig...  \n",
       "3  [None, https://st-cdn.tsum.com/sig/95cf11f3fa3...  \n",
       "4  [None, https://st-cdn.tsum.com/sig/13d43868670...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для df_ambassadors\n",
    "df_amb_cols = list(df_ambassadors.columns)  # все столбцы исходника\n",
    "df_amb_10_cols = [c for c in df_amb_10.columns if c not in df_amb_cols or c == 'anon_id_encrypred']\n",
    "#  ^ оставим 'anon_id_encrypred', чтобы не пропал при мерже, \n",
    "#    а затем уберём дубликаты при переупорядочивании.\n",
    "\n",
    "df_amb_merged = pd.merge(\n",
    "    df_ambassadors, \n",
    "    df_amb_10, \n",
    "    how='left', \n",
    "    left_on='anon_id_encrypred', \n",
    "    right_on='anon_id_encrypred'\n",
    ")\n",
    "\n",
    "# Итоговый порядок: сначала все из df_ambassadors, затем всё остальное\n",
    "df_amb_merged = df_amb_merged[df_amb_cols + [c for c in df_amb_10_cols if c != 'anon_id_encrypred']]\n",
    "\n",
    "# Аналогично для df_rich\n",
    "df_rich_cols = list(df_rich.columns)\n",
    "df_rich_10_cols = [c for c in df_rich_10.columns if c not in df_rich_cols or c == 'anon_id_encrypred']\n",
    "\n",
    "df_rich_merged = pd.merge(\n",
    "    df_rich,\n",
    "    df_rich_10,\n",
    "    how='left',\n",
    "    on='anon_id_encrypred'  # или left_on='anon_id_encrypred', right_on='anon_id_encrypred'\n",
    ")\n",
    "\n",
    "df_rich_merged = df_rich_merged[df_rich_cols + [c for c in df_rich_10_cols if c != 'anon_id_encrypred']]\n",
    "\n",
    "# Проверим\n",
    "display(df_amb_merged.head(5), df_rich_merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b59ed06f-93a0-463c-a62e-a01713ded4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amb_merged.dropna().to_excel(\"final_ambassadors.xlsx\", index=False)\n",
    "df_rich_merged.dropna().to_excel(\"final_rich.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c7531-56f6-4054-8803-10d3d05f1066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cc968-dc21-43d1-915a-d706df9ce3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea871da0-986d-4844-9e01-ff17a4fbd6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51fe65-3aae-4b7f-9f61-abc91f5c93c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e487e7-9e3c-482e-bff6-c425da239823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852879e3-178a-48e0-91a8-beb2906d0d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "901f6312-e532-4d64-b22c-406b47a03f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afec96cdaa14e328c0e321bf2755749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# k = 5 # top_k_items\n",
    "# n = 100 # n_components\n",
    "\n",
    "# # Функция подготовки user-item матрицы с логарифмом\n",
    "# def prepare_user_item_matrix(df):\n",
    "#     \"\"\"\n",
    "#     Создает user-item матрицу с логарифмом количества покупок.\n",
    "    \n",
    "#     df: DataFrame с колонками ['anon_id_encrypred', 'product_id', 'base_price']\n",
    "    \n",
    "#     Возвращает:\n",
    "#     - user_item_matrix (numpy 2D массив)\n",
    "#     - users_mapping (словарь user_id -> индекс)\n",
    "#     - items_mapping (словарь product_id -> индекс)\n",
    "#     - reverse_users_mapping (словарь индекс -> user_id)\n",
    "#     - reverse_items_mapping (словарь индекс -> product_id)\n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "#     df['log_purchases'] = df.groupby(['anon_id_encrypred', 'product_id'])['base_price'].transform('count')\n",
    "#     df['log_purchases'] = np.log1p(df['log_purchases'])  # log(1 + count)\n",
    "\n",
    "#     # Уникальные пользователи и товары\n",
    "#     users = df['anon_id_encrypred'].unique()\n",
    "#     items = df['product_id'].unique()\n",
    "    \n",
    "#     # Создаем маппинги ID → индекс\n",
    "#     users_mapping = {user: i for i, user in enumerate(users)}\n",
    "#     items_mapping = {item: i for i, item in enumerate(items)}\n",
    "    \n",
    "#     # Обратные маппинги индекс → ID\n",
    "#     reverse_users_mapping = {i: user for user, i in users_mapping.items()}\n",
    "#     reverse_items_mapping = {i: item for item, i in items_mapping.items()}\n",
    "\n",
    "#     # Создаем user-item матрицу\n",
    "#     user_item_matrix = np.zeros((len(users), len(items)))\n",
    "#     for _, row in df.iterrows():\n",
    "#         user_idx = users_mapping[row['anon_id_encrypred']]\n",
    "#         item_idx = items_mapping[row['product_id']]\n",
    "#         user_item_matrix[user_idx, item_idx] = row['log_purchases']\n",
    "    \n",
    "#     return user_item_matrix, users_mapping, items_mapping, reverse_users_mapping, reverse_items_mapping\n",
    "\n",
    "# # Функция вычисления SVD\n",
    "# def compute_svd(user_item_matrix, n_components=n):\n",
    "#     \"\"\"\n",
    "#     Вычисляет SVD-разложение user-item матрицы.\n",
    "    \n",
    "#     user_item_matrix: numpy 2D массив (пользователи x товары)\n",
    "#     n_components: Количество скрытых факторов\n",
    "    \n",
    "#     Возвращает:\n",
    "#     - предсказанную user-item матрицу (numpy 2D массив)\n",
    "#     \"\"\"\n",
    "#     # Выполняем SVD\n",
    "#     U, sigma, Vt = svds(user_item_matrix, k=n_components)\n",
    "    \n",
    "#     # Преобразуем sigma (диагональную) в квадратную матрицу\n",
    "#     sigma = np.diag(sigma)\n",
    "\n",
    "#     # Восстанавливаем предсказанную матрицу рейтингов R = U * Σ * V^T\n",
    "#     predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "    \n",
    "#     return predicted_ratings\n",
    "\n",
    "# # Функция рекомендаций\n",
    "# def recommend_svd(user_id, predicted_matrix, users_mapping, items_mapping, reverse_items_mapping, top_k_items=k):\n",
    "#     \"\"\"\n",
    "#     Для пользователя user_id предсказываем top-K товаров на основе предсказанной матрицы.\n",
    "#     \"\"\"\n",
    "#     if user_id not in users_mapping:\n",
    "#         return []\n",
    "    \n",
    "#     user_idx = users_mapping[user_id]\n",
    "#     predicted_scores = predicted_matrix[user_idx]\n",
    "#     top_item_indices = np.argsort(predicted_scores)[::-1][:top_k_items]\n",
    "#     recommended_items = [reverse_items_mapping[i] for i in top_item_indices]\n",
    "    \n",
    "#     return recommended_items\n",
    "\n",
    "# # Запуск модели\n",
    "# user_item_matrix, users_mapping, items_mapping, reverse_users_mapping, reverse_items_mapping = prepare_user_item_matrix(train_df)\n",
    "# predicted_ratings = compute_svd(user_item_matrix, n_components=n)\n",
    "\n",
    "\n",
    "# user_recommendations_svd = {user: recommend_svd(user, predicted_ratings, users_mapping, items_mapping, reverse_items_mapping, top_k_items=k) \n",
    "#                             for user in tqdm(test_df['anon_id_encrypred'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "200ca99b-6693-4967-840f-a7be7150fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00427\n",
      "Recall@k: 0.002171\n",
      "MAP@k: 0.30818\n",
      "NDCG@k: 0.00412\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k(user_recommendations=user_recommendations_svd, eval_df=test_df, k=k)\n",
    "recall_k = recall_at_k(user_recommendations=user_recommendations_svd, eval_df=test_df, k=k)\n",
    "map_k = map_at_k(user_recommendations=user_recommendations_svd, eval_df=test_df, k=k)\n",
    "ndcg_k = ndcg_at_k(user_recommendations=user_recommendations_svd, eval_df=test_df, k=k)\n",
    "\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81e76654-97e4-4ca9-a5f4-466546687f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00138</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>0.20033</td>\n",
       "      <td>0.00161</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01055</td>\n",
       "      <td>0.00670</td>\n",
       "      <td>0.26343</td>\n",
       "      <td>0.01020</td>\n",
       "      <td>{'top_k_items': 5, 'top_n_similar_users': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBCF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00458</td>\n",
       "      <td>0.00573</td>\n",
       "      <td>0.24515</td>\n",
       "      <td>0.00570</td>\n",
       "      <td>{'top_k_items': 5, 'top_n_similar_items': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.39059</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>{'top_k_items': 5, 'n_components': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVD</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00427</td>\n",
       "      <td>0.00217</td>\n",
       "      <td>0.30818</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>{'top_k_items': 5, 'n_components': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  k  Precision@k  Recall@k    MAP@k   NDCG@k  \\\n",
       "0   Top-K  5      0.00138   0.00057  0.20033  0.00161   \n",
       "1  Random  5      0.00000   0.00000      NaN  0.00000   \n",
       "2    UBCF  5      0.01055   0.00670  0.26343  0.01020   \n",
       "3    IBCF  5      0.00458   0.00573  0.24515  0.00570   \n",
       "4     SVD  5      0.00175   0.00090  0.39059  0.00198   \n",
       "5     SVD  5      0.00427   0.00217  0.30818  0.00412   \n",
       "\n",
       "                           Other_hyperparameters  \n",
       "0                                           None  \n",
       "1                                           None  \n",
       "2  {'top_k_items': 5, 'top_n_similar_users': 20}  \n",
       "3  {'top_k_items': 5, 'top_n_similar_items': 20}  \n",
       "4         {'top_k_items': 5, 'n_components': 20}  \n",
       "5        {'top_k_items': 5, 'n_components': 100}  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='SVD', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, \n",
    "                  hyperparameters={'top_k_items': k, 'n_components': n})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71044b35-eca8-48f5-888b-280caec19ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0f1b5-f50b-4c88-85c3-a788ff339ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc02ec-6c5b-43c5-9a6a-dcd6ee13ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324128d7-db5a-439e-b84a-1a7c4e60f824",
   "metadata": {},
   "source": [
    "## Strong Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dfcf5-3ad3-42cf-a453-6852d5bb70e8",
   "metadata": {},
   "source": [
    "### BERT4Rec самописный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f794b4-d88e-472f-bcbb-7087c9574f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые импорты\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import random\n",
    "# from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Импорты для RecSys\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "# from surprise import SVD, Dataset, Reader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.set_per_process_memory_fraction(0.95)  # Ограничение памяти до 80%\n",
    "# torch.mps.empty_cache()\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb67bf34-ff10-4877-8db1-f2966e93f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BERT4RecDataset(Dataset):\n",
    "#     def __init__(self, \n",
    "#                  sequences, \n",
    "#                  max_len, \n",
    "#                  mask_prob, \n",
    "#                  num_items, \n",
    "#                  pad_token=0, \n",
    "#                  mask_token=None):\n",
    "#         \"\"\"\n",
    "#         Инициализация датасета\n",
    "        \n",
    "#         :param sequences: Список последовательностей взаимодействий\n",
    "#         :param max_len: Максимальная длина последовательности\n",
    "#         :param mask_prob: Вероятность маскирования элемента\n",
    "#         :param num_items: Количество уникальных элементов в датасете\n",
    "#         :param pad_token: Токен для дополнения последовательностей\n",
    "#         :param mask_token: Токен для маскирования элементов\n",
    "#         \"\"\"\n",
    "#         self.sequences = sequences\n",
    "#         self.max_len = max_len\n",
    "#         self.mask_prob = mask_prob\n",
    "#         self.num_items = num_items\n",
    "#         self.pad_token = pad_token\n",
    "#         self.mask_token = mask_token if mask_token is not None else num_items + 1\n",
    "\n",
    "#         # Предобработка последовательностей\n",
    "#         self.processed_sequences = []\n",
    "#         for seq in sequences:\n",
    "#             # Обрезка последовательности (берём последние покупки, поэтому -self.max_len)\n",
    "#             truncated = seq[-self.max_len:] if len(seq) > self.max_len else seq\n",
    "#             # Дополнение до максимальной длины\n",
    "#             padded = [self.pad_token] * (self.max_len - len(truncated)) + truncated\n",
    "#             self.processed_sequences.append(padded)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.processed_sequences)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         seq = self.processed_sequences[idx].copy()\n",
    "#         input_seq = []\n",
    "#         target_seq = []\n",
    "        \n",
    "#         for item in seq:\n",
    "#             if item == self.pad_token:\n",
    "#                 # Для pad-токенов не применяем маскирование\n",
    "#                 input_seq.append(self.pad_token)\n",
    "#                 target_seq.append(0)  # Игнорируется в функции потерь\n",
    "#                 continue\n",
    "#             # mask_prob_modern = self.mask_prob if len(seq) > 1 else 1.0  # Всегда маскируем одиночные токены\n",
    "#             # if random.random() < mask_prob_modern:\n",
    "#             if random.random() < self.mask_prob:\n",
    "#                 # Стратегия маскирования как в оригинальном BERT\n",
    "#                 rand_prob = random.random()\n",
    "#                 if rand_prob < 0.8:\n",
    "#                     # Замена на маску\n",
    "#                     input_seq.append(self.mask_token)\n",
    "#                 elif rand_prob < 0.9:\n",
    "#                     # Замена на случайный элемент\n",
    "#                     input_seq.append(random.randint(1, self.num_items))\n",
    "#                 else:\n",
    "#                     # Оставить оригинальный элемент\n",
    "#                     input_seq.append(item)\n",
    "#                 target_seq.append(item)\n",
    "#             else:\n",
    "#                 input_seq.append(item)\n",
    "#                 target_seq.append(0)  # Не маскированные элементы игнорируются\n",
    "\n",
    "#         # Создаем маску внимания\n",
    "#         attention_mask = [1 if token != self.pad_token else 0 for token in seq]\n",
    "#         # Позиционные индексы\n",
    "#         position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "#         return {\n",
    "#             \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "#             \"labels\": torch.tensor(target_seq, dtype=torch.long),\n",
    "#             \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "#             \"position_ids\": position_ids  # Добавляем позиционные индексы\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8124b6-5cc8-42cd-9834-65490e3e04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 sequences, \n",
    "                 max_len, \n",
    "                 mask_prob, \n",
    "                 num_items, \n",
    "                 pad_token=0, \n",
    "                 mask_token=None, \n",
    "                 is_train=True):\n",
    "        \"\"\"\n",
    "        Датасет для BERT4Rec.\n",
    "\n",
    "        :param sequences: Список кортежей (user_id, sequence)\n",
    "        :param max_len: Максимальная длина последовательности\n",
    "        :param mask_prob: Вероятность маскирования элемента (только для train)\n",
    "        :param num_items: Количество уникальных элементов в датасете\n",
    "        :param pad_token: Токен для дополнения последовательностей\n",
    "        :param mask_token: Токен для маскирования элементов\n",
    "        :param is_train: Использовать ли маскирование (True — обучение, False — тест/валидация)\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.num_items = num_items\n",
    "        self.pad_token = pad_token\n",
    "        self.mask_token = mask_token if mask_token is not None else num_items + 1\n",
    "        self.is_train = is_train \n",
    "\n",
    "        self.user_ids = []\n",
    "        self.processed_sequences = []\n",
    "        \n",
    "        for user_id, seq in sequences:\n",
    "            self.user_ids.append(user_id)\n",
    "            truncated = seq[-self.max_len:] if len(seq) > self.max_len else seq\n",
    "            padded = [self.pad_token] * (self.max_len - len(truncated)) + truncated\n",
    "            self.processed_sequences.append(padded)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.user_ids[idx]\n",
    "        seq = self.processed_sequences[idx].copy()\n",
    "        \n",
    "        input_seq = []\n",
    "        target_seq = []\n",
    "        \n",
    "        for item in seq:\n",
    "            if item == self.pad_token:\n",
    "                input_seq.append(self.pad_token)\n",
    "                target_seq.append(0)  # Игнорируется в функции потерь\n",
    "                continue\n",
    "\n",
    "            if self.is_train and random.random() < self.mask_prob:  # <-- Маскируем только в train\n",
    "                rand_prob = random.random()\n",
    "                if rand_prob < 0.8:\n",
    "                    input_seq.append(self.mask_token)  # Маскируем\n",
    "                elif rand_prob < 0.9:\n",
    "                    input_seq.append(random.randint(1, self.num_items))  # Рандомный токен\n",
    "                else:\n",
    "                    input_seq.append(item)  # Оставляем\n",
    "                target_seq.append(item)\n",
    "            else:\n",
    "                input_seq.append(item)\n",
    "                target_seq.append(0)  # Не маскированные элементы игнорируются\n",
    "\n",
    "        attention_mask = [1 if token != self.pad_token else 0 for token in seq]\n",
    "        position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"user_id\": user_id,\n",
    "            \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(target_seq, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"position_ids\": position_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5b6164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2526624, 21)\n",
      "Test shape: (704478, 21)\n",
      "Минимальный новый индекс: 1\n",
      "Максимальный новый индекс: 309343\n",
      "Количество уникальных товаров: 309343\n",
      "Всего пользователей: 273287\n",
      "Пользователей в тренировочной выборке: 242532\n",
      "Пользователей в тестовой выборке: 142987\n"
     ]
    }
   ],
   "source": [
    "notebook_path = Path().resolve()\n",
    "project_dir = notebook_path.parent\n",
    "\n",
    "interim_data_path = project_dir / 'data' / 'interim'\n",
    "\n",
    "# df_filtered = pd.read_csv(interim_data_path / 'df_filtered.csv')\n",
    "# df_filtered['order_date'] = pd.to_datetime(df_filtered['order_date'])\n",
    "# df_filtered = df_filtered.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# # Создаем маппинг оригинальных product_id в новые индексы от 1 до df_filtered['product_id'].unique()\n",
    "# unique_product_ids = df_filtered['product_id'].unique()\n",
    "# product_id_to_idx = {product_id: idx + 1 for idx, product_id in enumerate(unique_product_ids)}  # +1 чтобы начинать с 1\n",
    "\n",
    "# # Применяем маппинг к данным\n",
    "# df_filtered['product_idx'] = df_filtered['product_id'].map(product_id_to_idx)\n",
    "\n",
    "# threshold_level = 0.8\n",
    "# min_date = df_filtered['order_date'].min()\n",
    "# max_date = df_filtered['order_date'].max()\n",
    "\n",
    "# print(f\"Min date: {min_date}\")\n",
    "# print(f\"Max date: {max_date}\")\n",
    "\n",
    "# total_days = (max_date - min_date).days\n",
    "# threshold_days = int(total_days * threshold_level)\n",
    "# threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "# print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "# train_df = df_filtered[df_filtered['order_date'] < threshold_date]\n",
    "# test_df = df_filtered[df_filtered['order_date'] >= threshold_date]\n",
    "\n",
    "# interim_data_path = project_dir / 'data' / 'interim'\n",
    "# df_filtered.to_csv(interim_data_path / 'df_filtered_for_bert4rec.csv', index=False)\n",
    "# train_df.to_csv(interim_data_path / 'train_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "# test_df.to_csv(interim_data_path / 'test_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "\n",
    "df_filtered = pd.read_csv(interim_data_path / 'df_filtered_for_bert4rec.csv')\n",
    "train_df = pd.read_csv(interim_data_path / 'train_data_by_threshold_date_for_bert4rec.csv')\n",
    "test_df = pd.read_csv(interim_data_path / 'test_data_by_threshold_date_for_bert4rec.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "\n",
    "# test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "\n",
    "print(\"Минимальный новый индекс:\", df_filtered['product_idx'].min())  # Должно быть 1\n",
    "print(\"Максимальный новый индекс:\", df_filtered['product_idx'].max())  # Должно быть равно количеству уникальных товаров\n",
    "print(\"Количество уникальных товаров:\", df_filtered['product_id'].nunique())\n",
    "print(f\"Всего пользователей: {len(df_filtered['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тренировочной выборке: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тестовой выборке: {len(test_df['anon_id_encrypred'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c0cb7-b5be-49a9-ab82-e373f9229888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перцентили длин последовательностей:\n",
      "0.25      2.0\n",
      "0.50      4.0\n",
      "0.75     11.0\n",
      "0.90     26.0\n",
      "0.95     45.0\n",
      "0.99    116.0\n",
      "dtype: float64\n",
      "Максимальная длина последовательности: 1014\n"
     ]
    }
   ],
   "source": [
    "# Группируем по пользователям и считаем длину последовательности для каждого\n",
    "user_sequence_lengths = df_filtered.groupby('anon_id_encrypred').size()\n",
    "percentiles = user_sequence_lengths.quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "# Находим максимальную длину последовательности\n",
    "max_sequence_length = user_sequence_lengths.max()\n",
    "print(\"Перцентили длин последовательностей:\")\n",
    "print(percentiles)\n",
    "print(f\"Максимальная длина последовательности: {max_sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819bd52e-45a6-4cd9-b01f-78a5e1a7476d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример последовательности для пользователя \u0004\u000eqqwuysvt: [6, 7, 8, 9, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Создаём последовательности покупок для каждого пользователя\n",
    "train_sequences = train_df.groupby('anon_id_encrypred')['product_idx'].apply(list).to_dict()\n",
    "test_sequences = test_df.groupby('anon_id_encrypred')['product_idx'].apply(list).to_dict()\n",
    "\n",
    "# Проверяем пример последовательности для одного пользователя\n",
    "print(f\"Пример последовательности для пользователя {list(train_sequences.keys())[1]}: {train_sequences[list(train_sequences.keys())[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2714adc-e30b-4b91-924e-3087dd732895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: wyyypqqtprspstrs\n",
      "Input IDs: tensor([     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "         44837,  81049, 309344])\n",
      "Labels: tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 2557])\n",
      "Attention Mask: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "Position IDs: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# Параметры датасета\n",
    "max_len = 12          # Максимальная длина последовательности\n",
    "mask_prob = 0.2       # Вероятность маскирования\n",
    "num_items = df_filtered['product_idx'].nunique()  # Количество уникальных товаров\n",
    "\n",
    "# Преобразуем словари последовательностей в списки кортежей (user_id, sequence)\n",
    "train_sequences_list = list(train_sequences.items())\n",
    "test_sequences_list = list(test_sequences.items())\n",
    "\n",
    "# Создаем датасеты\n",
    "train_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = BERT4RecDataset(\n",
    "    sequences=test_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "# Создаем DataLoader для тренировочного и тестового датасетов\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Пример использования DataLoader\n",
    "for batch in train_loader:\n",
    "    user_ids = batch['user_id'][0]\n",
    "    input_ids = batch['input_ids'][0]\n",
    "    labels = batch['labels'][0]\n",
    "    attention_mask = batch['attention_mask'][0]\n",
    "    position_ids = batch['position_ids'][0]\n",
    "    \n",
    "    print(\"User ID:\", user_ids)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Position IDs:\", position_ids)\n",
    "    break  # Остановимся после первого батча для примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735c4fde-5420-49ab-b517-b5ac14a445de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecModel(nn.Module):\n",
    "    def __init__(self, num_items, max_len, embedding_dim=512, num_layers=6, num_heads=8, \n",
    "                 dropout=0.1, ffn_dim=2048):\n",
    "        super().__init__()\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Token Embeddings (+2 для pad и mask токенов)\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Позиционные энкодинги с LayerNorm\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Трансформерный энкодер с улучшенными параметрами\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Расширенная классифицирующая голова\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim*2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim*2),\n",
    "            nn.Linear(embedding_dim*2, num_items + 1)\n",
    "        )\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов как в оригинальном BERT\"\"\"\n",
    "        # Инициализация эмбеддингов\n",
    "        nn.init.normal_(self.item_embeddings.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.position_embeddings.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        # Инициализация слоев трансформера\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "            \n",
    "        # Инициализация классификатора\n",
    "        nn.init.xavier_uniform_(self.fc[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc[3].weight)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        # Эмбеддинги токенов\n",
    "        item_embeds = self.item_embeddings(input_ids)\n",
    "        \n",
    "        # Позиционные энкодинги\n",
    "        pos_embeds = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Комбинирование с нормализацией и дропаутом\n",
    "        embeddings = self.layer_norm(item_embeds + pos_embeds)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        # Создаем ключевую маску для трансформера\n",
    "        src_key_padding_mask = (attention_mask == 0)\n",
    "        \n",
    "        # Пропускаем через трансформер\n",
    "        transformer_output = self.transformer(\n",
    "            embeddings,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        \n",
    "        # Классификация\n",
    "        logits = self.fc(transformer_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197e78f4-b437-4234-966f-e10ea4a472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=5,\n",
    "    log_interval=50,  # Логировать каждые 50 батчей\n",
    "    save_path=\"best_model.pth\",\n",
    "):\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # игнорим паддинги и добавляем стохастики label_smoothing=0.1\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Для визуализации\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    batch_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Training, Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, batch in progress_bar_train:\n",
    "            # Перенос данных на устройство\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            position_ids = batch['position_ids'].to(device)\n",
    "            \n",
    "            # Forward и backward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, position_ids)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), \n",
    "                            labels.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Логирование\n",
    "            running_loss += loss.item()\n",
    "            if (batch_idx + 1) % log_interval == 0:\n",
    "                avg_loss = running_loss / log_interval\n",
    "                train_loss_history.append(avg_loss)\n",
    "                running_loss = 0.0\n",
    "                batch_counter += 1\n",
    "            \n",
    "            progress_bar_train.set_postfix(loss=loss.item())\n",
    "\n",
    "        # # Validation после эпохи\n",
    "        # model.eval()\n",
    "        # val_loss = 0.0\n",
    "        # progress_bar_val = tqdm(val_loader,  total=len(val_loader), desc=f'Validation, Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     for batch in progress_bar_val:\n",
    "        #         input_ids = batch['input_ids'].to(device)\n",
    "        #         labels = batch['labels'].to(device)\n",
    "        #         attention_mask = batch['attention_mask'].to(device)\n",
    "        #         position_ids = batch['position_ids'].to(device)\n",
    "                \n",
    "        #         outputs = model(input_ids, attention_mask, position_ids)\n",
    "        #         loss = criterion(outputs.view(-1, outputs.size(-1)), \n",
    "        #                         labels.view(-1))\n",
    "        #         val_loss += loss.item()\n",
    "                \n",
    "        #         # Обновляем прогресс-бар с текущим лоссом\n",
    "        #         progress_bar_val.set_postfix(val_loss=loss.item())\n",
    "        \n",
    "        # avg_val_loss = val_loss / len(val_loader)\n",
    "        # val_loss_history.append(avg_val_loss)\n",
    "        \n",
    "        # # Сохранение лучшей модели\n",
    "        # if avg_val_loss < best_loss:\n",
    "        #     best_loss = avg_val_loss\n",
    "        #     torch.save(model.state_dict(), save_path)\n",
    "        #     print(f\"New best model saved with val loss: {best_loss:.4f}\")\n",
    "    \n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5347caca-e80e-413c-8b1a-0963c5debeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4RecModel(\n",
    "    num_items=num_items,\n",
    "    max_len=max_len,\n",
    "    embedding_dim=256, # было 256\n",
    "    num_layers=3,       # Кол-во атеншн слоёв (Аттеншн + лин + нелин + дропаут)\n",
    "    num_heads=4,        # Головы аттеншн слоёв\n",
    "    dropout=0.01 # было 0.1\n",
    ").to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                             lr=1e-5, # Было 1e-4\n",
    "                             weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07196eb4-b595-40fd-b09d-e59cb716234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4RecModel(\n",
       "  (item_embeddings): Embedding(309345, 256, padding_idx=0)\n",
       "  (position_embeddings): Embedding(12, 256)\n",
       "  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.01, inplace=False)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.01, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.01, inplace=False)\n",
       "        (dropout2): Dropout(p=0.01, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=512, out_features=309344, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c20fc7a8-4bef-4b0a-aae7-6d1cad1448fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23fe58591cf48c9891690e6b25cb6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, Epoch 1/5:   0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6e9e420e424d91aa5e7e04c2e313c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, Epoch 2/5:   0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc26a3f92f5b4f19b2d036a87c7a23a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, Epoch 3/5:   0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d2fdf95fc441deb6f2aba824b817b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, Epoch 4/5:   0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d0f96873054d26805b37b76ad69a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, Epoch 5/5:   0%|          | 0/3790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=5,\n",
    "    log_interval=100,\n",
    "    save_path=\"bert4rec_best.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a2ee7e8-145a-4fc4-a4ff-2cc70adf7dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f8df30a1bb4c0ebcfb7772ec802632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "BERT4RecModel.forward() missing 2 required positional arguments: 'attention_mask' and 'position_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m LRFinder(model, optimizer, criterion)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Запуск поиска learning rate\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39mrange_test(train_iter, end_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Визуализация результатов\u001b[39;00m\n\u001b[1;32m     31\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py:317\u001b[0m, in \u001b[0;36mLRFinder.range_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`val_loader` has unsupported type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected types are `torch.utils.data.DataLoader`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor child of `ValDataLoaderIter`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(val_loader))\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_iter)):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# Train on batch and retrieve loss\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch(\n\u001b[1;32m    318\u001b[0m         train_iter,\n\u001b[1;32m    319\u001b[0m         accumulation_steps,\n\u001b[1;32m    320\u001b[0m         non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer,\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    323\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\n\u001b[1;32m    324\u001b[0m             val_iter, non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch_lr_finder/lr_finder.py:377\u001b[0m, in \u001b[0;36mLRFinder._train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    372\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_to_device(\n\u001b[1;32m    373\u001b[0m     inputs, labels, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    374\u001b[0m )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[1;32m    378\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Loss should be averaged in each step\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: BERT4RecModel.forward() missing 2 required positional arguments: 'attention_mask' and 'position_ids'"
     ]
    }
   ],
   "source": [
    "# from torch_lr_finder import TrainDataLoaderIter\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # игнорим паддинги\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), \n",
    "#                              # lr=1e-5, # Было 1e-4\n",
    "#                              weight_decay=0.01)\n",
    "\n",
    "# class CustomTrainDataLoaderIter(TrainDataLoaderIter):\n",
    "#     def inputs_labels_from_batch(self, batch_data):\n",
    "#         # Извлекаем данные из батча\n",
    "#         inputs = {\n",
    "#             'input_ids': batch_data['input_ids'],          # Input IDs\n",
    "#             'attention_mask': batch_data['attention_mask'], # Attention Mask\n",
    "#             'position_ids': batch_data['position_ids']     # Position IDs\n",
    "#         }\n",
    "#         labels = batch_data['labels']  # Labels\n",
    "#         return inputs, labels\n",
    "\n",
    "\n",
    "# # Создаем кастомный итератор\n",
    "# train_iter = CustomTrainDataLoaderIter(train_loader)\n",
    "\n",
    "# # Инициализация LRFinder\n",
    "# lr_finder = LRFinder(model, optimizer, criterion)\n",
    "\n",
    "# # Запуск поиска learning rate\n",
    "# lr_finder.range_test(train_iter, end_lr=0.1, num_iter=100)\n",
    "\n",
    "# # Визуализация результатов\n",
    "# lr_finder.plot()\n",
    "\n",
    "# # Сброс состояния модели\n",
    "# lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a58a7d43-42e0-4693-89a3-63edfb584c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = project_dir / 'models'\n",
    "\n",
    "torch.save(model.state_dict(), models_path / 'bert4rec_embedding_dim_256_num_layers_3_num_heads_4_dropout_001_lr_1e5_base.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a54de-a5fa-4d58-b984-bf0ebde0334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создаем экземпляр модели\n",
    "# model = BERT4RecModel(\n",
    "#     num_items=num_items,\n",
    "#     max_len=max_len,\n",
    "#     embedding_dim=256,\n",
    "#     num_layers=4,       # Кол-во атеншн слоёв (Аттеншн + лин + нелин + дропаут)\n",
    "#     num_heads=8,        # Головы аттеншн слоёв\n",
    "#     dropout=0.1\n",
    "# ).to(device)\n",
    "\n",
    "# # Загружаем веса\n",
    "# model.load_state_dict(torch.load(models_path / 'bert4rec_embedding_dim_256_num_layers_3_num_heads_4_dropout_001_lr_1e5_base.pth'))\n",
    "\n",
    "# # Переводим модель в режим оценки\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65030368-fcf7-46b0-996b-dd09dfc5205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses_full = []\n",
    "# val_losses_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03fba85a-a9b8-4d0d-b633-db8e83776cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "\n",
    "# train_losses_full.append(train_losses)\n",
    "# val_losses_full.append(val_losses)\n",
    "\n",
    "# # Flatten\n",
    "# train_losses_full = list(chain.from_iterable(train_losses_full))\n",
    "# val_losses_full = list(chain.from_iterable(val_losses_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "981420d9-a16e-420d-9e90-977ee915eef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train_loss(train_losses, log_interval, name='Loss Over Batches'):\n",
    "    \"\"\"\n",
    "    Визуализация train_losses.\n",
    "    \n",
    "    :param train_losses: Список значений потерь на тренировке.\n",
    "    :param log_interval: Интервал логирования (для корректной оси X).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Ось X: количество батчей\n",
    "    x = [i * log_interval for i in range(len(train_losses))]\n",
    "    \n",
    "    # Отрисовка графика\n",
    "    plt.plot(x, train_losses, label='Train Loss', marker='o', color='blue', linestyle='-', linewidth=2, markersize=5)\n",
    "    \n",
    "    # Настройки графика\n",
    "    plt.title(name, fontsize=16)\n",
    "    plt.xlabel('Batches', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Отображение графика\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования после обучения\n",
    "plot_train_loss(train_losses, log_interval=100, name='Training Loss Over Batches')\n",
    "# plot_train_loss(val_losses_full, log_interval=100, name='Validation Loss Over Batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45562441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cce8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preparing:   0%|          | 19/309343 [01:21<367:54:27,  4.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# df_filtered = pd.concat([train_df, test_df], ignore_index=True)  # если необходимо объединить\u001b[39;00m\n\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Предположим, что у вас уже есть df_filtered с нужными столбцами\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m product_meta_dict = \u001b[43mcompute_product_meta_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Количество уникальных товаров\u001b[39;00m\n\u001b[32m     84\u001b[39m num_items = df_filtered[\u001b[33m'\u001b[39m\u001b[33mproduct_idx\u001b[39m\u001b[33m'\u001b[39m].nunique()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mcompute_product_meta_features\u001b[39m\u001b[34m(df, meta_dim, device)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Извлекаем признаки изображения\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphoto_analytics\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     image = Image.open(BytesIO(response.content)).convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     59\u001b[39m     image = image_transform(image).unsqueeze(\u001b[32m0\u001b[39m).to(device)  \u001b[38;5;66;03m# переносим на нужное устройство\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Дополнительные импорты для работы с изображениями и текстом\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.set_per_process_memory_fraction(0.95)  # Ограничение памяти до 80%\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "#########################\n",
    "# 1. Предобработка метаданных\n",
    "#########################\n",
    "\n",
    "def compute_product_meta_features(df, meta_dim=128, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Вычисляет мета-вектор для каждого уникального продукта.\n",
    "    Используются признаки: brand, title, color_base, ktt1 (категория) и изображение из photo_analytics.\n",
    "    \"\"\"\n",
    "    # Инициализируем модель для текстовых эмбеддингов\n",
    "    text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Инициализируем предобученную модель для изображений (удаляем последний классификационный слой)\n",
    "    image_model = models.resnet18(pretrained=True)\n",
    "    image_model.fc = nn.Identity()\n",
    "    image_model = image_model.to(device)\n",
    "    image_model.eval()  # замораживаем веса для извлечения признаков\n",
    "    \n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    product_meta = {}\n",
    "    unique_products = df.drop_duplicates(subset=['product_idx'])\n",
    "    \n",
    "    for _, row in tqdm(unique_products.iterrows(), desc='Data preparing', total=unique_products.shape[0]):\n",
    "        product_idx = row['product_idx']\n",
    "        # Объединяем текстовые признаки\n",
    "        text_input = f\"{row['brand']} {row['title']} {row['color_base']} {row['ktt1']}\"\n",
    "        text_feat = text_model.encode(text_input, convert_to_tensor=True).to(device)\n",
    "        \n",
    "        # Извлекаем признаки изображения\n",
    "        try:\n",
    "            response = requests.get(row['photo_analytics'], timeout=5)\n",
    "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            image = image_transform(image).unsqueeze(0).to(device)  # переносим на нужное устройство\n",
    "            with torch.no_grad():\n",
    "                image_feat = image_model(image).squeeze(0)\n",
    "        except Exception as e:\n",
    "            # Если не удалось получить изображение, используем вектор нулей (размер 512)\n",
    "            image_feat = torch.zeros(512, device=device)\n",
    "        \n",
    "        # Конкатенируем текстовые и визуальные признаки\n",
    "        meta_feat = torch.cat([text_feat, image_feat], dim=0)\n",
    "        # Если размер полученного вектора не совпадает с meta_dim, применяем линейную проекцию\n",
    "        if meta_feat.shape[0] != meta_dim:\n",
    "            proj = nn.Linear(meta_feat.shape[0], meta_dim).to(device)\n",
    "            meta_feat = proj(meta_feat.unsqueeze(0)).squeeze(0)\n",
    "        product_meta[product_idx] = meta_feat\n",
    "    \n",
    "    return product_meta\n",
    "\n",
    "# Пример: объединяем train_df и test_df (или используем df_filtered, если он есть)\n",
    "import pandas as pd\n",
    "# df_filtered = pd.concat([train_df, test_df], ignore_index=True)  # если необходимо объединить\n",
    "\n",
    "# Предположим, что у вас уже есть df_filtered с нужными столбцами\n",
    "product_meta_dict = compute_product_meta_features(df_filtered, meta_dim=128)\n",
    "\n",
    "# Количество уникальных товаров\n",
    "num_items = df_filtered['product_idx'].nunique()\n",
    "\n",
    "# Формируем матрицу весов для мета-эмбеддингов размерности (num_items+2, meta_dim)\n",
    "# +2 для pad (индекс 0) и mask токена (индекс num_items+1)\n",
    "meta_dim = 128\n",
    "meta_weights = torch.zeros(num_items + 2, meta_dim)\n",
    "# Заполняем веса для индексов от 1 до num_items (предполагается, что product_idx начинается с 1)\n",
    "for idx in range(1, num_items + 1):\n",
    "    if idx in product_meta_dict:\n",
    "        meta_weights[idx] = product_meta_dict[idx]\n",
    "    else:\n",
    "        meta_weights[idx] = torch.zeros(meta_dim)\n",
    "# Для токена 0 (pad) и токена mask (num_items+1) оставляем нули\n",
    "\n",
    "#########################\n",
    "# 2. Модификация модели BERT4Rec\n",
    "#########################\n",
    "\n",
    "class BERT4RecModel(nn.Module):\n",
    "    def __init__(self, num_items, max_len, meta_embedding_weights, embedding_dim=512, num_layers=6, num_heads=8, \n",
    "                 dropout=0.1, ffn_dim=2048):\n",
    "        \"\"\"\n",
    "        Модель BERT4Rec с дополнительными метаданными продукта.\n",
    "        \n",
    "        :param num_items: количество уникальных товаров\n",
    "        :param max_len: максимальная длина последовательности\n",
    "        :param meta_embedding_weights: предвычисленная матрица мета-векторов (torch.Tensor) размером (num_items+2, meta_dim)\n",
    "        :param embedding_dim: размерность эмбеддингов товара\n",
    "        :param num_layers: количество слоёв трансформера\n",
    "        :param num_heads: количество голов внимания\n",
    "        :param dropout: dropout\n",
    "        :param ffn_dim: размерность FFN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Эмбеддинги товара (токены: индексы от 0 до num_items+1)\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Слой мета-эмбеддингов (инициализируется предвычисленными признаками)\n",
    "        meta_dim = meta_embedding_weights.shape[1]\n",
    "        self.meta_embedding = nn.Embedding(num_items + 2, meta_dim, padding_idx=0)\n",
    "        self.meta_embedding.weight = nn.Parameter(meta_embedding_weights, requires_grad=False)  # замораживаем или можно fine-tune\n",
    "        # Проекция объединённого представления (конкатенация item и meta признаков)\n",
    "        self.meta_proj = nn.Linear(embedding_dim + meta_dim, embedding_dim)\n",
    "        \n",
    "        # Позиционные эмбеддинги\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Трансформерный энкодер\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Классификационная голова\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim * 2),\n",
    "            nn.Linear(embedding_dim * 2, num_items + 1)  # +1 так как target начинается с 1\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Инициализация эмбеддингов и весов трансформера\n",
    "        nn.init.normal_(self.item_embeddings.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.position_embeddings.weight, mean=0.0, std=0.02)\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc[3].weight)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        # Эмбеддинги товара\n",
    "        item_embeds = self.item_embeddings(input_ids)\n",
    "        # Мета-эмбеддинги (дополнительная информация)\n",
    "        meta_embeds = self.meta_embedding(input_ids)\n",
    "        # Объединяем: конкатенируем и проецируем в embedding_dim\n",
    "        combined_embeds = torch.cat([item_embeds, meta_embeds], dim=-1)\n",
    "        combined_embeds = self.meta_proj(combined_embeds)\n",
    "        \n",
    "        # Позиционные эмбеддинги\n",
    "        pos_embeds = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Суммируем эмбеддинги и позиционные признаки, применяем LayerNorm и Dropout\n",
    "        embeddings = self.layer_norm(combined_embeds + pos_embeds)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        # Маска для паддингов\n",
    "        src_key_padding_mask = (attention_mask == 0)\n",
    "        \n",
    "        # Пропускаем через трансформер\n",
    "        transformer_output = self.transformer(embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Классификационная голова\n",
    "        logits = self.fc(transformer_output)\n",
    "        return logits\n",
    "\n",
    "#########################\n",
    "# 3. Остальной код обучения остаётся аналогичным\n",
    "#########################\n",
    "\n",
    "# Пример создания датасетов, DataLoader и тренировки (код у вас уже есть)\n",
    "# При этом BERT4RecDataset не меняется, поскольку последовательности остаются на уровне product_idx\n",
    "\n",
    "# Параметры\n",
    "max_len = 12          # Максимальная длина последовательности\n",
    "mask_prob = 0.2       # Вероятность маскирования\n",
    "batch_size = 64\n",
    "\n",
    "# Преобразуем словари последовательностей в список кортежей (user_id, sequence)\n",
    "train_sequences_list = list(train_sequences.items())\n",
    "test_sequences_list = list(test_sequences.items())\n",
    "\n",
    "# Создаём датасеты (ваш класс BERT4RecDataset не изменился)\n",
    "train_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = BERT4RecDataset(\n",
    "    sequences=test_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model = BERT4RecModel(\n",
    "    num_items=num_items,\n",
    "    max_len=max_len,\n",
    "    meta_embedding_weights=meta_weights,\n",
    "    embedding_dim=256,    # например, 256\n",
    "    num_layers=3,         # количество слоёв\n",
    "    num_heads=4,          # количество голов\n",
    "    dropout=0.01\n",
    ").to(device)\n",
    "\n",
    "# Настраиваем оптимизатор\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Функция тренировки (ваша, как ранее)\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=5,\n",
    "    log_interval=50,\n",
    "    save_path=\"best_model.pth\",\n",
    "):\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Training, Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, batch in progress_bar_train:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            position_ids = batch['position_ids'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, position_ids)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if (batch_idx + 1) % log_interval == 0:\n",
    "                avg_loss = running_loss / log_interval\n",
    "                train_loss_history.append(avg_loss)\n",
    "                running_loss = 0.0\n",
    "                progress_bar_train.set_postfix(loss=avg_loss)\n",
    "        \n",
    "        # Валидация (если нужно, можно раскомментировать)\n",
    "        # model.eval()\n",
    "        # val_loss = 0.0\n",
    "        # with torch.no_grad():\n",
    "        #     for batch in val_loader:\n",
    "        #         input_ids = batch['input_ids'].to(device)\n",
    "        #         labels = batch['labels'].to(device)\n",
    "        #         attention_mask = batch['attention_mask'].to(device)\n",
    "        #         position_ids = batch['position_ids'].to(device)\n",
    "        #         outputs = model(input_ids, attention_mask, position_ids)\n",
    "        #         loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "        #         val_loss += loss.item()\n",
    "        # avg_val_loss = val_loss / len(val_loader)\n",
    "        # val_loss_history.append(avg_val_loss)\n",
    "        # if avg_val_loss < best_loss:\n",
    "        #     best_loss = avg_val_loss\n",
    "        #     torch.save(model.state_dict(), save_path)\n",
    "        #     print(f\"New best model saved with val loss: {best_loss:.4f}\")\n",
    "    \n",
    "    return train_loss_history, val_loss_history\n",
    "\n",
    "# Запускаем обучение\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=5,\n",
    "    log_interval=100,\n",
    "    save_path=\"bert4rec_best.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee022bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920db365-8e6e-4865-a447-4ffb58880c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6033b24-76f5-4771-bbcf-b65828b1b4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c42a19b4-ec48-412d-a21b-748b9d7531d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для параллельной генерации рекомендаций (на входе батч из тестового DataLoader)\n",
    "def generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=6, device=device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        position_ids = position_ids.to(device)\n",
    "        \n",
    "        # Получаем выходы модели: [B, seq_len, num_items+1]\n",
    "        outputs = model(input_ids, attention_mask, position_ids)\n",
    "        # Берем логиты последнего токена (последний временной шаг)\n",
    "        logits = outputs[:, -1, :]  # размер [B, num_items+1]\n",
    "        # Выбираем топ-k рекомендаций для каждого примера\n",
    "        recs = torch.topk(logits, k=k, dim=-1).indices\n",
    "    return recs\n",
    "\n",
    "# Функция для последовательной генерации рекомендаций для одного пользователя\n",
    "def generate_sequential_recommendations(model, initial_sequence, max_len, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Генерирует последовательные рекомендации (авторегрессивно) для одного пользователя.\n",
    "    \n",
    "    :param initial_sequence: Исходная последовательность (список int) без паддинга.\n",
    "    :param max_len: Максимальная длина последовательности, с которой обучалась модель.\n",
    "    :param k: Количество генерируемых рекомендаций.\n",
    "    :param device: Устройство.\n",
    "    :return: Список сгенерированных рекомендаций.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated = []\n",
    "    current_seq = initial_sequence.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(k):\n",
    "            # Если длина последовательности меньше max_len – дополняем слева паддингом (значение 0)\n",
    "            if len(current_seq) < max_len:\n",
    "                padded_seq = [0] * (max_len - len(current_seq)) + current_seq\n",
    "            else:\n",
    "                padded_seq = current_seq[-max_len:]\n",
    "            \n",
    "            input_ids = torch.tensor(padded_seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            attention_mask = (input_ids != 0).long()\n",
    "            position_ids = torch.arange(max_len, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, position_ids)  # [1, max_len, num_items+1]\n",
    "            logits = outputs[:, -1, :]  # [1, num_items+1]\n",
    "            next_token = torch.topk(logits, k=1, dim=-1).indices.squeeze().item()\n",
    "            generated.append(next_token)\n",
    "            current_seq.append(next_token)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a46b59b3-6b92-48ce-a873-715d43d47d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel_inference(model, inference_loader, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Запускает инференс на inference_loader и получает топ-K рекомендаций для каждого пользователя.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec\n",
    "    :param inference_loader: DataLoader без маскированных токенов (данные из train)\n",
    "    :param k: Количество рекомендаций\n",
    "    :param device: Устройство (CPU/GPU)\n",
    "    :return: Список предсказанных рекомендаций для всех пользователей\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Parallel Inference\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            position_ids = batch[\"position_ids\"].to(device)\n",
    "\n",
    "            # Генерируем k рекомендаций\n",
    "            recs = generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=k, device=device)\n",
    "            \n",
    "            all_recommendations.extend(recs.cpu().tolist())\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "\n",
    "def run_sequential_inference(model, inference_loader, max_len, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Запускает последовательный инференс: для каждого пользователя из inference_loader извлекается исходная (непадённая) последовательность,\n",
    "    и генерируется последовательность рекомендаций методом авторегрессии.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec.\n",
    "    :param inference_loader: DataLoader с данными (is_train=False).\n",
    "    :param max_len: Максимальная длина последовательности.\n",
    "    :param k: Количество генерируемых рекомендаций для каждого пользователя.\n",
    "    :param device: Устройство.\n",
    "    :return: Словарь вида {user_id: [последовательность рекомендаций]}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    user_recs = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Sequential Inference\"):\n",
    "            input_ids = batch['input_ids']           # [B, max_len]\n",
    "            attention_mask = batch['attention_mask']   # [B, max_len]\n",
    "            user_ids = batch['user_id']                # список user_id\n",
    "            \n",
    "            # Для каждого пользователя в батче извлекаем исходную последовательность без паддинга\n",
    "            for i in range(input_ids.shape[0]):\n",
    "                # Переходим на CPU, чтобы легко работать со списками\n",
    "                seq = input_ids[i].cpu().tolist()\n",
    "                mask = attention_mask[i].cpu().tolist()\n",
    "                # Извлекаем только те токены, где mask==1 (непаддинговые элементы)\n",
    "                initial_seq = [token for token, m in zip(seq, mask) if m == 1]\n",
    "                recs = generate_sequential_recommendations(model, initial_seq, max_len, k=k, device=device)\n",
    "                user_recs[user_ids[i]] = recs\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87317aef-b821-4a5d-a03e-e43eb437bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем train-данные для генерации предсказаний\n",
    "inference_dataset = BERT4RecDataset(sequences=train_sequences_list, max_len=max_len, mask_prob=0.0, num_items=num_items, is_train=False)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c64e54-d85c-4360-8e34-795eddad8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_recommendations_to_users(user_ids, recommendations):\n",
    "    \"\"\"\n",
    "    Преобразует список рекомендаций в словарь {user_id: recommendations}.\n",
    "\n",
    "    :param user_ids: Список ID пользователей из inference_loader\n",
    "    :param recommendations: Список рекомендаций из parallel_recs\n",
    "    :return: Словарь {user_id: [recommendations]}\n",
    "    \"\"\"\n",
    "    user_to_recs = {user: recs for user, recs in zip(user_ids, recommendations)}\n",
    "    return user_to_recs\n",
    "\n",
    "# Получаем список пользователей из inference_loader\n",
    "user_ids = inference_loader.dataset.user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e673eef-f9b2-40e3-847e-d6856c4bd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параллельные предсказания (Batch Inference)\n",
    "parallel_recs = run_parallel_inference(model, inference_loader, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_parallel_recs = map_recommendations_to_users(user_ids, parallel_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815bdfe-b39f-4947-b7f4-6ab29f00735d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cdb0d477a142b384762265dc7e67a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sequential Inference:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Параллельные предсказания (Batch Inference)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# parallel_recs = run_parallel_inference(model, inference_loader, k=k, device=device)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Последовательные предсказания (Sequential Inference)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m sequential_recs \u001b[38;5;241m=\u001b[39m run_sequential_inference(model, inference_loader, max_len\u001b[38;5;241m=\u001b[39mmax_len, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[125], line 56\u001b[0m, in \u001b[0;36mrun_sequential_inference\u001b[1;34m(model, inference_loader, max_len, k, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;66;03m# Извлекаем только те токены, где mask==1 (непаддинговые элементы)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             initial_seq \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(seq, mask) \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 56\u001b[0m             recs \u001b[38;5;241m=\u001b[39m generate_sequential_recommendations(model, initial_seq, max_len, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     57\u001b[0m             user_recs[user_ids[i]] \u001b[38;5;241m=\u001b[39m recs\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_recs\n",
      "Cell \u001b[1;32mIn[124], line 44\u001b[0m, in \u001b[0;36mgenerate_sequential_recommendations\u001b[1;34m(model, initial_sequence, max_len, k, device)\u001b[0m\n\u001b[0;32m     41\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m (input_ids \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     42\u001b[0m position_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(max_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask, position_ids)  \u001b[38;5;66;03m# [1, max_len, num_items+1]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# [1, num_items+1]\u001b[39;00m\n\u001b[0;32m     46\u001b[0m next_token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(logits, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 72\u001b[0m, in \u001b[0;36mBERT4RecModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids)\u001b[0m\n\u001b[0;32m     69\u001b[0m src_key_padding_mask \u001b[38;5;241m=\u001b[39m (attention_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Пропускаем через трансформер\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m     73\u001b[0m     embeddings,\n\u001b[0;32m     74\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Классификация\u001b[39;00m\n\u001b[0;32m     78\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(transformer_output)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(\n\u001b[0;32m    512\u001b[0m         output,\n\u001b[0;32m    513\u001b[0m         src_mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    514\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m    515\u001b[0m         src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers,\n\u001b[0;32m    516\u001b[0m     )\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:871\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_sparsity_fast_path:\n\u001b[0;32m    868\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mmerge_masks(\n\u001b[0;32m    869\u001b[0m             src_mask, src_key_padding_mask, src\n\u001b[0;32m    870\u001b[0m         )\n\u001b[1;32m--> 871\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_transformer_encoder_layer_fwd(\n\u001b[0;32m    872\u001b[0m             src,\n\u001b[0;32m    873\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[0;32m    874\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m    875\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39min_proj_weight,\n\u001b[0;32m    876\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m    877\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    878\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    879\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_relu_or_gelu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    880\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first,\n\u001b[0;32m    881\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    883\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    884\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    885\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    886\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    887\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    888\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    889\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    890\u001b[0m             merged_mask,\n\u001b[0;32m    891\u001b[0m             mask_type,\n\u001b[0;32m    892\u001b[0m         )\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\u001b[39;00m\n\u001b[0;32m    895\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Последовательные предсказания (Sequential Inference)\n",
    "sequential_recs = run_sequential_inference(model, inference_loader, max_len=max_len, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_sequential_recs = map_recommendations_to_users(user_ids, sequential_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87f0810d-990a-4a77-b949-a4b4eec3cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bert4rec_classic_parallel = RecommendationDataset(user_recommendations=test_user_to_parallel_recs, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_bert4rec_classic_parallel, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5395d665-4a56-4e4f-81dd-06def694b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef7b699571b48ddbf1489336e28721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b1a05b31af41afb59943ba10380b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.003697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1e89860b7b407391803f87c3fcd243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a079a86ca844dc853ab43b69ef59f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m map_k \u001b[38;5;241m=\u001b[39m map_at_k_gpu(loader\u001b[38;5;241m=\u001b[39mloader, k\u001b[38;5;241m=\u001b[39mk, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAP@k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap_k\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m ndcg_k \u001b[38;5;241m=\u001b[39m ndcg_at_k_gpu(loader\u001b[38;5;241m=\u001b[39mloader, k\u001b[38;5;241m=\u001b[39mk, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDCG@k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndcg_k\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[62], line 144\u001b[0m, in \u001b[0;36mndcg_at_k_gpu\u001b[1;34m(loader, k, batch_size, device)\u001b[0m\n\u001b[0;32m    141\u001b[0m         dcg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# IDCG@K\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m ideal_dcg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_items[i]), k)))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# NDCG@K\u001b[39;00m\n\u001b[0;32m    147\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m dcg \u001b[38;5;241m/\u001b[39m ideal_dcg \u001b[38;5;28;01mif\u001b[39;00m ideal_dcg \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[62], line 144\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m         dcg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# IDCG@K\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m ideal_dcg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_items[i]), k)))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# NDCG@K\u001b[39;00m\n\u001b[0;32m    147\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m dcg \u001b[38;5;241m/\u001b[39m ideal_dcg \u001b[38;5;28;01mif\u001b[39;00m ideal_dcg \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861c6ad-fefb-4c45-95d6-d06ec7672a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_results(model_name='Top-K', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874983a0-b07a-4d94-abf5-03b291ef2dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdc972e-b2cd-48d8-b819-af4028a7d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps:\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4741a-4e39-4ca4-8b4d-d29256befedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea101faa-5d2b-44f3-8046-3fbe91144118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca21a7-500f-4abd-9b36-14ce26723bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c64661-6729-4f2e-98bd-acfb01327fdc",
   "metadata": {},
   "source": [
    "### BERT4Rec Git version\n",
    "https://github.com/asash/bert4rec_repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74766d03-ad72-4914-b4a4-6c9e1569aa18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
