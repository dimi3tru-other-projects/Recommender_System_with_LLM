{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b461584d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b4696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.9) # Memory usage limit for MacOS\n",
    "    torch.mps.empty_cache() \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ebaea",
   "metadata": {},
   "source": [
    "#### For cleaning memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7a4dda-0964-49d1-8812-6c0bb98246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931cb14-3e62-4c69-b4cc-b034940382c2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78231942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, user_recommendations, user_to_true_items, k):\n",
    "        self.recommendations = [torch.LongTensor(recs[:k]) for recs in user_recommendations.values()]\n",
    "        self.true_items = [torch.LongTensor(list(user_to_true_items.get(u, []))) for u in user_recommendations.keys()]\n",
    "        self.true_len = [len(t) for t in self.true_items] \n",
    "        self.k = k\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.true_items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'recs': self.recommendations[idx], \n",
    "            'true': self.true_items[idx],\n",
    "            'true_len': self.true_len[idx]\n",
    "        }\n",
    "    \n",
    "\n",
    "def collate_fn(batch, device='mps'):\n",
    "    \"\"\"\n",
    "    Собираем батч целиком в тензоры, чтобы все метрики считались\n",
    "    без питоновских циклов (vectorized GPU).\n",
    "    Возвращаем:\n",
    "        recs      – LongTensor [B, k]\n",
    "        true      – LongTensor [B, L_max] (padding = -1)\n",
    "        true_len  – LongTensor [B]        (длина истинного списка)\n",
    "    \"\"\"\n",
    "    recs = torch.stack([item['recs'] for item in batch])          # [B, k]\n",
    "    true_len = torch.tensor([item['true_len'] for item in batch], dtype=torch.long)\n",
    "    L_max = int(true_len.max()) if true_len.numel() else 0\n",
    "    true_pad = torch.full((len(batch), L_max), -1, dtype=torch.long)  # -1: sentinel\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        if true_len[i]:\n",
    "            true_pad[i, :true_len[i]] = item['true']\n",
    "\n",
    "    return {\n",
    "        'recs': recs.to(device),\n",
    "        'true': true_pad.to(device),\n",
    "        'true_len': true_len.to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb74048",
   "metadata": {},
   "source": [
    "## Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bd4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path().resolve() # Path(__file__).resolve()\n",
    "project_dir = file_path.parent\n",
    "raw_data_path = project_dir / 'data' / 'raw'\n",
    "products_data_dir = project_dir / 'data' / 'processed' / 'products_data'\n",
    "interim_data_dir = project_dir / 'data' / 'interim'\n",
    "models_outputs_dir = project_dir / 'data' / 'processed' / 'models_outputs'\n",
    "models_dir = project_dir / 'models'\n",
    "processed_images_dir = products_data_dir / 'processed_images_224x224'\n",
    "products_data_file = products_data_dir / 'products_data.parquet'\n",
    "\n",
    "raw_data_path.mkdir(parents=True, exist_ok=True)\n",
    "products_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "interim_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_images_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc17ce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "      <th>sales_total</th>\n",
       "      <th>image_path</th>\n",
       "      <th>CLS_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>mean_patch_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_google_vit_huge_patch14_224_in21k</th>\n",
       "      <th>pooled_microsoft_resnet50</th>\n",
       "      <th>CLS_openai_clip_vit_large_patch14</th>\n",
       "      <th>mean_patch_openai_clip_vit_large_patch14</th>\n",
       "      <th>pooled_openai_clip_vit_large_patch14</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding_e5_large_v2</th>\n",
       "      <th>embedding_bge_large_en_v15</th>\n",
       "      <th>embedding_nomic_embed_text_v15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306670</th>\n",
       "      <td>wqsvuwy</td>\n",
       "      <td>Разноцветный</td>\n",
       "      <td>Lancel</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Аксессуары</td>\n",
       "      <td>Платки</td>\n",
       "      <td>Платок шелковый</td>\n",
       "      <td>Шелковый платок</td>\n",
       "      <td>13567982</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>6027468-shelkovyi-platok-lancel-raznotcvetnyi-...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/f5/9...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[0.14456921815872192, -0.06249238923192024, -0...</td>\n",
       "      <td>[0.013126503676176071, -0.0019127298146486282,...</td>\n",
       "      <td>[0.22613008320331573, 0.1457078456878662, -0.1...</td>\n",
       "      <td>[0.030423777177929878, 0.0, 0.0, 0.08489743620...</td>\n",
       "      <td>[0.15574012696743011, -0.3459433317184448, 0.6...</td>\n",
       "      <td>[0.6875616312026978, 0.6793960332870483, 0.354...</td>\n",
       "      <td>[0.42158013582229614, 0.2945811450481415, 0.35...</td>\n",
       "      <td>This Lancel silk scarf features shades of blue...</td>\n",
       "      <td>[0.02612929418683052, -0.05050811171531677, 0....</td>\n",
       "      <td>[-0.020242616534233093, -0.01976708509027958, ...</td>\n",
       "      <td>[0.01306484080851078, 0.022184912115335464, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306671</th>\n",
       "      <td>ttquswt</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>Giorgio Armani</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Бижутерия</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>Брошь</td>\n",
       "      <td>11201309</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>5504265-brosh-giorgio-armani-chernyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/76/...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>/Users/dimi3tru/Downloads/Downloads/my_python_...</td>\n",
       "      <td>[-0.12436471879482269, -0.030923746526241302, ...</td>\n",
       "      <td>[-0.01337357982993126, -0.0029991380870342255,...</td>\n",
       "      <td>[-0.09756504744291306, -0.15952929854393005, 0...</td>\n",
       "      <td>[0.03119073063135147, 0.0002419875527266413, 0...</td>\n",
       "      <td>[0.5343070030212402, 0.26047518849372864, 0.37...</td>\n",
       "      <td>[0.7018769979476929, 0.5926704406738281, 0.369...</td>\n",
       "      <td>[0.2984030842781067, 0.4144335687160492, -0.12...</td>\n",
       "      <td>This item is a black brooch from Giorgio Arman...</td>\n",
       "      <td>[0.013706686906516552, -0.061785973608493805, ...</td>\n",
       "      <td>[-0.029468011111021042, 0.002113671973347664, ...</td>\n",
       "      <td>[0.03772303834557533, 0.08191631734371185, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       articul_encrypred    color_base           brand               ktt1  \\\n",
       "306670           wqsvuwy  Разноцветный          Lancel  Товары для женщин   \n",
       "306671           ttquswt        Чёрный  Giorgio Armani  Товары для женщин   \n",
       "\n",
       "              ktt2    ktt3             ktt4            title  product_id  \\\n",
       "306670  Аксессуары  Платки  Платок шелковый  Шелковый платок    13567982   \n",
       "306671   Бижутерия   Брошь            Брошь            Брошь    11201309   \n",
       "\n",
       "       product_created_at                                               slug  \\\n",
       "306670         2020-06-25  6027468-shelkovyi-platok-lancel-raznotcvetnyi-...   \n",
       "306671         2016-07-26               5504265-brosh-giorgio-armani-chernyi   \n",
       "\n",
       "                                          photo_analytics  sales_total  \\\n",
       "306670  https://st-cdn.tsum.com/int/height/1526/i/f5/9...         0.01   \n",
       "306671  https://st-cdn.tsum.com/int/height/1526//i/76/...         0.01   \n",
       "\n",
       "                                               image_path  \\\n",
       "306670  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "306671  /Users/dimi3tru/Downloads/Downloads/my_python_...   \n",
       "\n",
       "                    CLS_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.14456921815872192, -0.06249238923192024, -0...   \n",
       "306671  [-0.12436471879482269, -0.030923746526241302, ...   \n",
       "\n",
       "             mean_patch_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.013126503676176071, -0.0019127298146486282,...   \n",
       "306671  [-0.01337357982993126, -0.0029991380870342255,...   \n",
       "\n",
       "                 pooled_google_vit_huge_patch14_224_in21k  \\\n",
       "306670  [0.22613008320331573, 0.1457078456878662, -0.1...   \n",
       "306671  [-0.09756504744291306, -0.15952929854393005, 0...   \n",
       "\n",
       "                                pooled_microsoft_resnet50  \\\n",
       "306670  [0.030423777177929878, 0.0, 0.0, 0.08489743620...   \n",
       "306671  [0.03119073063135147, 0.0002419875527266413, 0...   \n",
       "\n",
       "                        CLS_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.15574012696743011, -0.3459433317184448, 0.6...   \n",
       "306671  [0.5343070030212402, 0.26047518849372864, 0.37...   \n",
       "\n",
       "                 mean_patch_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.6875616312026978, 0.6793960332870483, 0.354...   \n",
       "306671  [0.7018769979476929, 0.5926704406738281, 0.369...   \n",
       "\n",
       "                     pooled_openai_clip_vit_large_patch14  \\\n",
       "306670  [0.42158013582229614, 0.2945811450481415, 0.35...   \n",
       "306671  [0.2984030842781067, 0.4144335687160492, -0.12...   \n",
       "\n",
       "                                              description  \\\n",
       "306670  This Lancel silk scarf features shades of blue...   \n",
       "306671  This item is a black brooch from Giorgio Arman...   \n",
       "\n",
       "                                    embedding_e5_large_v2  \\\n",
       "306670  [0.02612929418683052, -0.05050811171531677, 0....   \n",
       "306671  [0.013706686906516552, -0.061785973608493805, ...   \n",
       "\n",
       "                               embedding_bge_large_en_v15  \\\n",
       "306670  [-0.020242616534233093, -0.01976708509027958, ...   \n",
       "306671  [-0.029468011111021042, 0.002113671973347664, ...   \n",
       "\n",
       "                           embedding_nomic_embed_text_v15  \n",
       "306670  [0.01306484080851078, 0.022184912115335464, -0...  \n",
       "306671  [0.03772303834557533, 0.08191631734371185, -0....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_products = pd.read_parquet(products_data_file)\n",
    "df_products.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c93e89",
   "metadata": {},
   "source": [
    "There are some broken URLs — we remove these items from our dataset.\n",
    "\n",
    "![alt text](../junk/broken_urls.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c40ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows initially: 306672\n",
      "Number of rows with at least one missing value: 8\n",
      "Number of rows after cleaning: 306664\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of rows initially: {df_products.shape[0]}')\n",
    "print(f'Number of rows with at least one missing value: {df_products[df_products.isna().any(axis=1)].shape[0]}')\n",
    "\n",
    "df_products.dropna(inplace=True)\n",
    "print(f'Number of rows after cleaning: {df_products.shape[0]}')\n",
    "\n",
    "# df_products.to_parquet(interim_data_dir / 'df_products.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b125a",
   "metadata": {},
   "source": [
    "## Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0547cd-2267-4636-b82d-752f33e3c2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>sizeid</th>\n",
       "      <th>size_title</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>base_price</th>\n",
       "      <th>net_price</th>\n",
       "      <th>sale_percentage</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3485910</th>\n",
       "      <td>wyyypqqtpqqyuqqx</td>\n",
       "      <td>vqquspp</td>\n",
       "      <td>Чёрный</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>Dolce&amp;Gabbana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда верхняя</td>\n",
       "      <td>Жилеты</td>\n",
       "      <td>Утепленный жилет</td>\n",
       "      <td>13627178</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>124500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7004211-uteplennyi-zhilet-dolce-gabbana-chernyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/ad/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485911</th>\n",
       "      <td>wyyyrqqtqqrruyyp</td>\n",
       "      <td>vqsywtp</td>\n",
       "      <td>Серый</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>T</td>\n",
       "      <td>The Attico</td>\n",
       "      <td>Товары для женщин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда джинсовая</td>\n",
       "      <td>Куртка джинсовая</td>\n",
       "      <td>Джинсовая куртка</td>\n",
       "      <td>13661506</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>238500.0</td>\n",
       "      <td>222965.8</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>7028651-dzhinsovaya-kurtka-the-attico-temno-seryi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526/i/7c/7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred color_base sizeid size_title  \\\n",
       "3485910  wyyypqqtpqqyuqqx           vqquspp     Чёрный     48         48   \n",
       "3485911  wyyyrqqtqqrruyyp           vqsywtp      Серый     40         42   \n",
       "\n",
       "         order_date store          brand               ktt1    ktt2  \\\n",
       "3485910  2021-02-18     T  Dolce&Gabbana  Товары для мужчин  Одежда   \n",
       "3485911  2021-02-18     T     The Attico  Товары для женщин  Одежда   \n",
       "\n",
       "                     ktt3              ktt4             title  product_id  \\\n",
       "3485910    Одежда верхняя            Жилеты  Утепленный жилет    13627178   \n",
       "3485911  Одежда джинсовая  Куртка джинсовая  Джинсовая куртка    13661506   \n",
       "\n",
       "        product_created_at  base_price  net_price  sale_percentage  \\\n",
       "3485910         2020-10-21    124500.0   124500.0         0.000000   \n",
       "3485911         2021-02-01    238500.0   222965.8         0.065133   \n",
       "\n",
       "                                                      slug  \\\n",
       "3485910    7004211-uteplennyi-zhilet-dolce-gabbana-chernyi   \n",
       "3485911  7028651-dzhinsovaya-kurtka-the-attico-temno-seryi   \n",
       "\n",
       "                                           photo_analytics  \n",
       "3485910  https://st-cdn.tsum.com/int/height/1526/i/ad/b...  \n",
       "3485911  https://st-cdn.tsum.com/int/height/1526/i/7c/7...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_parsed = pd.read_csv(raw_data_path / 'all.csv', sep=';')\n",
    "# df_sales = pd.read_csv(raw_data_path / 'all_orders_encrypted_2020_small_30012024_3.csv', sep=',')\n",
    "# df_assortment = pd.read_csv(raw_data_path / 'tsum_assortment_31012025.csv', sep=',')\n",
    "df_sales = pd.read_csv(raw_data_path / 'full_orders_v6.csv', sep=None, engine='python')\n",
    "\n",
    "# display(df_parsed.tail(2), df_sales.tail(2), df_assortment.tail(2), df_sales.tail(2))\n",
    "df_sales.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64930a5f",
   "metadata": {},
   "source": [
    "Keep only the products that are present in the df_products dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be25e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique 'articul_encrypred' values — df_sales: 234460, df_products: 228219\n",
      "Unique 'product_id' values — df_sales: 314113, df_products: 306664\n",
      "\n",
      "Unique 'articul_encrypred' values (after filtering) — df_sales: 228219, df_products: 228219\n",
      "Unique 'product_id' values (after filtering) — df_sales: 306664, df_products: 306664\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique 'articul_encrypred' values — df_sales: {len(df_sales['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "print(f\"Unique 'product_id' values — df_sales: {len(df_sales['product_id'].unique())}, df_products: {len(df_products['product_id'].unique())}\")\n",
    "\n",
    "df_sales = df_sales.merge(\n",
    "    df_products[['articul_encrypred', 'product_id']],\n",
    "    on=['articul_encrypred', 'product_id'],\n",
    "    how='inner'\n",
    ")\n",
    "print()\n",
    "print(f\"Unique 'articul_encrypred' values (after filtering) — df_sales: {len(df_sales['articul_encrypred'].unique())}, df_products: {len(df_products['articul_encrypred'].unique())}\")\n",
    "print(f\"Unique 'product_id' values (after filtering) — df_sales: {len(df_sales['product_id'].unique())}, df_products: {len(df_products['product_id'].unique())}\")\n",
    "\n",
    "# df_sales.to_parquet(interim_data_dir / 'df_sales.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d6e91c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.to_parquet(interim_data_dir / 'df_sales.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3df99b-df71-4157-8c56-0825361a43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_purchase_days_per_user = 100  # Maximum number of purchase days allowed per user (a purchase = unique user-day pair)\n",
    "# min_purchases_per_user = 2       # Minimum number of purchases required per user (a purchase = user-item interaction)\n",
    "\n",
    "# # Exclude \"resellers\" — users with too many unique purchase days (e.g., buying 5 items on 1 day = 1 purchase)\n",
    "# purchase_days = df_sales.groupby('anon_id_encrypred')['order_date'].nunique().reset_index()\n",
    "# purchase_days.columns = ['anon_id_encrypred', 'unique_purchase_days']\n",
    "# resellers = purchase_days[purchase_days['unique_purchase_days'] > max_purchase_days_per_user]['anon_id_encrypred']\n",
    "\n",
    "# # Exclude users with too few purchases (e.g., buying 5 items on 1 day = 5 purchases)\n",
    "# user_purchase_counts = df_sales['anon_id_encrypred'].value_counts()\n",
    "\n",
    "# df_sales = (df_sales[~df_sales['anon_id_encrypred'].isin(resellers)]\n",
    "#                [df_sales['anon_id_encrypred'].isin(user_purchase_counts[user_purchase_counts >= min_purchases_per_user].index)]\n",
    "#            ).reset_index(drop=True)\n",
    "\n",
    "# df_sales.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c3fb1-d990-47f8-a8e3-aa0ff9260640",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76daa2ba-dbc4-43d1-b2f2-7217b2d6007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Precision@K for batched recommendation results using GPU.\n",
    "    '''\n",
    "    precision_sum, total_users = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Precision@K'):\n",
    "            recs = batch['recs'][:, :k]     # [B, k]\n",
    "            true_pad = batch['true']            # [B, L]\n",
    "            true_len = batch['true_len']        # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True, если рек попал в true\n",
    "            # torch.isin делает попарное «==» и даёт bool-тензор [B, k, L]; .any(-1) схлопывает последнюю ось, говоря «есть ли совпадение хотя бы с одним true-item\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1), # [B, k, 1], превращаем [B, k] → [B, k, 1] (добавляем фиктивную ось)\n",
    "            #     true_pad.unsqueeze(1) # [B, 1, L_max], [B, L] → [B, 1, L_max]\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin с ANY некорректно работают на MPS (на CUDA и CPU, даже макбука CPU всё нормально)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)           \n",
    "\n",
    "            hits_cnt = hits_mask.sum(1).float() # [B], считаем True в каждой строке сколько рекомендаций оказались релевантны\n",
    "            denom = torch.minimum(true_len.clamp(min=1).float(), torch.tensor(k, device=device)) # берём min(k, true_len) — если у пользователя меньше реальных товаров, чем k, не штрафуем его\n",
    "            precision = hits_cnt / denom\n",
    "\n",
    "            precision_sum += precision.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return precision_sum / total_users\n",
    "    \n",
    "\n",
    "def recall_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Recall@K for batched recommendation results using GPU.\n",
    "    '''\n",
    "    recall_sum, total_users = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Recall@K'):\n",
    "            recs      = batch['recs'][:, :k]      # [B, k]  топ-k рекомендаций\n",
    "            true_pad  = batch['true']             # [B, L]  true-items, паддинг = -1\n",
    "            true_len  = batch['true_len']         # [B]     длины true-списков\n",
    "\n",
    "            # hits_mask: [B, k] – True, если рек попал в true\n",
    "            # torch.isin делает попарное «==» и даёт bool-тензор [B, k, L]; .any(-1) схлопывает последнюю ось, говоря «есть ли совпадение хотя бы с одним true-item\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1), # [B, k, 1], превращаем [B, k] → [B, k, 1] (добавляем фиктивную ось)\n",
    "            #     true_pad.unsqueeze(1) # [B, 1, L_max], [B, L] → [B, 1, L_max]\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin с ANY некорректно работают на MPS (на CUDA и CPU, даже макбука CPU всё нормально)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            hits_cnt = hits_mask.sum(1).float()    # [B]  сколько релевантных рекомендаций\n",
    "\n",
    "            # recall = hits / |true|; пользователей без true-items пропускаем\n",
    "            valid_mask = true_len > 0              # [B]  bool\n",
    "            recall = torch.zeros_like(hits_cnt)\n",
    "            recall[valid_mask] = hits_cnt[valid_mask] / true_len[valid_mask].float()\n",
    "\n",
    "            recall_sum  += recall.sum().item()\n",
    "            total_users += valid_mask.sum().item()\n",
    "\n",
    "    return recall_sum / total_users\n",
    "    \n",
    "\n",
    "def map_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Mean Average Precision (MAP@K) for batched recommendation results using GPU.\n",
    "    '''\n",
    "    map_sum, total_users = 0.0, 0\n",
    "    positions = (torch.arange(k, device=device).float() + 1)  # [1 … k]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='MAP@K'):\n",
    "            recs      = batch['recs'][:, :k]      # [B, k]\n",
    "            true_pad  = batch['true']             # [B, L]\n",
    "            true_len  = batch['true_len']         # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True, если рек попал в true\n",
    "            # torch.isin делает попарное «==» и даёт bool-тензор [B, k, L]; .any(-1) схлопывает последнюю ось, говоря «есть ли совпадение хотя бы с одним true-item\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1), # [B, k, 1], превращаем [B, k] → [B, k, 1] (добавляем фиктивную ось)\n",
    "            #     true_pad.unsqueeze(1) # [B, 1, L_max], [B, L] → [B, 1, L_max]\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin с ANY некорректно работают на MPS (на CUDA и CPU, даже макбука CPU всё нормально)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            # cum_hits: сколько релевантов встретили до позиции j\n",
    "            cum_hits  = torch.cumsum(hits_mask.float(), dim=1)   # [B, k]\n",
    "\n",
    "            # precisions@j считаем только в точках-хитах\n",
    "            precisions = (cum_hits * hits_mask.float()) / positions  # [B, k]\n",
    "\n",
    "            # AP = сумма precisions / min(|true|, k)\n",
    "            denom = torch.minimum(\n",
    "                true_len.clamp(min=1).float(),\n",
    "                torch.tensor(k, device=device)\n",
    "            )                                                     # [B]\n",
    "            ap = precisions.sum(1) / denom                        # [B]\n",
    "\n",
    "            map_sum += ap.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return map_sum / total_users\n",
    "\n",
    "\n",
    "def ndcg_at_k_gpu(loader, k=10, device=device):\n",
    "    '''\n",
    "    Computes Normalized Discounted Cumulative Gain (NDCG@K) for batched recommendation results using GPU.\n",
    "    '''\n",
    "    ndcg_sum, total_users = 0.0, 0\n",
    "    discount = 1.0 / torch.log2(torch.arange(k, device=device).float() + 2)  # [1/log2(i+2)]\n",
    "    ideal_cum = torch.cumsum(discount, dim=0)                                # префикс-сумма для IDCG\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='NDCG@K'):\n",
    "            recs = batch['recs'][:, :k]   # [B, k]\n",
    "            true_pad = batch['true']          # [B, L]\n",
    "            true_len = batch['true_len']      # [B]\n",
    "\n",
    "            # hits_mask: [B, k] – True, если рек попал в true\n",
    "            # torch.isin делает попарное «==» и даёт bool-тензор [B, k, L]; .any(-1) схлопывает последнюю ось, говоря «есть ли совпадение хотя бы с одним true-item\n",
    "            # hits_mask = torch.isin(\n",
    "            #     recs.unsqueeze(-1), # [B, k, 1], превращаем [B, k] → [B, k, 1] (добавляем фиктивную ось)\n",
    "            #     true_pad.unsqueeze(1) # [B, 1, L_max], [B, L] → [B, 1, L_max]\n",
    "            # ).any(-1)\n",
    "\n",
    "            # !!! torch.isin с ANY некорректно работают на MPS (на CUDA и CPU, даже макбука CPU всё нормально)\n",
    "            hits_mask = (recs.unsqueeze(-1) == true_pad.unsqueeze(1)).any(-1)     \n",
    "\n",
    "            # DCG: суммируем discounted gain для каждого попадания\n",
    "            dcg = (hits_mask.float() * discount).sum(1)   # [B]\n",
    "\n",
    "            # IDCG: максимум возможного DCG при идеальной сортировке\n",
    "            idcg_len = torch.minimum(true_len, torch.tensor(k, device=device))  # [B]\n",
    "            idcg = torch.zeros_like(dcg)\n",
    "            idcg[idcg_len > 0] = ideal_cum[idcg_len[idcg_len > 0] - 1]\n",
    "\n",
    "            # NDCG = DCG / IDCG  (0, если idcg == 0)\n",
    "            ndcg = torch.where(idcg > 0, dcg / idcg, torch.zeros_like(dcg))\n",
    "\n",
    "            ndcg_sum += ndcg.sum().item()\n",
    "            total_users += recs.size(0)\n",
    "\n",
    "    return ndcg_sum / total_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a47c837-d7ec-4526-ae3b-f39c8a630f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_results(model_name, precision_k, recall_k, map_k, ndcg_k, k, hyperparameters=None, round_level=4):\n",
    "    '''\n",
    "    Appends model evaluation results to the dataframe.\n",
    "    \n",
    "    model_name: str – name of the model\n",
    "    precision_k, recall_k, map_k, ndcg_k: torch.Tensor or float – evaluation metrics\n",
    "    k: int – value of K used in metrics\n",
    "    hyperparameters: dict – model hyperparameters (optional)\n",
    "    round_level: int – number of decimal places to round to (default is 4)\n",
    "    '''\n",
    "    global df_metrics\n",
    "    \n",
    "    # Convert tensors to floats and round them (if they are tensors)\n",
    "    precision_k = round(precision_k.item() if isinstance(precision_k, torch.Tensor) else precision_k, round_level)\n",
    "    recall_k = round(recall_k.item() if isinstance(recall_k, torch.Tensor) else recall_k, round_level)\n",
    "    map_k = round(map_k.item() if isinstance(map_k, torch.Tensor) else map_k, round_level)\n",
    "    ndcg_k = round(ndcg_k.item() if isinstance(ndcg_k, torch.Tensor) else ndcg_k, round_level)\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'k': k,\n",
    "        'Precision@k': precision_k,\n",
    "        'Recall@k': recall_k,\n",
    "        'MAP@k': map_k,\n",
    "        'NDCG@k': ndcg_k,\n",
    "        'Other_hyperparameters': hyperparameters\n",
    "    }])\n",
    "    \n",
    "    df_metrics = pd.concat([df_metrics, new_row], ignore_index=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(columns=['Model', 'k', 'Precision@k', 'Recall@k', 'MAP@k', 'NDCG@k', 'Other_hyperparameters'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d3648-7b10-4194-86be-59363065dc73",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1259b4-022b-416e-8cb2-f955bfc6e142",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa8898",
   "metadata": {},
   "source": [
    "**User-based temporal split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2512df89-a9ef-4132-b136-08aa155ee5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сортируем данные по времени и бьём на трейн и тест\n",
    "# df_sales['order_date'] = pd.to_datetime(df_sales['order_date'])\n",
    "# df_sales = df_sales.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "\n",
    "# for user, user_df in df_sales.groupby('anon_id_encrypred'):\n",
    "#     split_idx = int(len(user_df) * 0.8)\n",
    "#     train_data.append(user_df.iloc[:split_idx])\n",
    "#     test_data.append(user_df.iloc[split_idx:])\n",
    "\n",
    "# train_df = pd.concat(train_data)\n",
    "# test_df = pd.concat(test_data)\n",
    "\n",
    "# df_sales.to_csv(interim_data_dir / 'df_sales.csv', index=False)\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_users.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_users.csv', index=False)\n",
    "\n",
    "# df_sales = pd.read_csv(interim_data_dir / 'df_sales.csv')\n",
    "# train_df = pd.read_csv(interim_data_dir / 'train_data_by_users.csv')\n",
    "# test_df = pd.read_csv(interim_data_dir / 'test_data_by_users.csv')\n",
    "\n",
    "# print(f\"Train shape: {train_df.shape}\")\n",
    "# print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5337b",
   "metadata": {},
   "source": [
    "**Global temporal split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2019-01-01 00:00:00\n",
      "Max date: 2021-02-18 00:00:00\n",
      "Threshold date (80.0%): 2020-09-15 00:00:00\n",
      "Train shape: (2700604, 20)\n",
      "Test shape: (767603, 20)\n",
      "\n",
      "Total number of users: 453195\n",
      "Number of users in the training set: 370091\n",
      "Number of users in the test set: 195339\n",
      "\n",
      "Total number of 'articul_encrypred': 228219\n",
      "Number of 'articul_encrypred' in the training set: 200065\n",
      "Number of 'articul_encrypred' in the test set: 118289\n",
      "\n",
      "Total number of 'product_id': 306664\n",
      "Number of 'product_id' in the training set: 267600\n",
      "Number of 'product_id' in the test set: 154024\n"
     ]
    }
   ],
   "source": [
    "df_sales['order_date'] = pd.to_datetime(df_sales['order_date'])\n",
    "df_sales = df_sales.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "threshold_level = 0.8\n",
    "min_date = df_sales['order_date'].min()\n",
    "max_date = df_sales['order_date'].max()\n",
    "\n",
    "print(f\"Min date: {min_date}\")\n",
    "print(f\"Max date: {max_date}\")\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "threshold_days = int(total_days * threshold_level)\n",
    "threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "train_df = df_sales[df_sales['order_date'] < threshold_date]\n",
    "test_df = df_sales[df_sales['order_date'] >= threshold_date]\n",
    "\n",
    "df_sales.to_csv(interim_data_dir / 'df_sales.csv', index=False)\n",
    "train_df.to_csv(interim_data_dir / 'train_data_by_threshold_date.csv', index=False)\n",
    "test_df.to_csv(interim_data_dir / 'test_data_by_threshold_date.csv', index=False)\n",
    "\n",
    "# df_sales = pd.read_csv(interim_data_dir / 'df_sales.csv')\n",
    "# train_df = pd.read_csv(interim_data_dir / 'train_data_by_threshold_date.csv')\n",
    "# test_df = pd.read_csv(interim_data_dir / 'test_data_by_threshold_date.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print()\n",
    "print(f\"Total number of users: {len(df_sales['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the training set: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Number of users in the test set: {len(test_df['anon_id_encrypred'].unique())}\")\n",
    "print()\n",
    "print(f\"Total number of 'articul_encrypred': {len(df_sales['articul_encrypred'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred' in the training set: {len(train_df['articul_encrypred'].unique())}\")\n",
    "print(f\"Number of 'articul_encrypred' in the test set: {len(test_df['articul_encrypred'].unique())}\")\n",
    "print()\n",
    "print(f\"Total number of 'product_id': {len(df_sales['product_id'].unique())}\")\n",
    "print(f\"Number of 'product_id' in the training set: {len(train_df['product_id'].unique())}\")\n",
    "print(f\"Number of 'product_id' in the test set: {len(test_df['product_id'].unique())}\")\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Для каждого пользователя формируем список покупок: (product_id, order_date)\n",
    "# test_user_to_true_items = {}\n",
    "# for user, user_df in tqdm(test_df.groupby('anon_id_encrypred'), desc='Preparing test data'):\n",
    "#     # user_df = user_df.sort_values(by='order_date')\n",
    "#     purchases = list(zip(user_df['product_id'], user_df['order_date']))\n",
    "#     test_user_to_true_items[user] = purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30cda962",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "k = 10\n",
    "round_level=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edc970-1bd8-411a-a29f-10c11418a180",
   "metadata": {},
   "source": [
    "### 1. Top-K Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c19127f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'top_sales' / 'user_recommendations_top_k.pkl', \"rb\") as f:\n",
    "    user_recommendations_top_k = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa9a3e-3dd8-4ecd-ab58-a28a3e1d5031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48fbc939b5945f9bb6127a9b81f6c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "\n",
    "popular_items = train_df['product_id'].value_counts().index.tolist()\n",
    "\n",
    "def recommend_top_k(top_k_items=k):\n",
    "    return popular_items[:top_k_items]\n",
    "\n",
    "user_recommendations_top_k = {user: recommend_top_k(top_k_items=k) for user in tqdm(test_df['anon_id_encrypred'].unique())}\n",
    "\n",
    "with open(models_outputs_dir / 'top_sales' / 'user_recommendations_top_k.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_top_k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32918cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_top_k = RecommendationDataset(user_recommendations=user_recommendations_top_k, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_top_k, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3cf2548-9d9b-482d-936d-b017c7766712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0281683c2a4702bc175c810caa2b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for Top 10 Recommender model: 0.00372823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f569e0cda24a4eaf0433d793b3dbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 for Top 10 Recommender model: 0.003641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2165940b3a545f78f986790eb8ec00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for Top 10 Recommender model: 0.00143723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9b84631d7e4fb3a0bf97302d8a9cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 for Top 10 Recommender model: 0.00243494\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Precision@{k} for Top {k} Recommender model: {precision_k:.8f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Recall@{k} for Top {k} Recommender model: {recall_k:8f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "print(f'MAP@{k} for Top {k} Recommender model: {map_k:.8f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "print(f'NDCG@{k} for Top {k} Recommender model: {ndcg_k:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c85fe4e-ef69-4bc8-aaeb-15879d72bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model   k  Precision@k  Recall@k     MAP@k    NDCG@k Other_hyperparameters\n",
       "0  Top-K  10     0.003728  0.003641  0.001437  0.002435                  None"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Top-K', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None, round_level=round_level)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996d325-c77b-434d-ba15-eb17e2608809",
   "metadata": {},
   "source": [
    "### 2. Random Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9afb51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'random' / 'user_recommendations_random.pkl', \"rb\") as f:\n",
    "    user_recommendations_random = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35dc09-640d-46ed-ae31-0f4b3cc6e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7407509cc224889bdbfb8a0d87725e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning recommendations:   0%|          | 0/195339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "\n",
    "def recommend_random(df, top_k_items=k):\n",
    "    return np.random.choice(df.unique(), size=min(top_k_items, len(df.unique())), replace=False)\n",
    "\n",
    "random_recommendations = recommend_random(df=train_df['product_id'], top_k_items=k)\n",
    "user_recommendations_random = {user: random_recommendations for user in tqdm(test_df['anon_id_encrypred'].unique(), desc='Assigning recommendations')}\n",
    "\n",
    "with open(models_outputs_dir / 'random' / 'user_recommendations_random.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_random, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3389614",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_random = RecommendationDataset(user_recommendations=user_recommendations_random, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_random, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfdb09d3-1cff-4823-b614-a75af109b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576b3443bca74dbab3ce76d8728a4cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for Random Recommender model: 0.00004552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12ac7432bfb4ed78d9aa64f46c5d4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 for Random Recommender model: 0.000042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d961f92734947bbbdd0cafbb21b2099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for Random Recommender model: 0.00000916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3e7a88e8d64febb135c82ad9d50966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 for Random Recommender model: 0.00002271\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Precision@{k} for Random Recommender model: {precision_k:.8f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Recall@{k} for Random Recommender model: {recall_k:8f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "print(f'MAP@{k} for Random Recommender model: {map_k:.8f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "print(f'NDCG@{k} for Random Recommender model: {ndcg_k:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d17403b2-e74b-4e05-bccd-50f65e603fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model   k  Precision@k  Recall@k     MAP@k    NDCG@k Other_hyperparameters\n",
       "0   Top-K  10     0.003728  0.003641  0.001437  0.002435                  None\n",
       "1  Random  10     0.000046  0.000042  0.000009  0.000023                  None"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Random', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None, round_level=round_level)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861ad65-6435-47bf-ad54-085126a7ba8a",
   "metadata": {},
   "source": [
    "### 3. User-Based Collaborative Filtering (UBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6017ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # Устройство – используем CPU, т.к. MPS не поддерживает sparse операции\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# # 1. Функция создания user-item матрицы (без изменений)\n",
    "# def create_user_item_matrix(df):\n",
    "#     user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "#     u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "#     p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "#     data = user_item_counts['count'].values\n",
    "#     user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "#     return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "# # 2. Вычисление низкоразмерных представлений пользователей с помощью Truncated SVD\n",
    "# def compute_user_embeddings(df, n_components=128):\n",
    "#     user_item_matrix, u_labels, _ = create_user_item_matrix(df)\n",
    "#     # Применяем логарифмическое сглаживание\n",
    "#     user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "#     svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "#     user_embeddings = svd.fit_transform(user_item_matrix)\n",
    "#     # Нормализуем каждую строку для косинусного сходства\n",
    "#     norms = np.linalg.norm(user_embeddings, axis=1, keepdims=True)\n",
    "#     norms[norms == 0] = 1.0\n",
    "#     user_embeddings_normalized = user_embeddings / norms\n",
    "#     # Переводим в torch.tensor\n",
    "#     user_embeddings_tensor = torch.tensor(user_embeddings_normalized, dtype=torch.float32, device=device)\n",
    "#     return user_embeddings_tensor, u_labels\n",
    "\n",
    "# # 3. Рекомендации на основе плотного косинусного сходства\n",
    "# def recommend_user_based_dense(\n",
    "#     user_ids,\n",
    "#     user_embeddings,\n",
    "#     user_labels,\n",
    "#     df, \n",
    "#     top_k_items=6,\n",
    "#     top_n_similar_users=20,\n",
    "#     filter_already_purchased=True\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Для каждого пользователя из user_ids вычисляем cosine similarity на основе user_embeddings,\n",
    "#     затем находим топ-N похожих пользователей и собираем их покупки.\n",
    "#     Если для пользователя нет данных (например, он отсутствует в тренировке),\n",
    "#     возвращаем дефолтные рекомендации — топ-k популярных товаров.\n",
    "#     \"\"\"\n",
    "#     # Собираем покупки из train_df\n",
    "#     user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "#     user_labels_index = pd.Index(user_labels)\n",
    "#     most_popular_items = df['product_id'].value_counts().index.tolist()\n",
    "#     recommendations = {}\n",
    "    \n",
    "#     for user_id in tqdm(user_ids, desc=\"Generating recommendations\"):\n",
    "#         try:\n",
    "#             u_idx = user_labels_index.get_loc(user_id)\n",
    "#         except KeyError:\n",
    "#             # Если пользователя нет в тренировочных данных, возвращаем дефолтные рекомендации\n",
    "#             recommendations[user_id] = np.array(most_popular_items[:top_k_items])\n",
    "#             continue\n",
    "        \n",
    "#         u_embedding = user_embeddings[u_idx].unsqueeze(0)  # shape (1, d)\n",
    "#         sim_vector = torch.mm(u_embedding, user_embeddings.t()).flatten()\n",
    "#         sim_vector[u_idx] = -float('inf')\n",
    "#         top_sim_scores, top_sim_indices = torch.topk(sim_vector, top_n_similar_users)\n",
    "#         similar_users_ids = user_labels[top_sim_indices.cpu().numpy()]\n",
    "#         user_bought = user_purchases.get(user_id, set())\n",
    "        \n",
    "#         product_counter = Counter()\n",
    "#         for sim_u in similar_users_ids:\n",
    "#             sim_bought = user_purchases.get(sim_u, set())\n",
    "#             new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "#             product_counter.update(new_items)\n",
    "        \n",
    "#         recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "        \n",
    "#         # Если полученных рекомендаций меньше, чем нужно, добиваем дефолтными популярными товарами\n",
    "#         if len(recommended_products) < top_k_items:\n",
    "#             needed_items = top_k_items - len(recommended_products)\n",
    "#             additional_items = [p for p in most_popular_items if p not in recommended_products and (p not in user_bought)]\n",
    "#             recommended_products.extend(additional_items[:needed_items])\n",
    "            \n",
    "#         recommendations[user_id] = np.array(recommended_products[:top_k_items])\n",
    "        \n",
    "#     return recommendations\n",
    "\n",
    "# # --- Пример использования ---\n",
    "# # Предполагаем, что у вас уже выполнен temporal split и у вас есть train_df и test_df.\n",
    "# # Вычисляем представления пользователей на train_df\n",
    "# user_embeddings, user_labels = compute_user_embeddings(train_df, n_components=128)\n",
    "\n",
    "# # Получаем уникальные user_ids из тестового набора\n",
    "# user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "# # Генерируем рекомендации для тестовых пользователей на основе dense similarity\n",
    "# user_recommendations_ubcf_svd = recommend_user_based_dense(\n",
    "#     user_ids=user_ids,\n",
    "#     user_embeddings=user_embeddings,\n",
    "#     user_labels=user_labels,\n",
    "#     df=train_df,\n",
    "#     top_k_items=6,\n",
    "#     top_n_similar_users=20,\n",
    "#     filter_already_purchased=filter_already_purchased\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ubcf_svd = RecommendationDataset(user_recommendations=user_recommendations_ubcf_svd, user_to_true_items=test_user_to_true_items, k=k)\n",
    "# loader = DataLoader(dataset_ubcf, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2af02504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "# recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "# map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "# ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "# print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb4fae8f-9af4-4e6b-a35a-03ad6457aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20  # top_n_similar_users\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_users = 1\n",
    "# Важно!!! Если у вас GPU desktop - комментируйте строку ниже\n",
    "device = torch.device(\"cpu\") # На macbook не работает sparce на msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9c7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Функция для создания user-item матрицы\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "\n",
    "# 2. Функция для вычисления матрицы сходства пользователей на GPU\n",
    "def compute_user_similarity(df):\n",
    "    \"\"\"\n",
    "    Создает user-item матрицу, логарифмирует count для сглаживания, \n",
    "    преобразует в sparse-тензор PyTorch, вычисляет косинусное сходство.\n",
    "    Возвращает user_similarity (sparse.mm результат) и user_labels.\n",
    "    \"\"\"\n",
    "    # Создаем user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Применяем log(1 + count), чтобы уменьшить влияние частых покупок\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # Преобразуем разреженную матрицу в PyTorch sparse_coo_tensor\n",
    "    # indices:  shape = (2, количество ненулевых элементов)\n",
    "    # values:   shape = (количество ненулевых элементов,)\n",
    "    # size:     (число пользователей, число товаров)\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # Нормализуем пользователей построчно для косинусного сходства\n",
    "    # row_norms.shape = (num_users,)\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(user_item_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Делим значения на норму соответствующей строки\n",
    "    # user_item_tensor.indices()[0] = индексы строк (пользователи)\n",
    "    normalized_values = user_item_tensor.values() / row_norms[user_item_tensor.indices()[0]]\n",
    "    user_item_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        user_item_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=user_item_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # Вычисляем матрицу сходства как M * M^T (косинусное сходство)\n",
    "    user_similarity = torch.sparse.mm(user_item_tensor_normalized, user_item_tensor_normalized.t())\n",
    "    \n",
    "    return user_similarity, user_labels  # product_labels не нужен для UBCF\n",
    "\n",
    "\n",
    "# 3. Функция рекомендаций (User-Based CF) на GPU с построчной обработкой\n",
    "def recommend_user_based_batch(\n",
    "    user_ids,\n",
    "    user_similarity,\n",
    "    user_labels,\n",
    "    df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_users=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации, основанные на top-N похожих пользователях.\n",
    "    \"\"\"\n",
    "    # Для быстрого поиска индекса пользователя по user_id\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    \n",
    "    # Список (или словарь) всех покупок пользователя\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Словарь: user_id -> список рекомендованных товаров\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Разбиваем на батчи только user_ids (чтобы не выделять память под всю dense-матрицу сразу)\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "    \n",
    "        # Для каждого пользователя в батче по очереди вытащим строку сходства (sparse)\n",
    "        for user_id in batch_user_ids:\n",
    "            # Получаем индекс пользователя в матрице user_similarity\n",
    "            try:\n",
    "                u_idx = user_labels_index.get_loc(user_id)\n",
    "            except KeyError:\n",
    "                # Если вдруг пользователя не оказалось в user_labels\n",
    "                recommendations[user_id] = np.array([])\n",
    "                continue\n",
    "    \n",
    "            # Извлекаем строку u_idx из user_similarity — это shape (1, num_users) (sparse)\n",
    "            row_sparse = user_similarity[u_idx]  # submatrix (1, U)\n",
    "            # Превращаем её в dense-вектор [U], но только для одного пользователя\n",
    "            row_dense = row_sparse.to_dense().flatten()  # теперь shape = [num_users]\n",
    "    \n",
    "            # Начинаем с базового `top_n_similar_users`\n",
    "            num_similar_users = top_n_similar_users\n",
    "            recommended_products = []\n",
    "            expansion_step = 0  # Количество расширений\n",
    "    \n",
    "            # Проверяем, нужно ли использовать динамическое увеличение top_n_similar_users\n",
    "            while (len(recommended_products) < top_k_items \n",
    "                    and n_iter_x5_top_n_similar_users is not None \n",
    "                    and n_iter_x5_top_n_similar_users > 0 \n",
    "                    and expansion_step <= n_iter_x5_top_n_similar_users):\n",
    "    \n",
    "                # Находим топ-N похожих пользователей (динамически увеличивая N)\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, num_similar_users + 1, dim=0)\n",
    "    \n",
    "                # Убираем самого пользователя (сходство с собой = 1)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask]\n",
    "    \n",
    "                # Превращаем индексы похожих пользователей в user_id\n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "    \n",
    "                # Собираем уникальные товары, которые есть у похожих пользователей\n",
    "                product_counter = Counter()  # Считаем частоту товаров среди похожих пользователей\n",
    "    \n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    # **Фильтруем только если filter_already_purchased=True**\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Увеличиваем счётчик\n",
    "    \n",
    "                # Берём топ-K товаров по частоте\n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "                if len(recommended_products) >= top_k_items:\n",
    "                    break  # Если набрали `top_k_items`, останавливаемся\n",
    "    \n",
    "                # Увеличиваем число похожих пользователей в 5 раз\n",
    "                num_similar_users *= 5\n",
    "                expansion_step += 1\n",
    "    \n",
    "            # Если n_iter_x5_top_n_similar_users=None → НЕ выполняем расширение\n",
    "            if n_iter_x5_top_n_similar_users is None or n_iter_x5_top_n_similar_users <= 0:\n",
    "                similar_users_scores, similar_users_indices = torch.topk(row_dense, top_n_similar_users + 1, dim=0)\n",
    "                mask = (similar_users_indices != u_idx)\n",
    "                similar_users_indices = similar_users_indices[mask][:top_n_similar_users]\n",
    "    \n",
    "                similar_users_ids = user_labels[similar_users_indices.cpu().numpy()]\n",
    "                user_bought = user_purchases.get(user_id, set())\n",
    "    \n",
    "                product_counter = Counter()\n",
    "                for sim_u in similar_users_ids:\n",
    "                    sim_bought = user_purchases.get(sim_u, set())\n",
    "                    new_items = sim_bought - user_bought if filter_already_purchased else sim_bought\n",
    "                    product_counter.update(new_items)  # Увеличиваем счётчик\n",
    "    \n",
    "                recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "    \n",
    "            # Если всё равно товаров не хватает → используем популярные товары\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                # Вычисляем популярные товары (их нужно хранить больше чем `top_k_items`, чтобы фильтрация работала)\n",
    "                most_popular_items = df['product_id'].value_counts().index.tolist()  # Оптимизируем\n",
    "                # Используем генераторное выражение + islice для эффективной остановки после нужного количества товаров\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items if p not in recommended_products and \n",
    "                     (p not in user_bought if filter_already_purchased else True)),  \n",
    "                    needed_items\n",
    "                ))\n",
    "                recommended_products.extend(additional_items)\n",
    "    \n",
    "            # Сохраняем результат в np.array\n",
    "            recommendations[user_id] = np.array(list(recommended_products)[:top_k_items])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'user_based' / 'user_recommendations_ubcf.pkl', \"rb\") as f:\n",
    "    user_recommendations_ubcf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf2811c5-4abb-46c5-8469-359c3bc21d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3e2c948ad437983947bf6e27e6024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "\n",
    "# 1) Вычисляем матрицу сходства пользователей на GPU\n",
    "user_similarity, user_labels = compute_user_similarity(train_df)\n",
    "\n",
    "# 2) Генерация рекомендаций для всех пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ubcf = recommend_user_based_batch(\n",
    "    user_ids=user_ids,\n",
    "    user_similarity=user_similarity,\n",
    "    user_labels=user_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_users=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_users=n_iter_x5_top_n_similar_users\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'user_based' / 'user_recommendations_ubcf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_ubcf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56336f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нашли 83104 пустых пользователей\n"
     ]
    }
   ],
   "source": [
    "# empty_users = [\n",
    "#     u for u, recs in user_recommendations_ubcf.items()\n",
    "#     if len(recs) == 0\n",
    "# ]\n",
    "\n",
    "# print(f\"нашли {len(empty_users)} пустых пользователей\")\n",
    "# # -------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# # -------- 2) пост-фактум «прописать» им fallback-топ-k --------------------\n",
    "# most_popular_items = train_df['product_id'].value_counts().index .tolist()\n",
    "# top_pop = most_popular_items[:k]                    # длиной k\n",
    "\n",
    "# for u in empty_users:\n",
    "#     user_recommendations_ubcf[u] = np.array(top_pop, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f5fad0c-74ca-403f-8e7a-1a512c642b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ubcf = RecommendationDataset(user_recommendations=user_recommendations_ubcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ubcf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30715fd4-48dc-4dfb-b9dd-0adc7155fe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8750a897c21148a7bc7e6ef20ef0bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for UBCF model: 0.00388593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd8faccf6ad400594c03fd2f9d9cf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 for UBCF model: 0.003787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3236594db91a4624a7be45ea0795650f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for UBCF model: 0.00156761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bdc142d3e54b67b89d6573ccce13e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 for UBCF model: 0.00260152\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Precision@{k} for UBCF model: {precision_k:.8f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Recall@{k} for UBCF model: {recall_k:8f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "print(f'MAP@{k} for UBCF model: {map_k:.8f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "print(f'NDCG@{k} for UBCF model: {ndcg_k:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c273a11-ce6b-499c-97a1-e2a7b8334d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_users': 20,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model   k  Precision@k  Recall@k     MAP@k    NDCG@k  \\\n",
       "0   Top-K  10     0.003728  0.003641  0.001437  0.002435   \n",
       "1  Random  10     0.000046  0.000042  0.000009  0.000023   \n",
       "2    UBCF  10     0.003886  0.003787  0.001568  0.002602   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'top_k_items': 10, 'top_n_similar_users': 20,...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='UBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_users': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_users': n_iter_x5_top_n_similar_users})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab1e79-dc3b-4da9-bf3c-deeeacd47e72",
   "metadata": {},
   "source": [
    "### 4. Item-Based Collaborative Filtering (IBCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0a7c584-a282-44da-88ce-b0da9e4455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20  # top_n_similar_items\n",
    "filter_already_purchased = True\n",
    "n_iter_x5_top_n_similar_items = 1\n",
    "# Важно!!! Если у вас GPU desktop - комментируйте строку ниже\n",
    "device = torch.device(\"cpu\") # На macbook не работает sparce на msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f436e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels\n",
    "\n",
    "def compute_item_similarity(df):\n",
    "    \"\"\"\n",
    "    Создает user-item матрицу, логарифмирует count для сглаживания,\n",
    "    транспонирует в (items x users), вычисляет косинусное сходство между товарами.\n",
    "    Возвращает item_similarity (sparse.mm результат) и product_labels.\n",
    "    \"\"\"\n",
    "    # 1) Cоздаём user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Применяем log(1 + count), чтобы уменьшить влияние частых покупок\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    # 2) Преобразуем в PyTorch sparse_coo_tensor\n",
    "    coo_indices = np.vstack(user_item_matrix.nonzero())\n",
    "    coo_values = user_item_matrix.data\n",
    "    \n",
    "    # user_item_matrix.shape = (num_users, num_items)\n",
    "    user_item_tensor = torch.sparse_coo_tensor(\n",
    "        torch.tensor(coo_indices, dtype=torch.long),\n",
    "        torch.tensor(coo_values, dtype=torch.float32),\n",
    "        size=user_item_matrix.shape\n",
    "    ).coalesce().to(device)\n",
    "    \n",
    "    # 3) Транспонируем, чтобы получить item-user матрицу (shape = (num_items, num_users))\n",
    "    # В PyTorch sparse_coo_tensor можно сделать sparse.transpose(dim0=0, dim1=1)\n",
    "    item_user_tensor = user_item_tensor.transpose(0, 1).coalesce()\n",
    "    \n",
    "    # 4) Нормируем строки (т.е. товары) для косинусного сходства\n",
    "    #    теперь каждую \"строку\" item_user_tensor мы считаем l2-норму\n",
    "    row_norms = torch.sqrt(torch.sparse.sum(item_user_tensor.pow(2), dim=1).to_dense())\n",
    "    row_norms[row_norms == 0] = 1.0\n",
    "    \n",
    "    # Делим значения на норму соответствующей строки (товара)\n",
    "    normalized_values = item_user_tensor.values() / row_norms[item_user_tensor.indices()[0]]\n",
    "    item_user_tensor_normalized = torch.sparse_coo_tensor(\n",
    "        item_user_tensor.indices(),\n",
    "        normalized_values,\n",
    "        size=item_user_tensor.size()\n",
    "    ).coalesce()\n",
    "    \n",
    "    # 5) Вычисляем матрицу сходства товаров (item x item): M * M^T\n",
    "    item_similarity = torch.sparse.mm(item_user_tensor_normalized, item_user_tensor_normalized.t())\n",
    "    \n",
    "    # Возвращаем item_similarity и product_labels\n",
    "    # (user_labels не нужны для Item-Based)\n",
    "    return item_similarity, product_labels\n",
    "\n",
    "\n",
    "def recommend_item_based_batch(\n",
    "    user_ids,\n",
    "    item_similarity,\n",
    "    item_labels,\n",
    "    df,\n",
    "    top_k_items=k,                  # Сколько товаров рекомендуем\n",
    "    top_n_similar_items=n,          # Сколько похожих товаров ищем для каждого купленного\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=False,\n",
    "    n_iter_x5_top_n_similar_items=None  # Аналогично n_iter_x5_top_n_similar_users\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации на основе похожих товаров (Item-Based).\n",
    "    Аналогия с User-Based, но вместо топ-N похожих пользователей ищем топ-N похожих товаров\n",
    "    для каждого товара, который купил пользователь.\n",
    "    \"\"\"\n",
    "    # Для быстрого поиска индекса товара по product_id\n",
    "    item_labels_index = pd.Index(item_labels)\n",
    "    \n",
    "    # Список всех покупок пользователя (anon_id_encrypred -> set(product_id))\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "    \n",
    "    # Словарь: user_id -> список рекомендованных товаров\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Получаем популярные товары (для fallback)\n",
    "    most_popular_items_all = df['product_id'].value_counts().index.tolist()\n",
    "    \n",
    "    # Разбиваем на батчи только user_ids\n",
    "    for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating Item-Based recommendations'):\n",
    "        batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            user_bought = user_purchases.get(user_id, set())\n",
    "            if len(user_bought) == 0:\n",
    "                # Если пользователь ничего не покупал, рекомендуем популярные товары\n",
    "                needed_items = top_k_items\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if (p not in user_bought if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommendations[user_id] = np.array(additional_items)\n",
    "                continue\n",
    "            \n",
    "            product_counter = Counter()\n",
    "            \n",
    "            # Для каждого товара, который купил пользователь, ищем похожие товары\n",
    "            for purchased_item in user_bought:\n",
    "                # Ищем индекс purchased_item в item_labels_index\n",
    "                try:\n",
    "                    i_idx = item_labels_index.get_loc(purchased_item)\n",
    "                except KeyError:\n",
    "                    # Если вдруг товара нет в item_labels\n",
    "                    continue\n",
    "                \n",
    "                row_sparse = item_similarity[i_idx]  # submatrix (1, num_items) (sparse)\n",
    "                row_dense = row_sparse.to_dense().flatten()\n",
    "                \n",
    "                # Начинаем с базового top_n_similar_items\n",
    "                num_similar_items = top_n_similar_items\n",
    "                similar_items_list = []\n",
    "                expansion_step = 0\n",
    "                \n",
    "                # Аналогично логике User-Based: расширяем, пока не наберём top_k_items (в совокупности)\n",
    "                while (len(similar_items_list) < top_k_items\n",
    "                       and n_iter_x5_top_n_similar_items is not None\n",
    "                       and n_iter_x5_top_n_similar_items > 0\n",
    "                       and expansion_step <= n_iter_x5_top_n_similar_items):\n",
    "                    \n",
    "                    # Находим top-(num_similar_items+1)\n",
    "                    # ( +1 чтобы исключить сам товар, если он попал в топ)\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, num_similar_items + 1, dim=0)\n",
    "                    \n",
    "                    # Убираем сам товар purchased_item (если он внутри)\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask]\n",
    "                    \n",
    "                    # Превращаем индексы похожих товаров в product_id\n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    \n",
    "                    # Если filter_already_purchased=True, убираем товары, которые уже купил пользователь\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in user_bought:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                    \n",
    "                    if len(similar_items_list) >= top_k_items:\n",
    "                        break\n",
    "                    \n",
    "                    # Увеличиваем число похожих товаров в 5 раз\n",
    "                    num_similar_items *= 5\n",
    "                    expansion_step += 1\n",
    "                \n",
    "                # Если n_iter_x5_top_n_similar_items=None → НЕ выполняем расширение\n",
    "                if n_iter_x5_top_n_similar_items is None or n_iter_x5_top_n_similar_items <= 0:\n",
    "                    sim_scores, sim_indices = torch.topk(row_dense, top_n_similar_items + 1, dim=0)\n",
    "                    mask = (sim_indices != i_idx)\n",
    "                    sim_indices = sim_indices[mask][:top_n_similar_items]\n",
    "                    \n",
    "                    similar_item_ids = item_labels[sim_indices.cpu().numpy()]\n",
    "                    for sim_item_id in similar_item_ids:\n",
    "                        if filter_already_purchased and sim_item_id in user_bought:\n",
    "                            continue\n",
    "                        similar_items_list.append(sim_item_id)\n",
    "                \n",
    "                # Подсчитаем, насколько часто встречаются эти похожие товары\n",
    "                product_counter.update(similar_items_list)\n",
    "            \n",
    "            # Берём топ-K товаров по частоте среди ВСЕХ собранных\n",
    "            recommended_products = [p for p, _ in product_counter.most_common(top_k_items)]\n",
    "            \n",
    "            # Если всё равно товаров не хватает → используем популярные товары\n",
    "            if len(recommended_products) < top_k_items:\n",
    "                needed_items = top_k_items - len(recommended_products)\n",
    "                additional_items = list(itertools.islice(\n",
    "                    (p for p in most_popular_items_all \n",
    "                     if p not in recommended_products and (p not in user_bought if filter_already_purchased else True)),\n",
    "                    needed_items\n",
    "                ))\n",
    "                recommended_products.extend(additional_items)\n",
    "            \n",
    "            recommendations[user_id] = np.array(recommended_products[:top_k_items])\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing saved recommendations\n",
    "with open(models_outputs_dir / 'item_based' / 'user_recommendations_ibcf.pkl', \"rb\") as f:\n",
    "    user_recommendations_ibcf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db8a5888-09d1-4269-ba4f-7329f10aeec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638bf5f6d6dc4d118d71db9f1d5a3160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Item-Based recommendations:   0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of new recommendations\n",
    "batch_size = 8\n",
    "\n",
    "# 1) Вычисляем матрицу сходства товаров на GPU\n",
    "item_similarity, item_labels = compute_item_similarity(train_df)\n",
    "\n",
    "# 2) Генерация рекомендаций для всех пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "user_recommendations_ibcf = recommend_item_based_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 50], # [:len(user_ids) // 50]\n",
    "    item_similarity=item_similarity,\n",
    "    item_labels=item_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    top_n_similar_items=n,\n",
    "    batch_size=batch_size,\n",
    "    filter_already_purchased=filter_already_purchased, \n",
    "    n_iter_x5_top_n_similar_items=n_iter_x5_top_n_similar_users\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'item_based' / 'user_recommendations_ibcf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_ibcf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2c098fa-14ac-4395-b28c-68add56459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibcf = RecommendationDataset(user_recommendations=user_recommendations_ibcf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_ibcf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d3b920e-e22e-4424-a525-ba83016b7a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afd32644ef44190b4de4b2bf976bfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for IBCF model: 0.00294967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e582065e0145f5b9b95378a5e0124b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 for IBCF model: 0.002940\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef8e4c7d44e47e6be7456eb3ebb561e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for IBCF model: 0.00104819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58287230644533abade64b925acaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 for IBCF model: 0.00169740\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Precision@{k} for IBCF model: {precision_k:.8f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Recall@{k} for IBCF model: {recall_k:8f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "print(f'MAP@{k} for IBCF model: {map_k:.8f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "print(f'NDCG@{k} for IBCF model: {ndcg_k:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a15377d8-dde8-4a44-a256-84b18c95d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_users': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_items': 20,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model   k  Precision@k  Recall@k     MAP@k    NDCG@k  \\\n",
       "0   Top-K  10     0.003728  0.003641  0.001437  0.002435   \n",
       "1  Random  10     0.000046  0.000042  0.000009  0.000023   \n",
       "2    UBCF  10     0.003886  0.003787  0.001568  0.002602   \n",
       "3    IBCF  10     0.002950  0.002940  0.001048  0.001697   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'top_k_items': 10, 'top_n_similar_users': 20,...  \n",
       "3  {'top_k_items': 10, 'top_n_similar_items': 20,...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='IBCF', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level, \n",
    "                  hyperparameters={'top_k_items': k, 'top_n_similar_items': n, \n",
    "                                   'filter_already_purchased': filter_already_purchased, 'n_iter_x5_top_n_similar_items': n_iter_x5_top_n_similar_items})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02406f-cf6c-4a83-b0a7-ecbea66cb300",
   "metadata": {},
   "source": [
    "### 5. Matrix Factorization (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93bdf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.9) # Memory usage limit for MacOS\n",
    "    torch.mps.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee142b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fe85a64-294d-4e05-b095-c8222a9ab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Возвращает разреженную матрицу (csr_matrix) и соответствия индексов \n",
    "    пользователей/товаров (user_labels, product_labels) строго в порядке factorize.\n",
    "    \"\"\"\n",
    "    user_item_counts = df.groupby(['anon_id_encrypred', 'product_id']).size().reset_index(name='count')\n",
    "    \n",
    "    # Факторизуем пользователей и товары\n",
    "    u_codes, u_labels = pd.factorize(user_item_counts['anon_id_encrypred'])\n",
    "    p_codes, p_labels = pd.factorize(user_item_counts['product_id'])\n",
    "    \n",
    "    data = user_item_counts['count'].values\n",
    "    \n",
    "    # Создаем разреженную матрицу (строки = пользователи, столбцы = товары)\n",
    "    user_item_matrix = csr_matrix((data, (u_codes, p_codes)))\n",
    "    \n",
    "    return user_item_matrix, u_labels, p_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb724ebc-b55a-4daa-8fe6-1aad44b89231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, latent_dim)\n",
    "        \n",
    "        # Инициализируем факторы (например, Xavier uniform)\n",
    "        nn.init.xavier_uniform_(self.user_factors.weight)\n",
    "        nn.init.xavier_uniform_(self.item_factors.weight)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        user_indices: LongTensor (batch_size,)\n",
    "        item_indices: LongTensor (batch_size,)\n",
    "        Возвращаем предсказанный рейтинг (скалярное произведение эмбеддингов).\n",
    "        \"\"\"\n",
    "        user_embedding = self.user_factors(user_indices)   # (batch_size, latent_dim)\n",
    "        item_embedding = self.item_factors(item_indices)   # (batch_size, latent_dim)\n",
    "        rating_pred = (user_embedding * item_embedding).sum(dim=1)  # (batch_size,)\n",
    "        return rating_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d21e0d00-734d-4118-a1a7-f2337c88fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matrix_factorization(\n",
    "    df,\n",
    "    latent_dim=256,\n",
    "    epochs=10,\n",
    "    lr=0.01,\n",
    "    batch_size=1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Обучает матричную факторизацию (SVD с градиентным спуском) на user-item матрице.\n",
    "    Возвращает модель, а также user_labels и product_labels для инференса.\n",
    "    \"\"\"\n",
    "    # 1) Создаем user-item матрицу\n",
    "    user_item_matrix, user_labels, product_labels = create_user_item_matrix(df)\n",
    "    \n",
    "    # Логарифмируем, чтобы сгладить влияние больших count\n",
    "    user_item_matrix.data = np.log1p(user_item_matrix.data)\n",
    "    \n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "\n",
    "    # 2) Создаём модель\n",
    "    model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "    # 3) Формируем обучающий датасет\n",
    "    coo = user_item_matrix.tocoo()\n",
    "    user_indices = torch.tensor(coo.row, dtype=torch.long, device=device)\n",
    "    item_indices = torch.tensor(coo.col, dtype=torch.long, device=device)\n",
    "    ratings = torch.tensor(coo.data, dtype=torch.float32, device=device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(user_indices, item_indices, ratings)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 4) Задаём оптимизатор и функцию потерь\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 5) Тренировка\n",
    "    model.train()\n",
    "\n",
    "    # Для трекинга лосса\n",
    "    batch_losses = []\n",
    "    batch_avg_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Training Matrix Factorization (epochs)'):\n",
    "        total_loss = 0.0\n",
    "        epoch_losses = []\n",
    "        verbose = len(dataloader) // 10\n",
    "        for batch_idx, (batch_user, batch_item, batch_rating) in enumerate(tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}\")):\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_user, batch_item)\n",
    "            loss = criterion(preds, batch_rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "            # Каждые 50 батчей сохраняем средний лосс\n",
    "            if (batch_idx + 1) % verbose == 0:\n",
    "                avg_loss = sum(epoch_losses[-50:]) / 50\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}, Avg Loss: {avg_loss:.4f}\")\n",
    "                batch_avg_losses.append(avg_loss)\n",
    "                print(f\"Step {batch_idx + 1}, last AVG loss: {avg_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {total_loss:.4f}\")\n",
    "        batch_losses.extend(epoch_losses)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(len(batch_avg_losses)), batch_avg_losses, label='Avg Loss per 50 batches')\n",
    "    plt.xlabel('Logging step (every 50 batches)')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title('Training Loss Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return model, user_labels, product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "001adee4-6610-4e0d-9076-b92e0334da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_mf_batch(\n",
    "    user_ids,\n",
    "    model,\n",
    "    user_labels,\n",
    "    product_labels,\n",
    "    df,\n",
    "    top_k_items=10,\n",
    "    batch_size=1024,\n",
    "    filter_already_purchased=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Для списка user_ids возвращает рекомендации, основанные на матричной факторизации.\n",
    "    Логика схожа с User-Based/Item-Based:\n",
    "      1) Считаем оценки для всех товаров\n",
    "      2) Если filter_already_purchased=True, убираем товары, которые пользователь уже покупал\n",
    "      3) Берём top-K\n",
    "      4) Если не хватает, добавляем популярные товары\n",
    "    \"\"\"\n",
    "    user_labels_index = pd.Index(user_labels)\n",
    "    product_labels_index = pd.Index(product_labels)\n",
    "\n",
    "    # Собираем покупки пользователя\n",
    "    user_purchases = df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "\n",
    "    # Популярные товары (для fallback)\n",
    "    most_popular_items = df['product_id'].value_counts().index.tolist()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_idx in tqdm(range(0, len(user_ids), batch_size), desc='Generating MF recommendations'):\n",
    "            batch_user_ids = user_ids[start_idx : start_idx + batch_size]\n",
    "\n",
    "            # Конвертируем user_ids в user_indices\n",
    "            valid_indices = []\n",
    "            valid_user_ids = []\n",
    "            for uid in batch_user_ids:\n",
    "                try:\n",
    "                    uidx = user_labels_index.get_loc(uid)\n",
    "                    valid_indices.append(uidx)\n",
    "                    valid_user_ids.append(uid)\n",
    "                except KeyError: \n",
    "                    # Если пользователя нет в train_df - это холодный старт, подставляем fallback – топ‑k популярных товаров\n",
    "                    recommendations[uid] = np.array(most_popular_items[:top_k_items])\n",
    "            \n",
    "            if len(valid_indices) == 0:\n",
    "                continue  # Все пользователи в этом батче невалидны\n",
    "\n",
    "            user_tensor = torch.tensor(valid_indices, dtype=torch.long, device=device)\n",
    "            item_tensor = torch.arange(len(product_labels), dtype=torch.long, device=device)\n",
    "\n",
    "            # Предсказываем рейтинги для (batch_users x все товары)\n",
    "            # Расширяем user_tensor, чтобы сделать все комбинации\n",
    "            # user_tensor.shape -> (batch_size_valid,)\n",
    "            # item_tensor.shape -> (num_items,)\n",
    "\n",
    "            # predictions.shape -> (batch_size_valid, num_items)\n",
    "            predictions = model(\n",
    "                user_tensor.unsqueeze(1).expand(-1, len(item_tensor)).flatten(),\n",
    "                item_tensor.repeat(len(user_tensor))\n",
    "            )\n",
    "            predictions = predictions.view(len(user_tensor), len(item_tensor))\n",
    "\n",
    "            # Для каждого пользователя выбираем top-K\n",
    "            for i, uid in enumerate(valid_user_ids):\n",
    "                user_bought = user_purchases.get(uid, set())\n",
    "\n",
    "                # Если filter_already_purchased=True, фильтруем уже купленные\n",
    "                if filter_already_purchased:\n",
    "                    mask = torch.tensor(\n",
    "                        [product_labels[j] not in user_bought for j in range(len(product_labels))],\n",
    "                        dtype=torch.bool,\n",
    "                        device=device\n",
    "                    )\n",
    "                    # Присваиваем -inf товарам, которые нужно исключить\n",
    "                    predictions[i][~mask] = float('-inf')\n",
    "\n",
    "                # Находим top-K\n",
    "                top_k_indices = torch.topk(predictions[i], top_k_items).indices\n",
    "                top_k_products = [product_labels[idx.item()] for idx in top_k_indices]\n",
    "\n",
    "                # Если меньше K рекомендаций (теоретически при сильной фильтрации?), берём популярные\n",
    "                # (Хотя в MF обычно много товаров, так что пусто не будет)\n",
    "                if len(top_k_products) < top_k_items:\n",
    "                    needed = top_k_items - len(top_k_products)\n",
    "                    fallback = list(itertools.islice(\n",
    "                        (p for p in most_popular_items if p not in top_k_products and\n",
    "                         (p not in user_bought if filter_already_purchased else True)),\n",
    "                        needed\n",
    "                    ))\n",
    "\n",
    "                    # Если fallback пуст, подставляем просто топ популярных товаров\n",
    "                    if top_k_items - len(top_k_products) - len(fallback) != 0:\n",
    "                        needed = top_k_items - len(top_k_products) - len(fallback)\n",
    "                        fallback = most_popular_items[:needed]\n",
    "                    top_k_products.extend(fallback)\n",
    "\n",
    "                recommendations[uid] = np.array(top_k_products[:top_k_items])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0138a94e-7069-4832-8ccc-f3e61e421825",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_already_purchased = True\n",
    "latent_dim=512\n",
    "epochs=3\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25dbef-1823-41f5-9773-80ba4e627d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e602b0cf15b4da58f7ded7e44d120d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Matrix Factorization (epochs):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0749340010f147128e39d92c584adaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 253, Avg Loss: 0.5094\n",
      "Step 253, last AVG loss: 0.5094\n",
      "Epoch 1, Batch 506, Avg Loss: 0.5091\n",
      "Step 506, last AVG loss: 0.5091\n",
      "Epoch 1, Batch 759, Avg Loss: 0.5010\n",
      "Step 759, last AVG loss: 0.5010\n",
      "Epoch 1, Batch 1012, Avg Loss: 0.4667\n",
      "Step 1012, last AVG loss: 0.4667\n",
      "Epoch 1, Batch 1265, Avg Loss: 0.3871\n",
      "Step 1265, last AVG loss: 0.3871\n",
      "Epoch 1, Batch 1518, Avg Loss: 0.2966\n",
      "Step 1518, last AVG loss: 0.2966\n",
      "Epoch 1, Batch 1771, Avg Loss: 0.2261\n",
      "Step 1771, last AVG loss: 0.2261\n",
      "Epoch 1, Batch 2024, Avg Loss: 0.1790\n",
      "Step 2024, last AVG loss: 0.1790\n",
      "Epoch 1, Batch 2277, Avg Loss: 0.1472\n",
      "Step 2277, last AVG loss: 0.1472\n",
      "Epoch 1, Batch 2530, Avg Loss: 0.1237\n",
      "Step 2530, last AVG loss: 0.1237\n",
      "Epoch 1/3, Total Loss: 887.5107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a9a40fc0c4cf2ad4a450ca48637d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 253, Avg Loss: 0.0555\n",
      "Step 253, last AVG loss: 0.0555\n",
      "Epoch 2, Batch 506, Avg Loss: 0.0499\n",
      "Step 506, last AVG loss: 0.0499\n",
      "Epoch 2, Batch 759, Avg Loss: 0.0475\n",
      "Step 759, last AVG loss: 0.0475\n",
      "Epoch 2, Batch 1012, Avg Loss: 0.0452\n",
      "Step 1012, last AVG loss: 0.0452\n",
      "Epoch 2, Batch 1265, Avg Loss: 0.0437\n",
      "Step 1265, last AVG loss: 0.0437\n",
      "Epoch 2, Batch 1518, Avg Loss: 0.0426\n",
      "Step 1518, last AVG loss: 0.0426\n",
      "Epoch 2, Batch 1771, Avg Loss: 0.0412\n",
      "Step 1771, last AVG loss: 0.0412\n",
      "Epoch 2, Batch 2024, Avg Loss: 0.0408\n",
      "Step 2024, last AVG loss: 0.0408\n",
      "Epoch 2, Batch 2277, Avg Loss: 0.0406\n",
      "Step 2277, last AVG loss: 0.0406\n",
      "Epoch 2, Batch 2530, Avg Loss: 0.0400\n",
      "Step 2530, last AVG loss: 0.0400\n",
      "Epoch 2/3, Total Loss: 116.6007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc99f5c35b4ff1b1639329f720d0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 253, Avg Loss: 0.0588\n",
      "Step 253, last AVG loss: 0.0588\n",
      "Epoch 3, Batch 506, Avg Loss: 0.0540\n",
      "Step 506, last AVG loss: 0.0540\n",
      "Epoch 3, Batch 759, Avg Loss: 0.0501\n",
      "Step 759, last AVG loss: 0.0501\n",
      "Epoch 3, Batch 1012, Avg Loss: 0.0470\n",
      "Step 1012, last AVG loss: 0.0470\n",
      "Epoch 3, Batch 1265, Avg Loss: 0.0446\n",
      "Step 1265, last AVG loss: 0.0446\n",
      "Epoch 3, Batch 1518, Avg Loss: 0.0415\n",
      "Step 1518, last AVG loss: 0.0415\n",
      "Epoch 3, Batch 1771, Avg Loss: 0.0402\n",
      "Step 1771, last AVG loss: 0.0402\n",
      "Epoch 3, Batch 2024, Avg Loss: 0.0384\n",
      "Step 2024, last AVG loss: 0.0384\n",
      "Epoch 3, Batch 2277, Avg Loss: 0.0375\n",
      "Step 2277, last AVG loss: 0.0375\n",
      "Epoch 3, Batch 2530, Avg Loss: 0.0365\n",
      "Step 2530, last AVG loss: 0.0365\n",
      "Epoch 3/3, Total Loss: 116.0665\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_model, user_labels, product_labels = train_matrix_factorization(\n",
    "    train_df,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mf_model.state_dict(), models_dir / f'mf_model_latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}.pth')\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'user_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(user_labels, f)\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'product_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(product_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84e0c5-4feb-4629-9828-eb0722ec9209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFactorization(\n",
       "  (user_factors): Embedding(370091, 512)\n",
       "  (item_factors): Embedding(267600, 512)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем user_labels и product_labels\n",
    "with open(models_outputs_dir / 'mf' / 'user_labels.pkl', \"rb\") as f:\n",
    "    user_labels = pickle.load(f)\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'product_labels.pkl', \"rb\") as f:\n",
    "    product_labels = pickle.load(f)\n",
    "\n",
    "# Воссоздаём архитектуру модели\n",
    "num_users = len(user_labels)\n",
    "num_items = len(product_labels)\n",
    "\n",
    "mf_model = MatrixFactorization(num_users, num_items, latent_dim).to(device)\n",
    "\n",
    "# Загружаем веса модели\n",
    "mf_model.load_state_dict(torch.load(models_dir / f'mf_model_latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}.pth'))\n",
    "\n",
    "# Переводим модель в режим предсказания (инференса)\n",
    "mf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31659d1e-482a-4599-bfdb-970f4361de45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12336"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем список тестовых пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "len(user_ids[:len(user_ids) // 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d349a-ecb1-4827-b7dd-5545f7ee8e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0546febf854c4b298aed1aa0a883fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating MF recommendations:   0%|          | 0/3256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Получаем список тестовых пользователей\n",
    "user_ids = test_df['anon_id_encrypred'].unique()\n",
    "\n",
    "# Делаем рекомендации\n",
    "user_recommendations_mf = recommend_mf_batch(\n",
    "    user_ids=user_ids[:len(user_ids) // 10],\n",
    "    model=mf_model,\n",
    "    user_labels=user_labels,\n",
    "    product_labels=product_labels,\n",
    "    df=train_df,\n",
    "    top_k_items=k,\n",
    "    batch_size=2,\n",
    "    filter_already_purchased=filter_already_purchased\n",
    ")\n",
    "\n",
    "with open(models_outputs_dir / 'mf' / 'user_recommendations_mf.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_mf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a94fa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_outputs_dir / 'mf' / 'user_recommendations_mf.pkl', \"rb\") as f:\n",
    "    user_recommendations_mf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1022f56b-2eaa-4714-aff5-82579d3b718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mf = RecommendationDataset(user_recommendations=user_recommendations_mf, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_mf, batch_size=batch_size, num_workers=0, \n",
    "                    collate_fn=lambda batch: collate_fn(batch, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1cc94cdf-56f6-4ad1-8dfb-5e46cc0940ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1e9e9173384f4d8803cb7502633938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for MF model: 0.00151912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1658bdd63e4388a7480b26a1760ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 for MF model: 0.001501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8935286cb64b46208552a0e35c64c4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for MF model: 0.00053080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd35476662464b8fb63c63f77987bc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 for MF model: 0.00087391\n"
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Precision@{k} for MF model: {precision_k:.8f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k)\n",
    "print(f'Recall@{k} for MF model: {recall_k:8f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k)\n",
    "print(f'MAP@{k} for MF model: {map_k:.8f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k)\n",
    "print(f'NDCG@{k} for MF model: {ndcg_k:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30839158-0bd9-4da4-9c35-97c3debca75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>MAP@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Other_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-K</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_users': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBCF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>{'top_k_items': 10, 'top_n_similar_items': 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matrix Factorization</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>{'top_k_items': 10, 'latent_dim': 512, 'filter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model   k  Precision@k  Recall@k     MAP@k    NDCG@k  \\\n",
       "0                 Top-K  10     0.003728  0.003641  0.001437  0.002435   \n",
       "1                Random  10     0.000046  0.000042  0.000009  0.000023   \n",
       "2                  UBCF  10     0.003886  0.003787  0.001568  0.002602   \n",
       "3                  IBCF  10     0.002950  0.002940  0.001048  0.001697   \n",
       "4  Matrix Factorization  10     0.001519  0.001501  0.000531  0.000874   \n",
       "\n",
       "                               Other_hyperparameters  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2  {'top_k_items': 10, 'top_n_similar_users': 20,...  \n",
       "3  {'top_k_items': 10, 'top_n_similar_items': 20,...  \n",
       "4  {'top_k_items': 10, 'latent_dim': 512, 'filter...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_results(model_name='Matrix Factorization', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, round_level=round_level,\n",
    "                  hyperparameters={'top_k_items': k, 'latent_dim': latent_dim, \n",
    "                                   'filter_already_purchased': filter_already_purchased})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "901f6312-e532-4d64-b22c-406b47a03f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5 # top_k_items\n",
    "# n = 100 # n_components\n",
    "\n",
    "# # Функция подготовки user-item матрицы с логарифмом\n",
    "# def prepare_user_item_matrix(df):\n",
    "#     \"\"\"\n",
    "#     Создает user-item матрицу с логарифмом количества покупок.\n",
    "    \n",
    "#     df: DataFrame с колонками ['anon_id_encrypred', 'product_id', 'base_price']\n",
    "    \n",
    "#     Возвращает:\n",
    "#     - user_item_matrix (numpy 2D массив)\n",
    "#     - users_mapping (словарь user_id -> индекс)\n",
    "#     - items_mapping (словарь product_id -> индекс)\n",
    "#     - reverse_users_mapping (словарь индекс -> user_id)\n",
    "#     - reverse_items_mapping (словарь индекс -> product_id)\n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "#     df['log_purchases'] = df.groupby(['anon_id_encrypred', 'product_id'])['base_price'].transform('count')\n",
    "#     df['log_purchases'] = np.log1p(df['log_purchases'])  # log(1 + count)\n",
    "\n",
    "#     # Уникальные пользователи и товары\n",
    "#     users = df['anon_id_encrypred'].unique()\n",
    "#     items = df['product_id'].unique()\n",
    "    \n",
    "#     # Создаем маппинги ID → индекс\n",
    "#     users_mapping = {user: i for i, user in enumerate(users)}\n",
    "#     items_mapping = {item: i for i, item in enumerate(items)}\n",
    "    \n",
    "#     # Обратные маппинги индекс → ID\n",
    "#     reverse_users_mapping = {i: user for user, i in users_mapping.items()}\n",
    "#     reverse_items_mapping = {i: item for item, i in items_mapping.items()}\n",
    "\n",
    "#     # Создаем user-item матрицу\n",
    "#     user_item_matrix = np.zeros((len(users), len(items)))\n",
    "#     for _, row in df.iterrows():\n",
    "#         user_idx = users_mapping[row['anon_id_encrypred']]\n",
    "#         item_idx = items_mapping[row['product_id']]\n",
    "#         user_item_matrix[user_idx, item_idx] = row['log_purchases']\n",
    "    \n",
    "#     return user_item_matrix, users_mapping, items_mapping, reverse_users_mapping, reverse_items_mapping\n",
    "\n",
    "# # Функция вычисления SVD\n",
    "# def compute_svd(user_item_matrix, n_components=n):\n",
    "#     \"\"\"\n",
    "#     Вычисляет SVD-разложение user-item матрицы.\n",
    "    \n",
    "#     user_item_matrix: numpy 2D массив (пользователи x товары)\n",
    "#     n_components: Количество скрытых факторов\n",
    "    \n",
    "#     Возвращает:\n",
    "#     - предсказанную user-item матрицу (numpy 2D массив)\n",
    "#     \"\"\"\n",
    "#     # Выполняем SVD\n",
    "#     U, sigma, Vt = svds(user_item_matrix, k=n_components)\n",
    "    \n",
    "#     # Преобразуем sigma (диагональную) в квадратную матрицу\n",
    "#     sigma = np.diag(sigma)\n",
    "\n",
    "#     # Восстанавливаем предсказанную матрицу рейтингов R = U * Σ * V^T\n",
    "#     predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "    \n",
    "#     return predicted_ratings\n",
    "\n",
    "# # Функция рекомендаций\n",
    "# def recommend_svd(user_id, predicted_matrix, users_mapping, items_mapping, reverse_items_mapping, top_k_items=k):\n",
    "#     \"\"\"\n",
    "#     Для пользователя user_id предсказываем top-K товаров на основе предсказанной матрицы.\n",
    "#     \"\"\"\n",
    "#     if user_id not in users_mapping:\n",
    "#         return []\n",
    "    \n",
    "#     user_idx = users_mapping[user_id]\n",
    "#     predicted_scores = predicted_matrix[user_idx]\n",
    "#     top_item_indices = np.argsort(predicted_scores)[::-1][:top_k_items]\n",
    "#     recommended_items = [reverse_items_mapping[i] for i in top_item_indices]\n",
    "    \n",
    "#     return recommended_items\n",
    "\n",
    "# # Запуск модели\n",
    "# user_item_matrix, users_mapping, items_mapping, reverse_users_mapping, reverse_items_mapping = prepare_user_item_matrix(train_df)\n",
    "# predicted_ratings = compute_svd(user_item_matrix, n_components=n)\n",
    "\n",
    "\n",
    "# user_recommendations_svd = {user: recommend_svd(user, predicted_ratings, users_mapping, items_mapping, reverse_items_mapping, top_k_items=k) \n",
    "#                             for user in tqdm(test_df['anon_id_encrypred'].unique())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324128d7-db5a-439e-b84a-1a7c4e60f824",
   "metadata": {},
   "source": [
    "## Strong Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dfcf5-3ad3-42cf-a453-6852d5bb70e8",
   "metadata": {},
   "source": [
    "### BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f794b4-d88e-472f-bcbb-7087c9574f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые импорты\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import random\n",
    "# from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Импорты для RecSys\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "# from surprise import SVD, Dataset, Reader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.set_per_process_memory_fraction(0.9) # Memory usage limit for MacOS\n",
    "    torch.mps.empty_cache() \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(911)\n",
    "random.seed(911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b518c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps: # or obj.is_cuda\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache() # or torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac253c",
   "metadata": {},
   "source": [
    "#### BERT4Rec Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8124b6-5cc8-42cd-9834-65490e3e04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self, sequences, max_len, mask_prob, num_items, pad_token=0, mask_token=None, is_train=True, external_targets=None):\n",
    "        self.max_len = max_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.num_items = num_items\n",
    "        self.pad_token = pad_token\n",
    "        self.mask_token = mask_token if mask_token is not None else num_items + 1\n",
    "        self.is_train = is_train \n",
    "        self.external_targets = external_targets  # user_id -> true items (list or set)\n",
    "\n",
    "        self.user_ids = []\n",
    "        self.processed_sequences = []\n",
    "        \n",
    "        for user_id, seq in sequences:\n",
    "            self.user_ids.append(user_id)\n",
    "            truncated = seq[-self.max_len:] if len(seq) > self.max_len else seq\n",
    "            padded = truncated + [self.pad_token] * (self.max_len - len(truncated))  # ПАДДИНГ СПРАВА\n",
    "            self.processed_sequences.append(padded)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.user_ids[idx]\n",
    "        seq = self.processed_sequences[idx].copy()\n",
    "\n",
    "        # === Валидационный режим ===\n",
    "        if not self.is_train and self.external_targets is not None:\n",
    "            input_seq = seq\n",
    "            true_items = list(self.external_targets.get(user_id, []))[:self.max_len]\n",
    "\n",
    "            # ПАДДИНГ СПРАВА для labels\n",
    "            padded_labels = true_items + [-100] * (self.max_len - len(true_items))  # -100 — default ignore_index\n",
    "            labels = torch.tensor(padded_labels, dtype=torch.long)\n",
    "\n",
    "            attention_mask = [1 if x != self.pad_token else 0 for x in input_seq]\n",
    "            position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "            return {\n",
    "                \"user_id\": user_id,\n",
    "                \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "                \"labels\": labels,\n",
    "                \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "                \"position_ids\": position_ids\n",
    "            }\n",
    "\n",
    "\n",
    "        # === Тренировочный режим (с гарантией min_masked = 1) ===\n",
    "        input_seq = seq.copy()\n",
    "        target_seq = [-100] * self.max_len\n",
    "\n",
    "        candidate_idxs = [i for i, token in enumerate(seq) if token != self.pad_token]\n",
    "        masked_idxs = [i for i in candidate_idxs if random.random() < self.mask_prob]\n",
    "\n",
    "        # === min_masked = 1 ===\n",
    "        if len(masked_idxs) == 0 and len(candidate_idxs) > 0:\n",
    "            masked_idxs = [random.choice(candidate_idxs)]\n",
    "\n",
    "        for i in masked_idxs:\n",
    "            original_token = seq[i]\n",
    "            prob = random.random()\n",
    "            if prob < 0.9:\n",
    "                input_seq[i] = self.mask_token\n",
    "            elif prob < 0.99:\n",
    "                input_seq[i] = random.randint(1, self.num_items)\n",
    "            else:\n",
    "                input_seq[i] = original_token\n",
    "            target_seq[i] = original_token\n",
    "\n",
    "        attention_mask = [1 if x != self.pad_token else 0 for x in input_seq]\n",
    "        position_ids = torch.arange(self.max_len, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"user_id\": user_id,\n",
    "            \"input_ids\": torch.tensor(input_seq, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(target_seq, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"position_ids\": position_ids\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b5b6164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2019-01-01 00:00:00\n",
      "Max date: 2021-02-18 00:00:00\n",
      "Threshold date (80.0%): 2020-09-15 00:00:00\n",
      "Train shape: (2700604, 21)\n",
      "Test shape: (767603, 21)\n",
      "Минимальный новый индекс: 1\n",
      "Максимальный новый индекс: 306664\n",
      "Количество уникальных товаров: 306664\n",
      "Всего пользователей: 453195\n",
      "Пользователей в тренировочной выборке: 370091\n",
      "Пользователей в тестовой выборке: 195339\n"
     ]
    }
   ],
   "source": [
    "df_sales = pd.read_parquet(interim_data_dir / 'df_sales.parquet')\n",
    "df_sales['order_date'] = pd.to_datetime(df_sales['order_date'])\n",
    "df_sales = df_sales.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# Создаем маппинг оригинальных product_id в новые индексы от 1 до df_sales['product_id'].unique()\n",
    "unique_product_ids = df_sales['product_id'].unique()\n",
    "product_id_to_idx = {product_id: idx + 1 for idx, product_id in enumerate(unique_product_ids)}  # +1 чтобы начинать с 1\n",
    "\n",
    "# Применяем маппинг к данным\n",
    "df_sales['product_idx'] = df_sales['product_id'].map(product_id_to_idx)\n",
    "\n",
    "threshold_level = 0.8\n",
    "min_date = df_sales['order_date'].min()\n",
    "max_date = df_sales['order_date'].max()\n",
    "\n",
    "print(f\"Min date: {min_date}\")\n",
    "print(f\"Max date: {max_date}\")\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "threshold_days = int(total_days * threshold_level)\n",
    "threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "train_df = df_sales[df_sales['order_date'] < threshold_date]\n",
    "test_df = df_sales[df_sales['order_date'] >= threshold_date]\n",
    "\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "\n",
    "# train_df = pd.read_csv(interim_data_dir / 'train_data_by_threshold_date_for_bert4rec.csv')\n",
    "# test_df = pd.read_csv(interim_data_dir / 'test_data_by_threshold_date_for_bert4rec.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "\n",
    "print(\"Минимальный новый индекс:\", df_sales['product_idx'].min())  # Должно быть 1\n",
    "print(\"Максимальный новый индекс:\", df_sales['product_idx'].max())  # Должно быть равно количеству уникальных товаров\n",
    "print(\"Количество уникальных товаров:\", df_sales['product_id'].nunique())\n",
    "print(f\"Всего пользователей: {len(df_sales['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тренировочной выборке: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тестовой выборке: {len(test_df['anon_id_encrypred'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70c0cb7-b5be-49a9-ab82-e373f9229888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перцентили длин последовательностей:\n",
      "0.25     1.0\n",
      "0.50     2.0\n",
      "0.75     6.0\n",
      "0.90    17.0\n",
      "0.95    30.0\n",
      "0.99    90.0\n",
      "dtype: float64\n",
      "Максимальная длина последовательности: 2446\n"
     ]
    }
   ],
   "source": [
    "# Группируем по пользователям и считаем длину последовательности для каждого\n",
    "user_sequence_lengths = df_sales.groupby('anon_id_encrypred').size()\n",
    "percentiles = user_sequence_lengths.quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "# Находим максимальную длину последовательности\n",
    "max_sequence_length = user_sequence_lengths.max()\n",
    "print(\"Перцентили длин последовательностей:\")\n",
    "print(percentiles)\n",
    "print(f\"Максимальная длина последовательности: {max_sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "819bd52e-45a6-4cd9-b01f-78a5e1a7476d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример последовательности для пользователя \u0004\u000eqqwrtrxq: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Создаём последовательности покупок для каждого пользователя\n",
    "train_sequences = train_df.groupby('anon_id_encrypred')['product_idx'].apply(list).to_dict()\n",
    "test_sequences = test_df.groupby('anon_id_encrypred')['product_idx'].apply(list).to_dict()\n",
    "\n",
    "# Проверяем пример последовательности для одного пользователя\n",
    "print(f\"Пример последовательности для пользователя {list(train_sequences.keys())[0]}: {train_sequences[list(train_sequences.keys())[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2714adc-e30b-4b91-924e-3087dd732895",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 15          # Максимальная длина последовательности\n",
    "mask_prob = 0.5       # Вероятность маскирования\n",
    "num_items = df_sales['product_idx'].nunique()  # Количество уникальных товаров\n",
    "\n",
    "# Преобразуем словари последовательностей в списки кортежей (user_id, sequence)\n",
    "train_sequences_list = list(train_sequences.items())\n",
    "test_sequences_list = list(test_sequences.items())\n",
    "\n",
    "train_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,     # <-- train для input’ов\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=False,\n",
    "    external_targets=test_sequences  # <-- таргеты из test_df\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8975b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One object from `train_loader`\n",
      "User ID: wyyypqqtpvsvsytu\n",
      "Input IDs: tensor([306665,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0])\n",
      "Labels: tensor([158158,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   -100,   -100,   -100,   -100])\n",
      "Attention Mask: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Position IDs: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n",
      "\n",
      "One object from `test_dataset`\n",
      "User ID: \u0004\u000eqqwrtrxq\n",
      "Input IDs: tensor([1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Labels: tensor([   4,    5, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100])\n",
      "Attention Mask: tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Position IDs: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# Пример использования DataLoader\n",
    "for batch in train_loader:\n",
    "    print('One object from `train_loader`')\n",
    "    user_ids = batch['user_id'][0]\n",
    "    input_ids = batch['input_ids'][0]\n",
    "    labels = batch['labels'][0]\n",
    "    attention_mask = batch['attention_mask'][0]\n",
    "    position_ids = batch['position_ids'][0]\n",
    "    \n",
    "    print(\"User ID:\", user_ids)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Position IDs:\", position_ids)\n",
    "    break  # Остановимся после первого батча для примера\n",
    "\n",
    "print()\n",
    "\n",
    "for batch in test_loader:\n",
    "    print('One object from `test_dataset`')\n",
    "    user_ids = batch['user_id'][0]\n",
    "    input_ids = batch['input_ids'][0]\n",
    "    labels = batch['labels'][0]\n",
    "    attention_mask = batch['attention_mask'][0]\n",
    "    position_ids = batch['position_ids'][0]\n",
    "    \n",
    "    print(\"User ID:\", user_ids)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Position IDs:\", position_ids)\n",
    "    break  # Остановимся после первого батча для примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "735c4fde-5420-49ab-b517-b5ac14a445de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_items,\n",
    "                 max_len,\n",
    "                 embedding_dim=256,\n",
    "                 num_layers=6,\n",
    "                 num_heads=4,\n",
    "                 dropout=0.1,\n",
    "                 ffn_dim=1024):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # PAD = 0, items = 1..num_items, MASK = num_items+1\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2,\n",
    "                                            embedding_dim,\n",
    "                                            padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layer,\n",
    "                                              num_layers=num_layers)\n",
    "\n",
    "        # ——— Новая классифицирующая голова ———\n",
    "        # Проецируем обратно в embedding_dim, чтобы можно было dot-product'ом\n",
    "        self.fc_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim * 2),\n",
    "            nn.Linear(embedding_dim * 2, embedding_dim, bias=False),\n",
    "            # nn.LayerNorm(embedding_dim),  \n",
    "        )\n",
    "        # bias для logits по словарю\n",
    "        self.vocab_bias = nn.Parameter(torch.zeros(num_items + 2))\n",
    "\n",
    "        # weight-tying: последний Linear выдаёт embedding_dim,\n",
    "        # а дальше dot(item_emb.weight.T) дает logits по vocab\n",
    "        # (embedding_dim == self.item_embeddings.embedding_dim)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # эмбеддинги\n",
    "        nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
    "        # nn.init.normal_(self.item_embeddings.weight, 0.0, 0.02)\n",
    "        nn.init.normal_(self.position_embeddings.weight, 0.0, 0.02)\n",
    "\n",
    "        # трансформер\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "\n",
    "        # голова\n",
    "        nn.init.xavier_uniform_(self.fc_head[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc_head[3].weight)\n",
    "        nn.init.zeros_(self.vocab_bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        B, L = input_ids.size()\n",
    "        # 1) Embeddings + scale\n",
    "        item_embeds = self.item_embeddings(input_ids)             # (B,L,dim)\n",
    "        pos_embeds  = self.position_embeddings(position_ids)      # (L,dim) -> broadcast\n",
    "        x = (item_embeds + pos_embeds) * math.sqrt(self.embedding_dim)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # 2) Causal + padding masks\n",
    "        src_key_padding_mask = (attention_mask == 0)              # (B,L)\n",
    "\n",
    "        # 3) Transformer\n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)  # (B,L,dim)\n",
    "\n",
    "        # 4) Head → back to embedding space\n",
    "        h = self.fc_head(x)                                      # (B,L,dim)\n",
    "\n",
    "        # 5) Dot-product with item_embeddings + bias → logits\n",
    "        logits = torch.matmul(h, self.item_embeddings.weight.T)  # (B,L,num_items+2)\n",
    "        logits = logits + self.vocab_bias                        # broadcast bias\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "197e78f4-b437-4234-966f-e10ea4a472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    save_path: str,\n",
    "    num_epochs: int = 5,\n",
    "    log_interval: int = 50,\n",
    "    scheduler    = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Тренирует модель с выводом прогресса через tqdm и периодическим логированием лосса.\n",
    "    Возвращает модель и историю лоссов.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100, label_smoothing=0.1) # label_smoothing=0.1 размывание таргета\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        # running_loss = 0.0\n",
    "        running, acc_steps = 0.0, 0\n",
    "\n",
    "        for n,p in model.named_parameters():\n",
    "            assert torch.all(torch.isfinite(p)), f\"NaN в параметре {n}\"\n",
    "\n",
    "\n",
    "        # оборачиваем сам loader, а затем делаем enumerate над tqdm-ом\n",
    "        pbar_train = tqdm(train_loader, total=len(train_loader),\n",
    "                          desc=f\"[Epoch {epoch}/{num_epochs}] Train\")\n",
    "        for batch_idx, batch in enumerate(pbar_train, 1):\n",
    "            try:\n",
    "                input_ids      = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                position_ids   = batch['position_ids'].to(device)\n",
    "                labels         = batch['labels'].to(device)\n",
    "\n",
    "                # === ✅ ДОПОЛНИТЕЛЬНАЯ ПРОВЕРКА ПЕРЕД LOSS ===\n",
    "                # print(f\"[Batch {batch_idx}] input_ids: min={input_ids.min().item()}, max={input_ids.max().item()}\")\n",
    "                # print(f\"[Batch {batch_idx}] labels:    min={labels[labels != -100].min().item() if (labels != -100).any() else 'n/a'}, \"\n",
    "                #     f\"max={labels[labels != -100].max().item() if (labels != -100).any() else 'n/a'}\")\n",
    "\n",
    "                # Проверка на допустимые значения\n",
    "                assert torch.all((labels == -100) | ((labels > 0) & (labels < num_items + 1))), \\\n",
    "                    f\"Invalid label value found! batch_idx={batch_idx}\"\n",
    "\n",
    "                assert input_ids.max() < num_items + 2, f\"input_ids contain invalid token! batch_idx={batch_idx}\"\n",
    "\n",
    "                if not (labels != -100).any():\n",
    "                    print(f\"[Batch {batch_idx}] All masked, skipping\")\n",
    "                    pbar_train.update(1)\n",
    "                    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(input_ids, attention_mask, position_ids)\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "\n",
    "                if not torch.isfinite(loss):\n",
    "                    print(f\"!!! NaN loss at epoch {epoch} batch {batch_idx}\")\n",
    "\n",
    "                    for name, p in model.named_parameters():\n",
    "                        if not torch.all(torch.isfinite(p)):\n",
    "                            bad = (~torch.isfinite(p)).sum().item()\n",
    "                            print(f\"  → {name}: {bad} bad entries\")\n",
    "                    raise RuntimeError(\"Stop: loss became NaN\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "                running += loss.item()\n",
    "                acc_steps += 1\n",
    "\n",
    "                if batch_idx % 500 == 0:\n",
    "                    print(f\"[Batch {batch_idx}] shape: input_ids={input_ids.shape}, labels={labels.shape}, outputs={outputs.shape}\")\n",
    "                    current_lr = scheduler.get_last_lr()[0]\n",
    "                    print(f\"[Batch {batch_idx}] lr = {current_lr:.8f}\")\n",
    "\n",
    "\n",
    "                # log n первых/каждый log_interval\n",
    "                if batch_idx == 1 or (acc_steps % log_interval == 0):\n",
    "                    avg = running / acc_steps\n",
    "                    pbar_train.set_postfix(batch_loss=f\"{avg:.4f}\")\n",
    "                    train_loss_history.append(avg)\n",
    "                    running, acc_steps = 0.0, 0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error at batch {batch_idx}: {e}\")\n",
    "\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        # val_running = 0.0\n",
    "        val_running, val_batches = 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar_val = tqdm(val_loader, total=len(val_loader),\n",
    "                            desc=f\"[Epoch {epoch}/{num_epochs}] Val  \")\n",
    "            for batch in pbar_val:\n",
    "                input_ids      = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                position_ids   = batch['position_ids'].to(device)\n",
    "                labels         = batch['labels'].to(device)\n",
    "\n",
    "                if (labels != -100).any():           # есть валид-таргеты\n",
    "                    outputs = model(input_ids, attention_mask, position_ids)\n",
    "                    loss    = criterion(\n",
    "                        outputs.view(-1, outputs.size(-1)),\n",
    "                        labels.view(-1)\n",
    "                    )\n",
    "                    val_running += loss.item()\n",
    "                    val_batches += 1\n",
    "                    pbar_val.set_postfix(val_loss=f\"{loss.item():.4f}\")\n",
    "                else:\n",
    "                    pbar_val.set_postfix(val_loss=\"skip\")\n",
    "\n",
    "        avg_val = val_running / val_batches if val_batches else float(\"nan\")\n",
    "        val_loss_history.append(avg_val)\n",
    "        print(f\"Epoch {epoch}: val_loss = {avg_val:.4f}\")\n",
    "\n",
    "        # сохраняем лучшую модель\n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"→ saved new best model  (val_loss {best_val_loss:.4f})\\n\")\n",
    "\n",
    "    return model, train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5347caca-e80e-413c-8b1a-0963c5debeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "embedding_dim=1024\n",
    "num_layers=12\n",
    "num_heads=8\n",
    "ffn_dim=4096\n",
    "dropout=0.1\n",
    "lr=1e-4\n",
    "log_interval=100\n",
    "\n",
    "model = BERT4RecModel(\n",
    "    num_items    = num_items,\n",
    "    max_len      = max_len,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_layers   =num_layers,\n",
    "    num_heads    =num_heads,\n",
    "    ffn_dim      =ffn_dim,\n",
    "    dropout      =dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=lr,\n",
    "                  weight_decay=1e-3)\n",
    "\n",
    "num_epochs   = 3\n",
    "total_steps  = num_epochs * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler = LambdaLR(optimizer,\n",
    "    lr_lambda=lambda step: (step / warmup_steps if step < warmup_steps\n",
    "        else max(0.0, (total_steps - step) / float(max(1, total_steps - warmup_steps)))\n",
    "    )\n",
    ")\n",
    "\n",
    "save_path = models_dir / f'bert4rec_model_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07196eb4-b595-40fd-b09d-e59cb716234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4RecModel(\n",
       "  (item_embeddings): Embedding(306666, 1024, padding_idx=0)\n",
       "  (position_embeddings): Embedding(15, 1024)\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_head): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c20fc7a8-4bef-4b0a-aae7-6d1cad1448fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855e2050b01f4c709fed5c0e11d486cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1/3] Train:   0%|          | 0/11566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 500] shape: input_ids=torch.Size([32, 15]), labels=torch.Size([32, 15]), outputs=torch.Size([32, 15, 306666])\n",
      "[Batch 500] lr = 0.00001441\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_model, train_losses, val_losses = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m torch.save(trained_model.state_dict(), models_dir / \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLAST_EPOCH_bert4rec_model_embedding_dim_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_epochs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_lr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_max_len_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_mask_prob_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_num_layers_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_num_heads_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_ffn_dim_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mffn_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_dropout_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_num_items_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mПоследний train loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_losses[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, save_path, num_epochs, log_interval, scheduler)\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mStop: loss became NaN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m optimizer.step()\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:220\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    218\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    219\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/Recommender_System_with_LLM/venv/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:176\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    174\u001b[39m clip_coef_clamped_device = clip_coef_clamped.to(device)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_grads:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_coef_clamped_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trained_model, train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    log_interval=log_interval,\n",
    "    save_path=save_path,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "torch.save(trained_model.state_dict(), models_dir / f'LAST_EPOCH_bert4rec_model_embedding_dim_{embedding_dim}_epochs_{num_epochs}_lr_{lr}_max_len_{max_len}_mask_prob_{mask_prob}_num_layers_{num_layers}_num_heads_{num_heads}_ffn_dim_{ffn_dim}_dropout_{dropout}_num_items_{num_items}.pth')\n",
    "\n",
    "print(f\"Последний train loss = {train_losses[-1]:.4f}\")\n",
    "print(f\"Последний val   loss = {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981420d9-a16e-420d-9e90-977ee915eef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train_loss(train_losses, log_interval, name='Loss Over Batches'):\n",
    "    \"\"\"\n",
    "    Визуализация train_losses.\n",
    "    \n",
    "    :param train_losses: Список значений потерь на тренировке.\n",
    "    :param log_interval: Интервал логирования (для корректной оси X).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Ось X: количество батчей\n",
    "    x = [i * log_interval for i in range(len(train_losses))]\n",
    "    \n",
    "    # Отрисовка графика\n",
    "    plt.plot(x, train_losses, label='Train Loss', marker='o', color='blue', linestyle='-', linewidth=2, markersize=5)\n",
    "    \n",
    "    # Настройки графика\n",
    "    plt.title(name, fontsize=16)\n",
    "    plt.xlabel('Batches', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Отображение графика\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования после обучения\n",
    "plot_train_loss(train_losses, log_interval=log_interval, name='Training Loss Over Batches')\n",
    "plot_train_loss(val_losses, log_interval=100, name='Validation Loss Over Batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c47e6d",
   "metadata": {},
   "source": [
    "#### BERT4Rec + Content embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d448c1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://st-cdn.tsum.com/int/height/1526//i/1e/32/23/32/1e322332-68be-3e58-94eb-e908a6dc7505.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.iloc[2]['photo_analytics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32ab9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://st-cdn.tsum.com/int/height/1526//i/03/24/d3/2f/0324d32f-0c3a-3823-bff0-6f8c5ec213fe.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.iloc[3]['photo_analytics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fb03638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>sizeid</th>\n",
       "      <th>size_title</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>base_price</th>\n",
       "      <th>net_price</th>\n",
       "      <th>sale_percentage</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163213</th>\n",
       "      <td>wyyypqqtprrswrqy</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11579616</td>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-svetlo-bezh...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/cd/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268731</th>\n",
       "      <td>wyyypqqtpryssyvw</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11034409</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>62050.0</td>\n",
       "      <td>48912.83</td>\n",
       "      <td>0.211719</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-bezhevyi-id...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464562</th>\n",
       "      <td>wyyypqqtptsrtxut</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11034409</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-bezhevyi-id...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865980</th>\n",
       "      <td>wyyyrqqtqqstyqux</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>E</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11579616</td>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-svetlo-bezh...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/cd/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033917</th>\n",
       "      <td>wyyysqqtqptxquwv</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11034409</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>62050.0</td>\n",
       "      <td>62050.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-bezhevyi-id...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574895</th>\n",
       "      <td>wyyypqqtqwwvsqwu</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Хаки</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>12544421</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-khaki-id125...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781541</th>\n",
       "      <td>wyyypqqtqxvusxuy</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Хаки</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>E</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>12544421</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>37250.0</td>\n",
       "      <td>37250.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-khaki-id125...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337530</th>\n",
       "      <td>wyyypvqpqqsxtypq</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Хаки</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>E</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>12544421</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>18200.00</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-khaki-id125...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612345</th>\n",
       "      <td>wyyypvqpquxrwqvq</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Хаки</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>E</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>12544421</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>24850.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-khaki-id125...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345658</th>\n",
       "      <td>wyyysqqtqpyvtwts</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Хаки</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>E</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>12544421</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>37250.0</td>\n",
       "      <td>28317.25</td>\n",
       "      <td>0.239805</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-khaki-id125...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/26/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred color_base sizeid size_title  \\\n",
       "163213   wyyypqqtprrswrqy           pyrtvyt    Бежевый    105        105   \n",
       "268731   wyyypqqtpryssyvw           pyrtvyt    Бежевый    105        105   \n",
       "464562   wyyypqqtptsrtxut           pyrtvyt    Бежевый    105        105   \n",
       "2865980  wyyyrqqtqqstyqux           pyrtvyt    Бежевый    105        105   \n",
       "3033917  wyyysqqtqptxquwv           pyrtvyt    Бежевый    105        105   \n",
       "...                   ...               ...        ...    ...        ...   \n",
       "1574895  wyyypqqtqwwvsqwu           pyrtvyt       Хаки     95         95   \n",
       "1781541  wyyypqqtqxvusxuy           pyrtvyt       Хаки     95         95   \n",
       "2337530  wyyypvqpqqsxtypq           pyrtvyt       Хаки     95         95   \n",
       "2612345  wyyypvqpquxrwqvq           pyrtvyt       Хаки     95         95   \n",
       "3345658  wyyysqqtqpyvtwts           pyrtvyt       Хаки     95         95   \n",
       "\n",
       "         order_date store       brand               ktt1                ktt2  \\\n",
       "163213   2019-05-20     T  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "268731   2019-09-03     T  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "464562   2019-04-23     T  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "2865980  2019-03-30     E  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "3033917  2020-02-17     T  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "...             ...   ...         ...                ...                 ...   \n",
       "1574895  2019-06-07     T  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "1781541  2020-01-31     E  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "2337530  2020-12-31     E  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "2612345  2020-12-13     E  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "3345658  2020-02-28     E  Loro Piana  Товары для мужчин  Аксессуары из кожи   \n",
       "\n",
       "          ktt3                 ktt4            title  product_id  \\\n",
       "163213   Ремни  Ремень классический  Замшевый ремень    11579616   \n",
       "268731   Ремни  Ремень классический  Замшевый ремень    11034409   \n",
       "464562   Ремни  Ремень классический  Замшевый ремень    11034409   \n",
       "2865980  Ремни  Ремень классический  Замшевый ремень    11579616   \n",
       "3033917  Ремни  Ремень классический  Замшевый ремень    11034409   \n",
       "...        ...                  ...              ...         ...   \n",
       "1574895  Ремни  Ремень классический  Замшевый ремень    12544421   \n",
       "1781541  Ремни  Ремень классический  Замшевый ремень    12544421   \n",
       "2337530  Ремни  Ремень классический  Замшевый ремень    12544421   \n",
       "2612345  Ремни  Ремень классический  Замшевый ремень    12544421   \n",
       "3345658  Ремни  Ремень классический  Замшевый ремень    12544421   \n",
       "\n",
       "        product_created_at  base_price  net_price  sale_percentage  \\\n",
       "163213          2016-12-12     58200.0   58200.00         0.000000   \n",
       "268731          2016-04-10     62050.0   48912.83         0.211719   \n",
       "464562          2016-04-10     58200.0   58200.00         0.000000   \n",
       "2865980         2016-12-12     58200.0   58200.00         0.000000   \n",
       "3033917         2016-04-10     62050.0   62050.00         0.000000   \n",
       "...                    ...         ...        ...              ...   \n",
       "1574895         2018-01-23     58200.0   58200.00         0.000000   \n",
       "1781541         2018-01-23     37250.0   37250.00         0.000000   \n",
       "2337530         2018-01-23     24850.0   18200.00         0.267606   \n",
       "2612345         2018-01-23     24850.0   24850.00         0.000000   \n",
       "3345658         2018-01-23     37250.0   28317.25         0.239805   \n",
       "\n",
       "                                                      slug  \\\n",
       "163213   1835785-zamshevyi-remen-loro-piana-svetlo-bezh...   \n",
       "268731   1835785-zamshevyi-remen-loro-piana-bezhevyi-id...   \n",
       "464562   1835785-zamshevyi-remen-loro-piana-bezhevyi-id...   \n",
       "2865980  1835785-zamshevyi-remen-loro-piana-svetlo-bezh...   \n",
       "3033917  1835785-zamshevyi-remen-loro-piana-bezhevyi-id...   \n",
       "...                                                    ...   \n",
       "1574895  1835785-zamshevyi-remen-loro-piana-khaki-id125...   \n",
       "1781541  1835785-zamshevyi-remen-loro-piana-khaki-id125...   \n",
       "2337530  1835785-zamshevyi-remen-loro-piana-khaki-id125...   \n",
       "2612345  1835785-zamshevyi-remen-loro-piana-khaki-id125...   \n",
       "3345658  1835785-zamshevyi-remen-loro-piana-khaki-id125...   \n",
       "\n",
       "                                           photo_analytics  \n",
       "163213   https://st-cdn.tsum.com/int/height/1526//i/cd/...  \n",
       "268731   https://st-cdn.tsum.com/int/height/1526//i/23/...  \n",
       "464562   https://st-cdn.tsum.com/int/height/1526//i/23/...  \n",
       "2865980  https://st-cdn.tsum.com/int/height/1526//i/cd/...  \n",
       "3033917  https://st-cdn.tsum.com/int/height/1526//i/23/...  \n",
       "...                                                    ...  \n",
       "1574895  https://st-cdn.tsum.com/int/height/1526//i/26/...  \n",
       "1781541  https://st-cdn.tsum.com/int/height/1526//i/26/...  \n",
       "2337530  https://st-cdn.tsum.com/int/height/1526//i/26/...  \n",
       "2612345  https://st-cdn.tsum.com/int/height/1526//i/26/...  \n",
       "3345658  https://st-cdn.tsum.com/int/height/1526//i/26/...  \n",
       "\n",
       "[234 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[filtered['articul_encrypred']=='pyrtvyt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a93fcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306672"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_products['photo_analytics'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbadd6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://st-cdn.tsum.com/int/height/1526//i/cd/16/40/11/cd164011-06a5-3837-b250-bbaf49a8ba87.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[filtered['articul_encrypred']=='pyrtvyt'].iloc[0]['photo_analytics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10f4a99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://st-cdn.tsum.com/int/height/1526//i/23/77/ab/cd/2377abcd-c0d3-35bf-9a87-72e340d19c3f.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered[filtered['articul_encrypred']=='pyrtvyt'].iloc[1]['photo_analytics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91379e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id_encrypred</th>\n",
       "      <th>articul_encrypred</th>\n",
       "      <th>color_base</th>\n",
       "      <th>sizeid</th>\n",
       "      <th>size_title</th>\n",
       "      <th>order_date</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>ktt1</th>\n",
       "      <th>ktt2</th>\n",
       "      <th>ktt3</th>\n",
       "      <th>ktt4</th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_created_at</th>\n",
       "      <th>base_price</th>\n",
       "      <th>net_price</th>\n",
       "      <th>sale_percentage</th>\n",
       "      <th>slug</th>\n",
       "      <th>photo_analytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3400023</th>\n",
       "      <td>wyyysqqtqqxrwrvs</td>\n",
       "      <td>pstrpxs</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>41-42</td>\n",
       "      <td>41-42</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>E</td>\n",
       "      <td>Falke</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Домашняя, пляжная одежда</td>\n",
       "      <td>Чулочно-носочные изделия</td>\n",
       "      <td>Носки</td>\n",
       "      <td>Хлопковые носки Tiago</td>\n",
       "      <td>6150794</td>\n",
       "      <td>2014-10-11</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2007.82</td>\n",
       "      <td>0.061766</td>\n",
       "      <td>1253192-khlopkovye-noski-tiago-falke-svetlo-be...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/ea/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876155</th>\n",
       "      <td>wyyypqqtqypstvpt</td>\n",
       "      <td>pstrpxs</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>45-46</td>\n",
       "      <td>45-46</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>E</td>\n",
       "      <td>Falke</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Домашняя, пляжная одежда</td>\n",
       "      <td>Чулочно-носочные изделия</td>\n",
       "      <td>Носки</td>\n",
       "      <td>Хлопковые носки Tiago</td>\n",
       "      <td>6118244</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>2140.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1253192-khlopkovye-noski-tiago-falke-svetlo-be...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/5a/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040626</th>\n",
       "      <td>wyyysqqtqptysyvy</td>\n",
       "      <td>pxuuvtv</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>T</td>\n",
       "      <td>James Perse</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда джерси</td>\n",
       "      <td>Поло джерси</td>\n",
       "      <td>Хлопковое поло</td>\n",
       "      <td>12417434</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4340.83</td>\n",
       "      <td>0.457057</td>\n",
       "      <td>1944757-khlopkovoe-polo-james-perse-bezhevyi-i...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/1e/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612892</th>\n",
       "      <td>wyyypvqpquxryvwp</td>\n",
       "      <td>pxuuvtv</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>E</td>\n",
       "      <td>James Perse</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Одежда</td>\n",
       "      <td>Одежда джерси</td>\n",
       "      <td>Поло джерси</td>\n",
       "      <td>Хлопковое поло</td>\n",
       "      <td>12046519</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>15450.0</td>\n",
       "      <td>12360.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1944757-khlopkovoe-polo-james-perse-bezhevyi</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/03/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163213</th>\n",
       "      <td>wyyypqqtprrswrqy</td>\n",
       "      <td>pyrtvyt</td>\n",
       "      <td>Бежевый</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>T</td>\n",
       "      <td>Loro Piana</td>\n",
       "      <td>Товары для мужчин</td>\n",
       "      <td>Аксессуары из кожи</td>\n",
       "      <td>Ремни</td>\n",
       "      <td>Ремень классический</td>\n",
       "      <td>Замшевый ремень</td>\n",
       "      <td>11579616</td>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>58200.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835785-zamshevyi-remen-loro-piana-svetlo-bezh...</td>\n",
       "      <td>https://st-cdn.tsum.com/int/height/1526//i/cd/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anon_id_encrypred articul_encrypred color_base sizeid size_title  \\\n",
       "3400023  wyyysqqtqqxrwrvs           pstrpxs    Бежевый  41-42      41-42   \n",
       "1876155  wyyypqqtqypstvpt           pstrpxs    Бежевый  45-46      45-46   \n",
       "3040626  wyyysqqtqptysyvy           pxuuvtv    Бежевый      0         44   \n",
       "2612892  wyyypvqpquxryvwp           pxuuvtv    Бежевый      5         54   \n",
       "163213   wyyypqqtprrswrqy           pyrtvyt    Бежевый    105        105   \n",
       "\n",
       "         order_date store        brand               ktt1  \\\n",
       "3400023  2019-03-27     E        Falke  Товары для мужчин   \n",
       "1876155  2019-03-28     E        Falke  Товары для мужчин   \n",
       "3040626  2019-03-04     T  James Perse  Товары для мужчин   \n",
       "2612892  2020-04-08     E  James Perse  Товары для мужчин   \n",
       "163213   2019-05-20     T   Loro Piana  Товары для мужчин   \n",
       "\n",
       "                             ktt2                      ktt3  \\\n",
       "3400023  Домашняя, пляжная одежда  Чулочно-носочные изделия   \n",
       "1876155  Домашняя, пляжная одежда  Чулочно-носочные изделия   \n",
       "3040626                    Одежда             Одежда джерси   \n",
       "2612892                    Одежда             Одежда джерси   \n",
       "163213         Аксессуары из кожи                     Ремни   \n",
       "\n",
       "                        ktt4                  title  product_id  \\\n",
       "3400023                Носки  Хлопковые носки Tiago     6150794   \n",
       "1876155                Носки  Хлопковые носки Tiago     6118244   \n",
       "3040626          Поло джерси         Хлопковое поло    12417434   \n",
       "2612892          Поло джерси         Хлопковое поло    12046519   \n",
       "163213   Ремень классический        Замшевый ремень    11579616   \n",
       "\n",
       "        product_created_at  base_price  net_price  sale_percentage  \\\n",
       "3400023         2014-10-11      2140.0    2007.82         0.061766   \n",
       "1876155         2014-10-09      2140.0    2140.00         0.000000   \n",
       "3040626         2017-11-24      7995.0    4340.83         0.457057   \n",
       "2612892         2017-05-30     15450.0   12360.00         0.200000   \n",
       "163213          2016-12-12     58200.0   58200.00         0.000000   \n",
       "\n",
       "                                                      slug  \\\n",
       "3400023  1253192-khlopkovye-noski-tiago-falke-svetlo-be...   \n",
       "1876155  1253192-khlopkovye-noski-tiago-falke-svetlo-be...   \n",
       "3040626  1944757-khlopkovoe-polo-james-perse-bezhevyi-i...   \n",
       "2612892       1944757-khlopkovoe-polo-james-perse-bezhevyi   \n",
       "163213   1835785-zamshevyi-remen-loro-piana-svetlo-bezh...   \n",
       "\n",
       "                                           photo_analytics  \n",
       "3400023  https://st-cdn.tsum.com/int/height/1526//i/ea/...  \n",
       "1876155  https://st-cdn.tsum.com/int/height/1526//i/5a/...  \n",
       "3040626  https://st-cdn.tsum.com/int/height/1526//i/1e/...  \n",
       "2612892  https://st-cdn.tsum.com/int/height/1526//i/03/...  \n",
       "163213   https://st-cdn.tsum.com/int/height/1526//i/cd/...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales = pd.read_parquet(interim_data_dir / 'df_sales.parquet')\n",
    "\n",
    "# Группировка по color_base и articul_encrypred\n",
    "grouped = df_sales.groupby(['color_base', 'articul_encrypred'])\n",
    "\n",
    "# Фильтрация групп, где есть разные sizeid и разные product_id\n",
    "filtered = grouped.filter(\n",
    "    lambda x: x['sizeid'].nunique() > 1 and x['product_id'].nunique() > 1\n",
    ")\n",
    "\n",
    "# Сортировка для удобства\n",
    "filtered = filtered.sort_values(by=['color_base', 'articul_encrypred', 'sizeid'])\n",
    "\n",
    "# Просмотр нескольких строк\n",
    "filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_parquet(interim_data_dir / 'df_sales.parquet')[['anon_id_encrypred', 'articul_encrypred', 'color_base', 'sizeid',\n",
    "       'size_title', 'order_date', 'store', 'brand', 'ktt1', 'ktt2', 'ktt3',\n",
    "       'ktt4', 'title', 'product_id', 'product_created_at', 'base_price',\n",
    "       'net_price', 'sale_percentage', 'slug', 'photo_analytics']]\n",
    "df_sales['order_date'] = pd.to_datetime(df_sales['order_date'])\n",
    "df_sales = df_sales.sort_values(by=['anon_id_encrypred', 'order_date'])\n",
    "\n",
    "# Создаем маппинг оригинальных product_id в новые индексы от 1 до df_sales['product_id'].unique()\n",
    "unique_product_ids = df_sales['product_id'].unique()\n",
    "product_id_to_idx = {product_id: idx + 1 for idx, product_id in enumerate(unique_product_ids)}  # +1 чтобы начинать с 1\n",
    "\n",
    "# Применяем маппинг к данным\n",
    "df_sales['product_idx'] = df_sales['product_id'].map(product_id_to_idx)\n",
    "\n",
    "threshold_level = 0.8\n",
    "min_date = df_sales['order_date'].min()\n",
    "max_date = df_sales['order_date'].max()\n",
    "\n",
    "print(f\"Min date: {min_date}\")\n",
    "print(f\"Max date: {max_date}\")\n",
    "\n",
    "total_days = (max_date - min_date).days\n",
    "threshold_days = int(total_days * threshold_level)\n",
    "threshold_date = min_date + pd.Timedelta(days=threshold_days)\n",
    "\n",
    "print(f\"Threshold date ({round(threshold_level * 100, 0)}%): {threshold_date}\")\n",
    "\n",
    "train_df = df_sales[df_sales['order_date'] < threshold_date]\n",
    "test_df = df_sales[df_sales['order_date'] >= threshold_date]\n",
    "\n",
    "# train_df.to_csv(interim_data_dir / 'train_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "# test_df.to_csv(interim_data_dir / 'test_data_by_threshold_date_for_bert4rec.csv', index=False)\n",
    "\n",
    "# train_df = pd.read_csv(interim_data_dir / 'train_data_by_threshold_date_for_bert4rec.csv')\n",
    "# test_df = pd.read_csv(interim_data_dir / 'test_data_by_threshold_date_for_bert4rec.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "\n",
    "test_user_to_true_items = test_df.groupby('anon_id_encrypred')['product_id'].apply(set).to_dict()\n",
    "\n",
    "print(\"Минимальный новый индекс:\", df_sales['product_idx'].min())  # Должно быть 1\n",
    "print(\"Максимальный новый индекс:\", df_sales['product_idx'].max())  # Должно быть равно количеству уникальных товаров\n",
    "print(\"Количество уникальных товаров:\", df_sales['product_id'].nunique())\n",
    "print(f\"Всего пользователей: {len(df_sales['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тренировочной выборке: {len(train_df['anon_id_encrypred'].unique())}\")\n",
    "print(f\"Пользователей в тестовой выборке: {len(test_df['anon_id_encrypred'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964ddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d39e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bd300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70412d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для параллельной генерации рекомендаций (на входе батч из тестового DataLoader)\n",
    "def generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=10, device=device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        position_ids = position_ids.to(device)\n",
    "        \n",
    "        # Получаем выходы модели: [B, seq_len, num_items+1]\n",
    "        outputs = model(input_ids, attention_mask, position_ids)\n",
    "        # Берем логиты последнего токена (последний временной шаг)\n",
    "        logits = outputs[:, -1, :]  # размер [B, num_items+1]\n",
    "        # Выбираем топ-k рекомендаций для каждого примера\n",
    "        recs = torch.topk(logits, k=k, dim=-1).indices\n",
    "    return recs\n",
    "\n",
    "# Функция для последовательной генерации рекомендаций для одного пользователя\n",
    "def generate_sequential_recommendations(model, initial_sequence, max_len, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Генерирует последовательные рекомендации (авторегрессивно) для одного пользователя.\n",
    "    \n",
    "    :param initial_sequence: Исходная последовательность (список int) без паддинга.\n",
    "    :param max_len: Максимальная длина последовательности, с которой обучалась модель.\n",
    "    :param k: Количество генерируемых рекомендаций.\n",
    "    :param device: Устройство.\n",
    "    :return: Список сгенерированных рекомендаций.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated = []\n",
    "    current_seq = initial_sequence.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(k):\n",
    "            # Если длина последовательности меньше max_len – дополняем слева паддингом (значение 0)\n",
    "            if len(current_seq) < max_len:\n",
    "                padded_seq = [0] * (max_len - len(current_seq)) + current_seq\n",
    "            else:\n",
    "                padded_seq = current_seq[-max_len:]\n",
    "            \n",
    "            input_ids = torch.tensor(padded_seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            attention_mask = (input_ids != 0).long()\n",
    "            position_ids = torch.arange(max_len, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, position_ids)  # [1, max_len, num_items+1]\n",
    "            logits = outputs[:, -1, :]  # [1, num_items+1]\n",
    "            next_token = torch.topk(logits, k=1, dim=-1).indices.squeeze().item()\n",
    "            generated.append(next_token)\n",
    "            current_seq.append(next_token)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ba619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel_inference(model, inference_loader, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Запускает инференс на inference_loader и получает топ-K рекомендаций для каждого пользователя.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec\n",
    "    :param inference_loader: DataLoader без маскированных токенов (данные из train)\n",
    "    :param k: Количество рекомендаций\n",
    "    :param device: Устройство (CPU/GPU)\n",
    "    :return: Список предсказанных рекомендаций для всех пользователей\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Parallel Inference\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            position_ids = batch[\"position_ids\"].to(device)\n",
    "\n",
    "            # Генерируем k рекомендаций\n",
    "            recs = generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=k, device=device)\n",
    "            \n",
    "            all_recommendations.extend(recs.cpu().tolist())\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "\n",
    "def run_sequential_inference(model, inference_loader, max_len, k=10, device=device):\n",
    "    \"\"\"\n",
    "    Запускает последовательный инференс: для каждого пользователя из inference_loader извлекается исходная (непадённая) последовательность,\n",
    "    и генерируется последовательность рекомендаций методом авторегрессии.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec.\n",
    "    :param inference_loader: DataLoader с данными (is_train=False).\n",
    "    :param max_len: Максимальная длина последовательности.\n",
    "    :param k: Количество генерируемых рекомендаций для каждого пользователя.\n",
    "    :param device: Устройство.\n",
    "    :return: Словарь вида {user_id: [последовательность рекомендаций]}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    user_recs = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Sequential Inference\"):\n",
    "            input_ids = batch['input_ids']           # [B, max_len]\n",
    "            attention_mask = batch['attention_mask']   # [B, max_len]\n",
    "            user_ids = batch['user_id']                # список user_id\n",
    "            \n",
    "            # Для каждого пользователя в батче извлекаем исходную последовательность без паддинга\n",
    "            for i in range(input_ids.shape[0]):\n",
    "                # Переходим на CPU, чтобы легко работать со списками\n",
    "                seq = input_ids[i].cpu().tolist()\n",
    "                mask = attention_mask[i].cpu().tolist()\n",
    "                # Извлекаем только те токены, где mask==1 (непаддинговые элементы)\n",
    "                initial_seq = [token for token, m in zip(seq, mask) if m == 1]\n",
    "                recs = generate_sequential_recommendations(model, initial_seq, max_len, k=k, device=device)\n",
    "                user_recs[user_ids[i]] = recs\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем train-данные для генерации предсказаний\n",
    "inference_dataset = BERT4RecDataset(sequences=train_sequences_list, max_len=max_len, mask_prob=0.0, num_items=num_items, is_train=False)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb18144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_recommendations_to_users(user_ids, recommendations):\n",
    "    \"\"\"\n",
    "    Преобразует список рекомендаций в словарь {user_id: recommendations}.\n",
    "\n",
    "    :param user_ids: Список ID пользователей из inference_loader\n",
    "    :param recommendations: Список рекомендаций из parallel_recs\n",
    "    :return: Словарь {user_id: [recommendations]}\n",
    "    \"\"\"\n",
    "    user_to_recs = {user: recs for user, recs in zip(user_ids, recommendations)}\n",
    "    return user_to_recs\n",
    "\n",
    "# Получаем список пользователей из inference_loader\n",
    "user_ids = inference_loader.dataset.user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параллельные предсказания (Batch Inference)\n",
    "parallel_recs = run_parallel_inference(model, inference_loader, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_parallel_recs = map_recommendations_to_users(user_ids, parallel_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Последовательные предсказания (Sequential Inference)\n",
    "sequential_recs = run_sequential_inference(model, inference_loader, max_len=max_len, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_sequential_recs = map_recommendations_to_users(user_ids, sequential_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9745bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dc9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec10d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343f58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba432f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94a36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8198e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_lr_finder import TrainDataLoaderIter\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(ignore_index=0) # игнорим паддинги\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), \n",
    "#                              # lr=1e-5, # Было 1e-4\n",
    "#                              weight_decay=0.01)\n",
    "\n",
    "# class CustomTrainDataLoaderIter(TrainDataLoaderIter):\n",
    "#     def inputs_labels_from_batch(self, batch_data):\n",
    "#         # Извлекаем данные из батча\n",
    "#         inputs = {\n",
    "#             'input_ids': batch_data['input_ids'],          # Input IDs\n",
    "#             'attention_mask': batch_data['attention_mask'], # Attention Mask\n",
    "#             'position_ids': batch_data['position_ids']     # Position IDs\n",
    "#         }\n",
    "#         labels = batch_data['labels']  # Labels\n",
    "#         return inputs, labels\n",
    "\n",
    "\n",
    "# # Создаем кастомный итератор\n",
    "# train_iter = CustomTrainDataLoaderIter(train_loader)\n",
    "\n",
    "# # Инициализация LRFinder\n",
    "# lr_finder = LRFinder(model, optimizer, criterion)\n",
    "\n",
    "# # Запуск поиска learning rate\n",
    "# lr_finder.range_test(train_iter, end_lr=0.1, num_iter=100)\n",
    "\n",
    "# # Визуализация результатов\n",
    "# lr_finder.plot()\n",
    "\n",
    "# # Сброс состояния модели\n",
    "# lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создаем экземпляр модели\n",
    "# model = BERT4RecModel(\n",
    "#     num_items=num_items,\n",
    "#     max_len=max_len,\n",
    "#     embedding_dim=256,\n",
    "#     num_layers=4,       # Кол-во атеншн слоёв (Аттеншн + лин + нелин + дропаут)\n",
    "#     num_heads=8,        # Головы аттеншн слоёв\n",
    "#     dropout=0.1\n",
    "# ).to(device)\n",
    "\n",
    "# # Загружаем веса\n",
    "# model.load_state_dict(torch.load(models_path / 'bert4rec_embedding_dim_256_num_layers_3_num_heads_4_dropout_001_lr_1e5_base.pth'))\n",
    "\n",
    "# # Переводим модель в режим оценки\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45562441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667dc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300236e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preparing:   0%|          | 19/309343 [01:21<367:54:27,  4.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# df_filtered = pd.concat([train_df, test_df], ignore_index=True)  # если необходимо объединить\u001b[39;00m\n\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Предположим, что у вас уже есть df_filtered с нужными столбцами\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m product_meta_dict = \u001b[43mcompute_product_meta_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Количество уникальных товаров\u001b[39;00m\n\u001b[32m     84\u001b[39m num_items = df_filtered[\u001b[33m'\u001b[39m\u001b[33mproduct_idx\u001b[39m\u001b[33m'\u001b[39m].nunique()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mcompute_product_meta_features\u001b[39m\u001b[34m(df, meta_dim, device)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Извлекаем признаки изображения\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphoto_analytics\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     image = Image.open(BytesIO(response.content)).convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     59\u001b[39m     image = image_transform(image).unsqueeze(\u001b[32m0\u001b[39m).to(device)  \u001b[38;5;66;03m# переносим на нужное устройство\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Downloads/my_python_projects/project_for_TSUM_V2/TSUM_recommender_system/venv/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "# Дополнительные импорты для работы с изображениями и текстом\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.mps.set_per_process_memory_fraction(0.95)  # Ограничение памяти до 80%\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "#########################\n",
    "# 1. Предобработка метаданных\n",
    "#########################\n",
    "\n",
    "def compute_product_meta_features(df, meta_dim=128, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Вычисляет мета-вектор для каждого уникального продукта.\n",
    "    Используются признаки: brand, title, color_base, ktt1 (категория) и изображение из photo_analytics.\n",
    "    \"\"\"\n",
    "    # Инициализируем модель для текстовых эмбеддингов\n",
    "    text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Инициализируем предобученную модель для изображений (удаляем последний классификационный слой)\n",
    "    image_model = models.resnet18(pretrained=True)\n",
    "    image_model.fc = nn.Identity()\n",
    "    image_model = image_model.to(device)\n",
    "    image_model.eval()  # замораживаем веса для извлечения признаков\n",
    "    \n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    product_meta = {}\n",
    "    unique_products = df.drop_duplicates(subset=['product_idx'])\n",
    "    \n",
    "    for _, row in tqdm(unique_products.iterrows(), desc='Data preparing', total=unique_products.shape[0]):\n",
    "        product_idx = row['product_idx']\n",
    "        # Объединяем текстовые признаки\n",
    "        text_input = f\"{row['brand']} {row['title']} {row['color_base']} {row['ktt1']}\"\n",
    "        text_feat = text_model.encode(text_input, convert_to_tensor=True).to(device)\n",
    "        \n",
    "        # Извлекаем признаки изображения\n",
    "        try:\n",
    "            response = requests.get(row['photo_analytics'], timeout=5)\n",
    "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            image = image_transform(image).unsqueeze(0).to(device)  # переносим на нужное устройство\n",
    "            with torch.no_grad():\n",
    "                image_feat = image_model(image).squeeze(0)\n",
    "        except Exception as e:\n",
    "            # Если не удалось получить изображение, используем вектор нулей (размер 512)\n",
    "            image_feat = torch.zeros(512, device=device)\n",
    "        \n",
    "        # Конкатенируем текстовые и визуальные признаки\n",
    "        meta_feat = torch.cat([text_feat, image_feat], dim=0)\n",
    "        # Если размер полученного вектора не совпадает с meta_dim, применяем линейную проекцию\n",
    "        if meta_feat.shape[0] != meta_dim:\n",
    "            proj = nn.Linear(meta_feat.shape[0], meta_dim).to(device)\n",
    "            meta_feat = proj(meta_feat.unsqueeze(0)).squeeze(0)\n",
    "        product_meta[product_idx] = meta_feat\n",
    "    \n",
    "    return product_meta\n",
    "\n",
    "# Пример: объединяем train_df и test_df (или используем df_sales, если он есть)\n",
    "import pandas as pd\n",
    "# df_sales = pd.concat([train_df, test_df], ignore_index=True)  # если необходимо объединить\n",
    "\n",
    "# Предположим, что у вас уже есть df_sales с нужными столбцами\n",
    "product_meta_dict = compute_product_meta_features(df_sales, meta_dim=128)\n",
    "\n",
    "# Количество уникальных товаров\n",
    "num_items = df_sales['product_idx'].nunique()\n",
    "\n",
    "# Формируем матрицу весов для мета-эмбеддингов размерности (num_items+2, meta_dim)\n",
    "# +2 для pad (индекс 0) и mask токена (индекс num_items+1)\n",
    "meta_dim = 128\n",
    "meta_weights = torch.zeros(num_items + 2, meta_dim)\n",
    "# Заполняем веса для индексов от 1 до num_items (предполагается, что product_idx начинается с 1)\n",
    "for idx in range(1, num_items + 1):\n",
    "    if idx in product_meta_dict:\n",
    "        meta_weights[idx] = product_meta_dict[idx]\n",
    "    else:\n",
    "        meta_weights[idx] = torch.zeros(meta_dim)\n",
    "# Для токена 0 (pad) и токена mask (num_items+1) оставляем нули\n",
    "\n",
    "#########################\n",
    "# 2. Модификация модели BERT4Rec\n",
    "#########################\n",
    "\n",
    "class BERT4RecModel(nn.Module):\n",
    "    def __init__(self, num_items, max_len, meta_embedding_weights, embedding_dim=512, num_layers=6, num_heads=8, \n",
    "                 dropout=0.1, ffn_dim=2048):\n",
    "        \"\"\"\n",
    "        Модель BERT4Rec с дополнительными метаданными продукта.\n",
    "        \n",
    "        :param num_items: количество уникальных товаров\n",
    "        :param max_len: максимальная длина последовательности\n",
    "        :param meta_embedding_weights: предвычисленная матрица мета-векторов (torch.Tensor) размером (num_items+2, meta_dim)\n",
    "        :param embedding_dim: размерность эмбеддингов товара\n",
    "        :param num_layers: количество слоёв трансформера\n",
    "        :param num_heads: количество голов внимания\n",
    "        :param dropout: dropout\n",
    "        :param ffn_dim: размерность FFN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Эмбеддинги товара (токены: индексы от 0 до num_items+1)\n",
    "        self.item_embeddings = nn.Embedding(num_items + 2, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Слой мета-эмбеддингов (инициализируется предвычисленными признаками)\n",
    "        meta_dim = meta_embedding_weights.shape[1]\n",
    "        self.meta_embedding = nn.Embedding(num_items + 2, meta_dim, padding_idx=0)\n",
    "        self.meta_embedding.weight = nn.Parameter(meta_embedding_weights, requires_grad=False)  # замораживаем или можно fine-tune\n",
    "        # Проекция объединённого представления (конкатенация item и meta признаков)\n",
    "        self.meta_proj = nn.Linear(embedding_dim + meta_dim, embedding_dim)\n",
    "        \n",
    "        # Позиционные эмбеддинги\n",
    "        self.position_embeddings = nn.Embedding(max_len, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Трансформерный энкодер\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ffn_dim,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Классификационная голова\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embedding_dim * 2),\n",
    "            nn.Linear(embedding_dim * 2, num_items + 1)  # +1 так как target начинается с 1\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Инициализация эмбеддингов и весов трансформера\n",
    "        nn.init.normal_(self.item_embeddings.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.position_embeddings.weight, mean=0.0, std=0.02)\n",
    "        for layer in self.transformer.layers:\n",
    "            nn.init.xavier_uniform_(layer.self_attn.in_proj_weight)\n",
    "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
    "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc[0].weight)\n",
    "        nn.init.xavier_uniform_(self.fc[3].weight)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, position_ids):\n",
    "        # Эмбеддинги товара\n",
    "        item_embeds = self.item_embeddings(input_ids)\n",
    "        # Мета-эмбеддинги (дополнительная информация)\n",
    "        meta_embeds = self.meta_embedding(input_ids)\n",
    "        # Объединяем: конкатенируем и проецируем в embedding_dim\n",
    "        combined_embeds = torch.cat([item_embeds, meta_embeds], dim=-1)\n",
    "        combined_embeds = self.meta_proj(combined_embeds)\n",
    "        \n",
    "        # Позиционные эмбеддинги\n",
    "        pos_embeds = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Суммируем эмбеддинги и позиционные признаки, применяем LayerNorm и Dropout\n",
    "        embeddings = self.layer_norm(combined_embeds + pos_embeds)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        # Маска для паддингов\n",
    "        src_key_padding_mask = (attention_mask == 0)\n",
    "        \n",
    "        # Пропускаем через трансформер\n",
    "        transformer_output = self.transformer(embeddings, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # Классификационная голова\n",
    "        logits = self.fc(transformer_output)\n",
    "        return logits\n",
    "\n",
    "#########################\n",
    "# 3. Остальной код обучения остаётся аналогичным\n",
    "#########################\n",
    "\n",
    "# Пример создания датасетов, DataLoader и тренировки (код у вас уже есть)\n",
    "# При этом BERT4RecDataset не меняется, поскольку последовательности остаются на уровне product_idx\n",
    "\n",
    "# Параметры\n",
    "max_len = 12          # Максимальная длина последовательности\n",
    "mask_prob = 0.2       # Вероятность маскирования\n",
    "batch_size = 64\n",
    "\n",
    "# Преобразуем словари последовательностей в список кортежей (user_id, sequence)\n",
    "train_sequences_list = list(train_sequences.items())\n",
    "test_sequences_list = list(test_sequences.items())\n",
    "\n",
    "# Создаём датасеты (ваш класс BERT4RecDataset не изменился)\n",
    "train_dataset = BERT4RecDataset(\n",
    "    sequences=train_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "test_dataset = BERT4RecDataset(\n",
    "    sequences=test_sequences_list,\n",
    "    max_len=max_len,\n",
    "    mask_prob=mask_prob,\n",
    "    num_items=num_items,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model = BERT4RecModel(\n",
    "    num_items=num_items,\n",
    "    max_len=max_len,\n",
    "    meta_embedding_weights=meta_weights,\n",
    "    embedding_dim=256,    # например, 256\n",
    "    num_layers=3,         # количество слоёв\n",
    "    num_heads=4,          # количество голов\n",
    "    dropout=0.01\n",
    ").to(device)\n",
    "\n",
    "# Настраиваем оптимизатор\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Функция тренировки (ваша, как ранее)\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=5,\n",
    "    log_interval=50,\n",
    "    save_path=\"best_model.pth\",\n",
    "):\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar_train = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Training, Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, batch in progress_bar_train:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            position_ids = batch['position_ids'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, position_ids)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if (batch_idx + 1) % log_interval == 0:\n",
    "                avg_loss = running_loss / log_interval\n",
    "                train_loss_history.append(avg_loss)\n",
    "                running_loss = 0.0\n",
    "                progress_bar_train.set_postfix(loss=avg_loss)\n",
    "        \n",
    "        # Валидация (если нужно, можно раскомментировать)\n",
    "        # model.eval()\n",
    "        # val_loss = 0.0\n",
    "        # with torch.no_grad():\n",
    "        #     for batch in val_loader:\n",
    "        #         input_ids = batch['input_ids'].to(device)\n",
    "        #         labels = batch['labels'].to(device)\n",
    "        #         attention_mask = batch['attention_mask'].to(device)\n",
    "        #         position_ids = batch['position_ids'].to(device)\n",
    "        #         outputs = model(input_ids, attention_mask, position_ids)\n",
    "        #         loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "        #         val_loss += loss.item()\n",
    "        # avg_val_loss = val_loss / len(val_loader)\n",
    "        # val_loss_history.append(avg_val_loss)\n",
    "        # if avg_val_loss < best_loss:\n",
    "        #     best_loss = avg_val_loss\n",
    "        #     torch.save(model.state_dict(), save_path)\n",
    "        #     print(f\"New best model saved with val loss: {best_loss:.4f}\")\n",
    "    \n",
    "    return train_loss_history, val_loss_history\n",
    "\n",
    "# Запускаем обучение\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=5,\n",
    "    log_interval=100,\n",
    "    save_path=\"bert4rec_best.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee022bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920db365-8e6e-4865-a447-4ffb58880c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6033b24-76f5-4771-bbcf-b65828b1b4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c42a19b4-ec48-412d-a21b-748b9d7531d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для параллельной генерации рекомендаций (на входе батч из тестового DataLoader)\n",
    "def generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=6, device=device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        position_ids = position_ids.to(device)\n",
    "        \n",
    "        # Получаем выходы модели: [B, seq_len, num_items+1]\n",
    "        outputs = model(input_ids, attention_mask, position_ids)\n",
    "        # Берем логиты последнего токена (последний временной шаг)\n",
    "        logits = outputs[:, -1, :]  # размер [B, num_items+1]\n",
    "        # Выбираем топ-k рекомендаций для каждого примера\n",
    "        recs = torch.topk(logits, k=k, dim=-1).indices\n",
    "    return recs\n",
    "\n",
    "# Функция для последовательной генерации рекомендаций для одного пользователя\n",
    "def generate_sequential_recommendations(model, initial_sequence, max_len, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Генерирует последовательные рекомендации (авторегрессивно) для одного пользователя.\n",
    "    \n",
    "    :param initial_sequence: Исходная последовательность (список int) без паддинга.\n",
    "    :param max_len: Максимальная длина последовательности, с которой обучалась модель.\n",
    "    :param k: Количество генерируемых рекомендаций.\n",
    "    :param device: Устройство.\n",
    "    :return: Список сгенерированных рекомендаций.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated = []\n",
    "    current_seq = initial_sequence.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(k):\n",
    "            # Если длина последовательности меньше max_len – дополняем слева паддингом (значение 0)\n",
    "            if len(current_seq) < max_len:\n",
    "                padded_seq = [0] * (max_len - len(current_seq)) + current_seq\n",
    "            else:\n",
    "                padded_seq = current_seq[-max_len:]\n",
    "            \n",
    "            input_ids = torch.tensor(padded_seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            attention_mask = (input_ids != 0).long()\n",
    "            position_ids = torch.arange(max_len, dtype=torch.long, device=device).unsqueeze(0)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, position_ids)  # [1, max_len, num_items+1]\n",
    "            logits = outputs[:, -1, :]  # [1, num_items+1]\n",
    "            next_token = torch.topk(logits, k=1, dim=-1).indices.squeeze().item()\n",
    "            generated.append(next_token)\n",
    "            current_seq.append(next_token)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a46b59b3-6b92-48ce-a873-715d43d47d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel_inference(model, inference_loader, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Запускает инференс на inference_loader и получает топ-K рекомендаций для каждого пользователя.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec\n",
    "    :param inference_loader: DataLoader без маскированных токенов (данные из train)\n",
    "    :param k: Количество рекомендаций\n",
    "    :param device: Устройство (CPU/GPU)\n",
    "    :return: Список предсказанных рекомендаций для всех пользователей\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Parallel Inference\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            position_ids = batch[\"position_ids\"].to(device)\n",
    "\n",
    "            # Генерируем k рекомендаций\n",
    "            recs = generate_parallel_recommendations(model, input_ids, attention_mask, position_ids, k=k, device=device)\n",
    "            \n",
    "            all_recommendations.extend(recs.cpu().tolist())\n",
    "\n",
    "    return all_recommendations\n",
    "\n",
    "\n",
    "def run_sequential_inference(model, inference_loader, max_len, k=6, device=device):\n",
    "    \"\"\"\n",
    "    Запускает последовательный инференс: для каждого пользователя из inference_loader извлекается исходная (непадённая) последовательность,\n",
    "    и генерируется последовательность рекомендаций методом авторегрессии.\n",
    "    \n",
    "    :param model: Обученная модель BERT4Rec.\n",
    "    :param inference_loader: DataLoader с данными (is_train=False).\n",
    "    :param max_len: Максимальная длина последовательности.\n",
    "    :param k: Количество генерируемых рекомендаций для каждого пользователя.\n",
    "    :param device: Устройство.\n",
    "    :return: Словарь вида {user_id: [последовательность рекомендаций]}.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    user_recs = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(inference_loader, desc=\"Sequential Inference\"):\n",
    "            input_ids = batch['input_ids']           # [B, max_len]\n",
    "            attention_mask = batch['attention_mask']   # [B, max_len]\n",
    "            user_ids = batch['user_id']                # список user_id\n",
    "            \n",
    "            # Для каждого пользователя в батче извлекаем исходную последовательность без паддинга\n",
    "            for i in range(input_ids.shape[0]):\n",
    "                # Переходим на CPU, чтобы легко работать со списками\n",
    "                seq = input_ids[i].cpu().tolist()\n",
    "                mask = attention_mask[i].cpu().tolist()\n",
    "                # Извлекаем только те токены, где mask==1 (непаддинговые элементы)\n",
    "                initial_seq = [token for token, m in zip(seq, mask) if m == 1]\n",
    "                recs = generate_sequential_recommendations(model, initial_seq, max_len, k=k, device=device)\n",
    "                user_recs[user_ids[i]] = recs\n",
    "\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87317aef-b821-4a5d-a03e-e43eb437bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем train-данные для генерации предсказаний\n",
    "inference_dataset = BERT4RecDataset(sequences=train_sequences_list, max_len=max_len, mask_prob=0.0, num_items=num_items, is_train=False)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c64e54-d85c-4360-8e34-795eddad8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_recommendations_to_users(user_ids, recommendations):\n",
    "    \"\"\"\n",
    "    Преобразует список рекомендаций в словарь {user_id: recommendations}.\n",
    "\n",
    "    :param user_ids: Список ID пользователей из inference_loader\n",
    "    :param recommendations: Список рекомендаций из parallel_recs\n",
    "    :return: Словарь {user_id: [recommendations]}\n",
    "    \"\"\"\n",
    "    user_to_recs = {user: recs for user, recs in zip(user_ids, recommendations)}\n",
    "    return user_to_recs\n",
    "\n",
    "# Получаем список пользователей из inference_loader\n",
    "user_ids = inference_loader.dataset.user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e673eef-f9b2-40e3-847e-d6856c4bd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параллельные предсказания (Batch Inference)\n",
    "parallel_recs = run_parallel_inference(model, inference_loader, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_parallel_recs = map_recommendations_to_users(user_ids, parallel_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815bdfe-b39f-4947-b7f4-6ab29f00735d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cdb0d477a142b384762265dc7e67a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sequential Inference:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Параллельные предсказания (Batch Inference)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# parallel_recs = run_parallel_inference(model, inference_loader, k=k, device=device)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Последовательные предсказания (Sequential Inference)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m sequential_recs \u001b[38;5;241m=\u001b[39m run_sequential_inference(model, inference_loader, max_len\u001b[38;5;241m=\u001b[39mmax_len, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[125], line 56\u001b[0m, in \u001b[0;36mrun_sequential_inference\u001b[1;34m(model, inference_loader, max_len, k, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;66;03m# Извлекаем только те токены, где mask==1 (непаддинговые элементы)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             initial_seq \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(seq, mask) \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 56\u001b[0m             recs \u001b[38;5;241m=\u001b[39m generate_sequential_recommendations(model, initial_seq, max_len, k\u001b[38;5;241m=\u001b[39mk, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     57\u001b[0m             user_recs[user_ids[i]] \u001b[38;5;241m=\u001b[39m recs\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_recs\n",
      "Cell \u001b[1;32mIn[124], line 44\u001b[0m, in \u001b[0;36mgenerate_sequential_recommendations\u001b[1;34m(model, initial_sequence, max_len, k, device)\u001b[0m\n\u001b[0;32m     41\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m (input_ids \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     42\u001b[0m position_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(max_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask, position_ids)  \u001b[38;5;66;03m# [1, max_len, num_items+1]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# [1, num_items+1]\u001b[39;00m\n\u001b[0;32m     46\u001b[0m next_token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(logits, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 72\u001b[0m, in \u001b[0;36mBERT4RecModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids)\u001b[0m\n\u001b[0;32m     69\u001b[0m src_key_padding_mask \u001b[38;5;241m=\u001b[39m (attention_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Пропускаем через трансформер\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m     73\u001b[0m     embeddings,\n\u001b[0;32m     74\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Классификация\u001b[39;00m\n\u001b[0;32m     78\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(transformer_output)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(\n\u001b[0;32m    512\u001b[0m         output,\n\u001b[0;32m    513\u001b[0m         src_mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    514\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m    515\u001b[0m         src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers,\n\u001b[0;32m    516\u001b[0m     )\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:871\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_sparsity_fast_path:\n\u001b[0;32m    868\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mmerge_masks(\n\u001b[0;32m    869\u001b[0m             src_mask, src_key_padding_mask, src\n\u001b[0;32m    870\u001b[0m         )\n\u001b[1;32m--> 871\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_transformer_encoder_layer_fwd(\n\u001b[0;32m    872\u001b[0m             src,\n\u001b[0;32m    873\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[0;32m    874\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m    875\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39min_proj_weight,\n\u001b[0;32m    876\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m    877\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    878\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    879\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_relu_or_gelu \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    880\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first,\n\u001b[0;32m    881\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    883\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    884\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    885\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    886\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    887\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    888\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    889\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    890\u001b[0m             merged_mask,\n\u001b[0;32m    891\u001b[0m             mask_type,\n\u001b[0;32m    892\u001b[0m         )\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\u001b[39;00m\n\u001b[0;32m    895\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Последовательные предсказания (Sequential Inference)\n",
    "sequential_recs = run_sequential_inference(model, inference_loader, max_len=max_len, k=k, device=device)\n",
    "\n",
    "# Создаём словарь {user_id: recommendations}\n",
    "test_user_to_sequential_recs = map_recommendations_to_users(user_ids, sequential_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87f0810d-990a-4a77-b949-a4b4eec3cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bert4rec_classic_parallel = RecommendationDataset(user_recommendations=test_user_to_parallel_recs, user_to_true_items=test_user_to_true_items, k=k)\n",
    "loader = DataLoader(dataset_bert4rec_classic_parallel, batch_size=batch_size, collate_fn=collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5395d665-4a56-4e4f-81dd-06def694b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef7b699571b48ddbf1489336e28721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precision@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k: 0.00379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b1a05b31af41afb59943ba10380b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recall@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k: 0.003697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1e89860b7b407391803f87c3fcd243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAP@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@k: 0.00156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a079a86ca844dc853ab43b69ef59f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NDCG@K:   0%|          | 0/8541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m map_k \u001b[38;5;241m=\u001b[39m map_at_k_gpu(loader\u001b[38;5;241m=\u001b[39mloader, k\u001b[38;5;241m=\u001b[39mk, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAP@k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap_k\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m ndcg_k \u001b[38;5;241m=\u001b[39m ndcg_at_k_gpu(loader\u001b[38;5;241m=\u001b[39mloader, k\u001b[38;5;241m=\u001b[39mk, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDCG@k: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndcg_k\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[62], line 144\u001b[0m, in \u001b[0;36mndcg_at_k_gpu\u001b[1;34m(loader, k, batch_size, device)\u001b[0m\n\u001b[0;32m    141\u001b[0m         dcg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# IDCG@K\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m ideal_dcg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_items[i]), k)))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# NDCG@K\u001b[39;00m\n\u001b[0;32m    147\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m dcg \u001b[38;5;241m/\u001b[39m ideal_dcg \u001b[38;5;28;01mif\u001b[39;00m ideal_dcg \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[62], line 144\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m         dcg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# IDCG@K\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m ideal_dcg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mtensor(j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_items[i]), k)))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# NDCG@K\u001b[39;00m\n\u001b[0;32m    147\u001b[0m ndcg \u001b[38;5;241m=\u001b[39m dcg \u001b[38;5;241m/\u001b[39m ideal_dcg \u001b[38;5;28;01mif\u001b[39;00m ideal_dcg \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "precision_k = precision_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Precision@k: {precision_k:.5f}')\n",
    "\n",
    "recall_k = recall_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'Recall@k: {recall_k:5f}')\n",
    "\n",
    "map_k = map_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'MAP@k: {map_k:.5f}')\n",
    "\n",
    "ndcg_k = ndcg_at_k_gpu(loader=loader, k=k, batch_size=batch_size)\n",
    "print(f'NDCG@k: {ndcg_k:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861c6ad-fefb-4c45-95d6-d06ec7672a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_results(model_name='Top-K', k=k, precision_k=precision_k, recall_k=recall_k, map_k=map_k, ndcg_k=ndcg_k, hyperparameters=None)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874983a0-b07a-4d94-abf5-03b291ef2dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdc972e-b2cd-48d8-b819-af4028a7d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import weakref\n",
    "\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_mps:\n",
    "            ref = weakref.ref(obj)\n",
    "            del obj\n",
    "            del ref\n",
    "    except ReferenceError:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4741a-4e39-4ca4-8b4d-d29256befedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea101faa-5d2b-44f3-8046-3fbe91144118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca21a7-500f-4abd-9b36-14ce26723bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c64661-6729-4f2e-98bd-acfb01327fdc",
   "metadata": {},
   "source": [
    "### BERT4Rec Git version\n",
    "https://github.com/asash/bert4rec_repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74766d03-ad72-4914-b4a4-6c9e1569aa18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv: Recommender System with LLM)",
   "language": "python",
   "name": "recommender_system_with_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
